<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11.2 线性神经网络 | kj的学习笔记</title>
  <meta name="description" content="个人学习笔记" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="11.2 线性神经网络 | kj的学习笔记" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/‪D:.png" />
  <meta property="og:description" content="个人学习笔记" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11.2 线性神经网络 | kj的学习笔记" />
  
  <meta name="twitter:description" content="个人学习笔记" />
  <meta name="twitter:image" content="/‪D:.png" />

<meta name="author" content="刘柯榉" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="dl_1.html"/>
<link rel="next" href="dl_3.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.11/grViz.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-1.0.11/DiagrammeR.js"></script>
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<pre>  kj的学习笔记  </pre>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="content.html"><a href="content.html"><i class="fa fa-check"></i>内容组成</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>个人简介</a></li>
<li class="part"><span><b>I 专项</b></span></li>
<li class="chapter" data-level="1" data-path="rmd.html"><a href="rmd.html"><i class="fa fa-check"></i><b>1</b> R Markdown</a>
<ul>
<li class="chapter" data-level="1.1" data-path="rmd_1.html"><a href="rmd_1.html"><i class="fa fa-check"></i><b>1.1</b> 安装与创建</a></li>
<li class="chapter" data-level="1.2" data-path="rmd_2.html"><a href="rmd_2.html"><i class="fa fa-check"></i><b>1.2</b> 初识RMD</a></li>
<li class="chapter" data-level="1.3" data-path="rmd_3.html"><a href="rmd_3.html"><i class="fa fa-check"></i><b>1.3</b> 语法介绍</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_1"><i class="fa fa-check"></i><b>1.3.1</b> 标题</a></li>
<li class="chapter" data-level="1.3.2" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_2"><i class="fa fa-check"></i><b>1.3.2</b> 字体样式</a></li>
<li class="chapter" data-level="1.3.3" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_3"><i class="fa fa-check"></i><b>1.3.3</b> 换行</a></li>
<li class="chapter" data-level="1.3.4" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_4"><i class="fa fa-check"></i><b>1.3.4</b> 链接</a></li>
<li class="chapter" data-level="1.3.5" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_5"><i class="fa fa-check"></i><b>1.3.5</b> 引用</a></li>
<li class="chapter" data-level="1.3.6" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_6"><i class="fa fa-check"></i><b>1.3.6</b> 列表</a></li>
<li class="chapter" data-level="1.3.7" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_7"><i class="fa fa-check"></i><b>1.3.7</b> 代码</a></li>
<li class="chapter" data-level="1.3.8" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_8"><i class="fa fa-check"></i><b>1.3.8</b> 表格</a></li>
<li class="chapter" data-level="1.3.9" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_9"><i class="fa fa-check"></i><b>1.3.9</b> 图片</a></li>
<li class="chapter" data-level="1.3.10" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_10"><i class="fa fa-check"></i><b>1.3.10</b> 数学公式</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="rmd_4.html"><a href="rmd_4.html"><i class="fa fa-check"></i><b>1.4</b> 文档元素</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_1"><i class="fa fa-check"></i><b>1.4.1</b> 分割线</a></li>
<li class="chapter" data-level="1.4.2" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_2"><i class="fa fa-check"></i><b>1.4.2</b> 转义符</a></li>
<li class="chapter" data-level="1.4.3" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_3"><i class="fa fa-check"></i><b>1.4.3</b> 分页符</a></li>
<li class="chapter" data-level="1.4.4" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_4"><i class="fa fa-check"></i><b>1.4.4</b> 设置动态标题</a></li>
<li class="chapter" data-level="1.4.5" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_5"><i class="fa fa-check"></i><b>1.4.5</b> 自动更新时间</a></li>
<li class="chapter" data-level="1.4.6" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_6"><i class="fa fa-check"></i><b>1.4.6</b> 获取元数据信息</a></li>
<li class="chapter" data-level="1.4.7" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_7"><i class="fa fa-check"></i><b>1.4.7</b> 参考文献</a></li>
<li class="chapter" data-level="1.4.8" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_8"><i class="fa fa-check"></i><b>1.4.8</b> 交叉引用</a></li>
<li class="chapter" data-level="1.4.9" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_9"><i class="fa fa-check"></i><b>1.4.9</b> 多位作者</a></li>
<li class="chapter" data-level="1.4.10" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_10"><i class="fa fa-check"></i><b>1.4.10</b> 将模型输出为公式</a></li>
<li class="chapter" data-level="1.4.11" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_11"><i class="fa fa-check"></i><b>1.4.11</b> 流程图</a></li>
<li class="chapter" data-level="1.4.12" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_12"><i class="fa fa-check"></i><b>1.4.12</b> 注释</a></li>
<li class="chapter" data-level="1.4.13" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_13"><i class="fa fa-check"></i><b>1.4.13</b> 缩进</a></li>
<li class="chapter" data-level="1.4.14" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_14"><i class="fa fa-check"></i><b>1.4.14</b> 字体颜色</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="rmd_5.html"><a href="rmd_5.html"><i class="fa fa-check"></i><b>1.5</b> HTML文档</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_1"><i class="fa fa-check"></i><b>1.5.1</b> 标签</a></li>
<li class="chapter" data-level="1.5.2" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_2"><i class="fa fa-check"></i><b>1.5.2</b> 目录</a></li>
<li class="chapter" data-level="1.5.3" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_3"><i class="fa fa-check"></i><b>1.5.3</b> 外观</a></li>
<li class="chapter" data-level="1.5.4" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_4"><i class="fa fa-check"></i><b>1.5.4</b> 选项卡</a></li>
<li class="chapter" data-level="1.5.5" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_5"><i class="fa fa-check"></i><b>1.5.5</b> 表格</a></li>
<li class="chapter" data-level="1.5.6" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_6"><i class="fa fa-check"></i><b>1.5.6</b> 代码块及其输出</a></li>
<li class="chapter" data-level="1.5.7" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_7"><i class="fa fa-check"></i><b>1.5.7</b> 添加HTML文件</a></li>
<li class="chapter" data-level="1.5.8" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_8"><i class="fa fa-check"></i><b>1.5.8</b> Pandoc参数</a></li>
<li class="chapter" data-level="1.5.9" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_9"><i class="fa fa-check"></i><b>1.5.9</b> 共享选项</a></li>
<li class="chapter" data-level="1.5.10" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_10"><i class="fa fa-check"></i><b>1.5.10</b> 下载文件</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="rmd_6.html"><a href="rmd_6.html"><i class="fa fa-check"></i><b>1.6</b> PDF文档</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_1"><i class="fa fa-check"></i><b>1.6.1</b> 中文文档</a></li>
<li class="chapter" data-level="1.6.2" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_2"><i class="fa fa-check"></i><b>1.6.2</b> 目录</a></li>
<li class="chapter" data-level="1.6.3" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_3"><i class="fa fa-check"></i><b>1.6.3</b> 图与表</a></li>
<li class="chapter" data-level="1.6.4" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_4"><i class="fa fa-check"></i><b>1.6.4</b> 语法高亮</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="manim.html"><a href="manim.html"><i class="fa fa-check"></i><b>2</b> Manim</a>
<ul>
<li class="chapter" data-level="2.1" data-path="manim_1.html"><a href="manim_1.html"><i class="fa fa-check"></i><b>2.1</b> 安装与创建</a></li>
<li class="chapter" data-level="2.2" data-path="manim_2.html"><a href="manim_2.html"><i class="fa fa-check"></i><b>2.2</b> 初识Manim</a></li>
<li class="chapter" data-level="2.3" data-path="manim_3.html"><a href="manim_3.html"><i class="fa fa-check"></i><b>2.3</b> 输出设置</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="manim_3.html"><a href="manim_3.html#manim_3_1"><i class="fa fa-check"></i><b>2.3.1</b> 输出文件夹</a></li>
<li class="chapter" data-level="2.3.2" data-path="manim_3.html"><a href="manim_3.html#manim_3_2"><i class="fa fa-check"></i><b>2.3.2</b> 片段</a></li>
<li class="chapter" data-level="2.3.3" data-path="manim_3.html"><a href="manim_3.html#manim_3_3"><i class="fa fa-check"></i><b>2.3.3</b> 命令行标志</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="manim_4.html"><a href="manim_4.html"><i class="fa fa-check"></i><b>2.4</b> 配置</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="manim_4.html"><a href="manim_4.html#manim_4_1"><i class="fa fa-check"></i><b>2.4.1</b> 命令行参数</a></li>
<li class="chapter" data-level="2.4.2" data-path="manim_4.html"><a href="manim_4.html#manim_4_2"><i class="fa fa-check"></i><b>2.4.2</b> ManimConfig类</a></li>
<li class="chapter" data-level="2.4.3" data-path="manim_4.html"><a href="manim_4.html#manim_4_3"><i class="fa fa-check"></i><b>2.4.3</b> 配置文件</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="manim_5.html"><a href="manim_5.html"><i class="fa fa-check"></i><b>2.5</b> 文本</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="manim_5.html"><a href="manim_5.html#manim_5_1"><i class="fa fa-check"></i><b>2.5.1</b> Text</a></li>
<li class="chapter" data-level="2.5.2" data-path="manim_5.html"><a href="manim_5.html#manim_5_2"><i class="fa fa-check"></i><b>2.5.2</b> MarkupText</a></li>
<li class="chapter" data-level="2.5.3" data-path="manim_5.html"><a href="manim_5.html#manim_5_3"><i class="fa fa-check"></i><b>2.5.3</b> Paragraph</a></li>
<li class="chapter" data-level="2.5.4" data-path="manim_5.html"><a href="manim_5.html#manim_5_4"><i class="fa fa-check"></i><b>2.5.4</b> Tex</a></li>
<li class="chapter" data-level="2.5.5" data-path="manim_5.html"><a href="manim_5.html#manim_5_5"><i class="fa fa-check"></i><b>2.5.5</b> MathTex</a></li>
<li class="chapter" data-level="2.5.6" data-path="manim_5.html"><a href="manim_5.html#manim_5_6"><i class="fa fa-check"></i><b>2.5.6</b> Title</a></li>
<li class="chapter" data-level="2.5.7" data-path="manim_5.html"><a href="manim_5.html#manim_5_7"><i class="fa fa-check"></i><b>2.5.7</b> BulletedList</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="manim_6.html"><a href="manim_6.html"><i class="fa fa-check"></i><b>2.6</b> 内置颜色</a></li>
<li class="chapter" data-level="2.7" data-path="manim_7.html"><a href="manim_7.html"><i class="fa fa-check"></i><b>2.7</b> 物体的位置与移动</a></li>
<li class="chapter" data-level="2.8" data-path="manim_8.html"><a href="manim_8.html"><i class="fa fa-check"></i><b>2.8</b> 动画</a></li>
<li class="chapter" data-level="2.9" data-path="manim_9.html"><a href="manim_9.html"><i class="fa fa-check"></i><b>2.9</b> 镜头视角</a></li>
<li class="chapter" data-level="2.10" data-path="manim_10.html"><a href="manim_10.html"><i class="fa fa-check"></i><b>2.10</b> 存储对象</a></li>
<li class="chapter" data-level="2.11" data-path="manim_11.html"><a href="manim_11.html"><i class="fa fa-check"></i><b>2.11</b> 成品</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sql.html"><a href="sql.html"><i class="fa fa-check"></i><b>3</b> SQL</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sql_1.html"><a href="sql_1.html"><i class="fa fa-check"></i><b>3.1</b> 连接MySQL</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sql_1.html"><a href="sql_1.html#sql_1_1"><i class="fa fa-check"></i><b>3.1.1</b> R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sql_2.html"><a href="sql_2.html"><i class="fa fa-check"></i><b>3.2</b> MySQL必知必会</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sql_2.html"><a href="sql_2.html#sql_2_1"><i class="fa fa-check"></i><b>3.2.1</b> 提要</a></li>
<li class="chapter" data-level="3.2.2" data-path="sql_2.html"><a href="sql_2.html#sql_2_2"><i class="fa fa-check"></i><b>3.2.2</b> 选择数据库与表</a></li>
<li class="chapter" data-level="3.2.3" data-path="sql_2.html"><a href="sql_2.html#sql_2_3"><i class="fa fa-check"></i><b>3.2.3</b> 检索数据</a></li>
<li class="chapter" data-level="3.2.4" data-path="sql_2.html"><a href="sql_2.html#sql_2_4"><i class="fa fa-check"></i><b>3.2.4</b> 排序检索数据</a></li>
<li class="chapter" data-level="3.2.5" data-path="sql_2.html"><a href="sql_2.html#sql_2_5"><i class="fa fa-check"></i><b>3.2.5</b> 过滤数据</a></li>
<li class="chapter" data-level="3.2.6" data-path="sql_2.html"><a href="sql_2.html#sql_2_6"><i class="fa fa-check"></i><b>3.2.6</b> 计算字段</a></li>
<li class="chapter" data-level="3.2.7" data-path="sql_2.html"><a href="sql_2.html#sql_2_7"><i class="fa fa-check"></i><b>3.2.7</b> 函数</a></li>
<li class="chapter" data-level="3.2.8" data-path="sql_2.html"><a href="sql_2.html#sql_2_8"><i class="fa fa-check"></i><b>3.2.8</b> 汇总数据</a></li>
<li class="chapter" data-level="3.2.9" data-path="sql_2.html"><a href="sql_2.html#sql_2_9"><i class="fa fa-check"></i><b>3.2.9</b> 数据分组</a></li>
<li class="chapter" data-level="3.2.10" data-path="sql_2.html"><a href="sql_2.html#sql_2_10"><i class="fa fa-check"></i><b>3.2.10</b> 子查询</a></li>
<li class="chapter" data-level="3.2.11" data-path="sql_2.html"><a href="sql_2.html#sql_2_11"><i class="fa fa-check"></i><b>3.2.11</b> 表联结</a></li>
<li class="chapter" data-level="3.2.12" data-path="sql_2.html"><a href="sql_2.html#sql_2_12"><i class="fa fa-check"></i><b>3.2.12</b> 组合查询</a></li>
<li class="chapter" data-level="3.2.13" data-path="sql_2.html"><a href="sql_2.html#sql_2_13"><i class="fa fa-check"></i><b>3.2.13</b> 全文本搜索</a></li>
<li class="chapter" data-level="3.2.14" data-path="sql_2.html"><a href="sql_2.html#sql_2_14"><i class="fa fa-check"></i><b>3.2.14</b> 插入数据</a></li>
<li class="chapter" data-level="3.2.15" data-path="sql_2.html"><a href="sql_2.html#sql_2_15"><i class="fa fa-check"></i><b>3.2.15</b> 更新数据</a></li>
<li class="chapter" data-level="3.2.16" data-path="sql_2.html"><a href="sql_2.html#sql_2_16"><i class="fa fa-check"></i><b>3.2.16</b> 表的操作</a></li>
<li class="chapter" data-level="3.2.17" data-path="sql_2.html"><a href="sql_2.html#sql_2_17"><i class="fa fa-check"></i><b>3.2.17</b> 使用视图</a></li>
<li class="chapter" data-level="3.2.18" data-path="sql_2.html"><a href="sql_2.html#sql_2_18"><i class="fa fa-check"></i><b>3.2.18</b> 使用存储过程</a></li>
<li class="chapter" data-level="3.2.19" data-path="sql_2.html"><a href="sql_2.html#sql_2_19"><i class="fa fa-check"></i><b>3.2.19</b> 触发器</a></li>
<li class="chapter" data-level="3.2.20" data-path="sql_2.html"><a href="sql_2.html#sql_2_20"><i class="fa fa-check"></i><b>3.2.20</b> 事务处理</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="spider.html"><a href="spider.html"><i class="fa fa-check"></i><b>4</b> 爬虫</a>
<ul>
<li class="chapter" data-level="4.1" data-path="spider_1.html"><a href="spider_1.html"><i class="fa fa-check"></i><b>4.1</b> 提要</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>5</b> Shiny</a>
<ul>
<li class="chapter" data-level="5.1" data-path="shiny_1.html"><a href="shiny_1.html"><i class="fa fa-check"></i><b>5.1</b> 初始Shiny</a></li>
<li class="chapter" data-level="5.2" data-path="shiny_2.html"><a href="shiny_2.html"><i class="fa fa-check"></i><b>5.2</b> UI设计</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="shiny_2.html"><a href="shiny_2.html#shiny_2_1"><i class="fa fa-check"></i><b>5.2.1</b> 输入</a></li>
<li class="chapter" data-level="5.2.2" data-path="shiny_2.html"><a href="shiny_2.html#shiny_2_2"><i class="fa fa-check"></i><b>5.2.2</b> 输出</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="shiny_3.html"><a href="shiny_3.html"><i class="fa fa-check"></i><b>5.3</b> 反应式编程</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_1"><i class="fa fa-check"></i><b>5.3.1</b> 服务端</a></li>
<li class="chapter" data-level="5.3.2" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_2"><i class="fa fa-check"></i><b>5.3.2</b> 反应表达式</a></li>
<li class="chapter" data-level="5.3.3" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_3"><i class="fa fa-check"></i><b>5.3.3</b> 控制更新</a></li>
<li class="chapter" data-level="5.3.4" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_4"><i class="fa fa-check"></i><b>5.3.4</b> 信息反馈</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="shiny_4.html"><a href="shiny_4.html"><i class="fa fa-check"></i><b>5.4</b> 页面布局</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="shiny_4.html"><a href="shiny_4.html#shiny_4_1"><i class="fa fa-check"></i><b>5.4.1</b> 页面函数</a></li>
<li class="chapter" data-level="5.4.2" data-path="shiny_4.html"><a href="shiny_4.html#shiny_4_2"><i class="fa fa-check"></i><b>5.4.2</b> 布局函数</a></li>
<li class="chapter" data-level="5.4.3" data-path="shiny_4.html"><a href="shiny_4.html#shiny_4_2_3"><i class="fa fa-check"></i><b>5.4.3</b> bslib风格布局</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="shiny_5.html"><a href="shiny_5.html"><i class="fa fa-check"></i><b>5.5</b> 主题</a></li>
<li class="chapter" data-level="5.6" data-path="shiny_6.html"><a href="shiny_6.html"><i class="fa fa-check"></i><b>5.6</b> 交互式图像与插入图像</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="shiny_6.html"><a href="shiny_6.html#shiny_6_1"><i class="fa fa-check"></i><b>5.6.1</b> 交互式图像</a></li>
<li class="chapter" data-level="5.6.2" data-path="shiny_6.html"><a href="shiny_6.html#shiny_6_2"><i class="fa fa-check"></i><b>5.6.2</b> 插入图像</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="shiny_7.html"><a href="shiny_7.html"><i class="fa fa-check"></i><b>5.7</b> 用户反馈</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_1"><i class="fa fa-check"></i><b>5.7.1</b> 验证</a></li>
<li class="chapter" data-level="5.7.2" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_2"><i class="fa fa-check"></i><b>5.7.2</b> 通知</a></li>
<li class="chapter" data-level="5.7.3" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_3"><i class="fa fa-check"></i><b>5.7.3</b> 进度条</a></li>
<li class="chapter" data-level="5.7.4" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_4"><i class="fa fa-check"></i><b>5.7.4</b> 确认</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="shiny_8.html"><a href="shiny_8.html"><i class="fa fa-check"></i><b>5.8</b> shiny中的整洁式编程</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="shiny_8.html"><a href="shiny_8.html#shiny_8_1"><i class="fa fa-check"></i><b>5.8.1</b> Data-masking</a></li>
<li class="chapter" data-level="5.8.2" data-path="shiny_8.html"><a href="shiny_8.html#shiny_8_2"><i class="fa fa-check"></i><b>5.8.2</b> Tidy-selection</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="shiny_9.html"><a href="shiny_9.html"><i class="fa fa-check"></i><b>5.9</b> 交互式Rmarkdown</a></li>
<li class="chapter" data-level="5.10" data-path="shiny_10.html"><a href="shiny_10.html"><i class="fa fa-check"></i><b>5.10</b> 数据仪表盘</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="shiny_10.html"><a href="shiny_10.html#shiny_10_1"><i class="fa fa-check"></i><b>5.10.1</b> 整体框架</a></li>
<li class="chapter" data-level="5.10.2" data-path="shiny_10.html"><a href="shiny_10.html#shiny_10_2"><i class="fa fa-check"></i><b>5.10.2</b> 外观</a></li>
<li class="chapter" data-level="5.10.3" data-path="shiny_10.html"><a href="shiny_10.html#shiny_10_3"><i class="fa fa-check"></i><b>5.10.3</b> 案例</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="shiny_11.html"><a href="shiny_11.html"><i class="fa fa-check"></i><b>5.11</b> 分享shiny</a></li>
</ul></li>
<li class="part"><span><b>II 模型与方法</b></span></li>
<li class="chapter" data-level="6" data-path="reg.html"><a href="reg.html"><i class="fa fa-check"></i><b>6</b> 应用回归分析</a>
<ul>
<li class="chapter" data-level="6.1" data-path="reg_1.html"><a href="reg_1.html"><i class="fa fa-check"></i><b>6.1</b> 引言</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="reg_1.html"><a href="reg_1.html#reg_1_1"><i class="fa fa-check"></i><b>6.1.1</b> 变量间的相关关系</a></li>
<li class="chapter" data-level="6.1.2" data-path="reg_1.html"><a href="reg_1.html#reg_1_2"><i class="fa fa-check"></i><b>6.1.2</b> 回归模型的一般形式</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="reg_2.html"><a href="reg_2.html"><i class="fa fa-check"></i><b>6.2</b> 假定</a></li>
<li class="chapter" data-level="6.3" data-path="reg_3.html"><a href="reg_3.html"><i class="fa fa-check"></i><b>6.3</b> 线性回归模型</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="reg_3.html"><a href="reg_3.html#reg_3_1"><i class="fa fa-check"></i><b>6.3.1</b> 一元线性回归模型</a></li>
<li class="chapter" data-level="6.3.2" data-path="reg_3.html"><a href="reg_3.html#reg_3_2"><i class="fa fa-check"></i><b>6.3.2</b> 多元线性回归模型</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="reg_4.html"><a href="reg_4.html"><i class="fa fa-check"></i><b>6.4</b> 参数估计</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="reg_4.html"><a href="reg_4.html#reg_4_1"><i class="fa fa-check"></i><b>6.4.1</b> 最小二乘估计</a></li>
<li class="chapter" data-level="6.4.2" data-path="reg_4.html"><a href="reg_4.html#reg_4_2"><i class="fa fa-check"></i><b>6.4.2</b> 极大似然估计</a></li>
<li class="chapter" data-level="6.4.3" data-path="reg_4.html"><a href="reg_4.html#reg_4_3"><i class="fa fa-check"></i><b>6.4.3</b> 矩估计</a></li>
<li class="chapter" data-level="6.4.4" data-path="reg_4.html"><a href="reg_4.html#reg_4_4"><i class="fa fa-check"></i><b>6.4.4</b> 几何视角</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="reg_5.html"><a href="reg_5.html"><i class="fa fa-check"></i><b>6.5</b> 最小二乘估计的性质</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="reg_5.html"><a href="reg_5.html#reg_5_1"><i class="fa fa-check"></i><b>6.5.1</b> 线性</a></li>
<li class="chapter" data-level="6.5.2" data-path="reg_5.html"><a href="reg_5.html#reg_5_2"><i class="fa fa-check"></i><b>6.5.2</b> 无偏性</a></li>
<li class="chapter" data-level="6.5.3" data-path="reg_5.html"><a href="reg_5.html#reg_5_3"><i class="fa fa-check"></i><b>6.5.3</b> 有效性</a></li>
<li class="chapter" data-level="6.5.4" data-path="reg_5.html"><a href="reg_5.html#reg_5_4"><i class="fa fa-check"></i><b>6.5.4</b> 方差</a></li>
<li class="chapter" data-level="6.5.5" data-path="reg_5.html"><a href="reg_5.html#reg_5_5"><i class="fa fa-check"></i><b>6.5.5</b> 正态性</a></li>
<li class="chapter" data-level="6.5.6" data-path="reg_5.html"><a href="reg_5.html#reg_5_6"><i class="fa fa-check"></i><b>6.5.6</b> 残差</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="reg_6.html"><a href="reg_6.html"><i class="fa fa-check"></i><b>6.6</b> 显著性检验</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="reg_6.html"><a href="reg_6.html#reg_6_1"><i class="fa fa-check"></i><b>6.6.1</b> 区间估计</a></li>
<li class="chapter" data-level="6.6.2" data-path="reg_6.html"><a href="reg_6.html#reg_6_2"><i class="fa fa-check"></i><b>6.6.2</b> t检验</a></li>
<li class="chapter" data-level="6.6.3" data-path="reg_6.html"><a href="reg_6.html#reg_6_3"><i class="fa fa-check"></i><b>6.6.3</b> F检验</a></li>
<li class="chapter" data-level="6.6.4" data-path="reg_6.html"><a href="reg_6.html#reg_6_4"><i class="fa fa-check"></i><b>6.6.4</b> 偏F检验</a></li>
<li class="chapter" data-level="6.6.5" data-path="reg_6.html"><a href="reg_6.html#reg_6_5"><i class="fa fa-check"></i><b>6.6.5</b> 样本决定系数</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="reg_7.html"><a href="reg_7.html"><i class="fa fa-check"></i><b>6.7</b> 预测</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="reg_7.html"><a href="reg_7.html#reg_7_1"><i class="fa fa-check"></i><b>6.7.1</b> 预测因变量新值的均值</a></li>
<li class="chapter" data-level="6.7.2" data-path="reg_7.html"><a href="reg_7.html#reg_7_2"><i class="fa fa-check"></i><b>6.7.2</b> 预测因变量的新值</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="reg_8.html"><a href="reg_8.html"><i class="fa fa-check"></i><b>6.8</b> 回归系数的解释</a></li>
<li class="chapter" data-level="6.9" data-path="reg_9.html"><a href="reg_9.html"><i class="fa fa-check"></i><b>6.9</b> 中心化与标准化</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="reg_9.html"><a href="reg_9.html#reg_9_1"><i class="fa fa-check"></i><b>6.9.1</b> 中心化</a></li>
<li class="chapter" data-level="6.9.2" data-path="reg_9.html"><a href="reg_9.html#reg_9_2"><i class="fa fa-check"></i><b>6.9.2</b> 标准化</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="reg_10.html"><a href="reg_10.html"><i class="fa fa-check"></i><b>6.10</b> 相关系数与偏相关系数</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="reg_10.html"><a href="reg_10.html#reg_10_1"><i class="fa fa-check"></i><b>6.10.1</b> 样本相关系数</a></li>
<li class="chapter" data-level="6.10.2" data-path="reg_10.html"><a href="reg_10.html#reg_10_2"><i class="fa fa-check"></i><b>6.10.2</b> 样本偏相关系数</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="reg_11.html"><a href="reg_11.html"><i class="fa fa-check"></i><b>6.11</b> 重要的定义和等式</a></li>
<li class="chapter" data-level="6.12" data-path="reg_12.html"><a href="reg_12.html"><i class="fa fa-check"></i><b>6.12</b> 回归诊断</a>
<ul>
<li class="chapter" data-level="6.12.1" data-path="reg_12.html"><a href="reg_12.html#reg_12_1"><i class="fa fa-check"></i><b>6.12.1</b> 残差分析</a></li>
<li class="chapter" data-level="6.12.2" data-path="reg_12.html"><a href="reg_12.html#reg_12_2"><i class="fa fa-check"></i><b>6.12.2</b> 异常点和强影响点</a></li>
<li class="chapter" data-level="6.12.3" data-path="reg_12.html"><a href="reg_12.html#reg_12_3"><i class="fa fa-check"></i><b>6.12.3</b> 异方差</a></li>
<li class="chapter" data-level="6.12.4" data-path="reg_12.html"><a href="reg_12.html#reg_12_4"><i class="fa fa-check"></i><b>6.12.4</b> 自相关</a></li>
<li class="chapter" data-level="6.12.5" data-path="reg_12.html"><a href="reg_12.html#reg_12_5"><i class="fa fa-check"></i><b>6.12.5</b> 多重共线性</a></li>
</ul></li>
<li class="chapter" data-level="6.13" data-path="reg_13.html"><a href="reg_13.html"><i class="fa fa-check"></i><b>6.13</b> 变量选择与正则化</a>
<ul>
<li class="chapter" data-level="6.13.1" data-path="reg_13.html"><a href="reg_13.html#reg_13_1"><i class="fa fa-check"></i><b>6.13.1</b> 冗余与遗漏</a></li>
<li class="chapter" data-level="6.13.2" data-path="reg_13.html"><a href="reg_13.html#reg_13_2"><i class="fa fa-check"></i><b>6.13.2</b> 变量选择的传统方法</a></li>
<li class="chapter" data-level="6.13.3" data-path="reg_13.html"><a href="reg_13.html#reg_13_3"><i class="fa fa-check"></i><b>6.13.3</b> 变量选择的正则化方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ms.html"><a href="ms.html"><i class="fa fa-check"></i><b>7</b> 应用多元统计</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ms_1.html"><a href="ms_1.html"><i class="fa fa-check"></i><b>7.1</b> 矩阵运算</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="ms_1.html"><a href="ms_1.html#ms_1_1"><i class="fa fa-check"></i><b>7.1.1</b> Kronecker积</a></li>
<li class="chapter" data-level="7.1.2" data-path="ms_1.html"><a href="ms_1.html#ms_1_2"><i class="fa fa-check"></i><b>7.1.2</b> 拉直</a></li>
<li class="chapter" data-level="7.1.3" data-path="ms_1.html"><a href="ms_1.html#ms_1_3"><i class="fa fa-check"></i><b>7.1.3</b> 减号逆与加号逆</a></li>
<li class="chapter" data-level="7.1.4" data-path="ms_1.html"><a href="ms_1.html#ms_1_4"><i class="fa fa-check"></i><b>7.1.4</b> 分块矩阵</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ms_2.html"><a href="ms_2.html"><i class="fa fa-check"></i><b>7.2</b> 多元正态分布</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ms_2.html"><a href="ms_2.html#ms_2_1"><i class="fa fa-check"></i><b>7.2.1</b> 多元分布的基本运算性质</a></li>
<li class="chapter" data-level="7.2.2" data-path="ms_2.html"><a href="ms_2.html#ms_2_2"><i class="fa fa-check"></i><b>7.2.2</b> 多元正态分布的定义</a></li>
<li class="chapter" data-level="7.2.3" data-path="ms_2.html"><a href="ms_2.html#ms_2_3"><i class="fa fa-check"></i><b>7.2.3</b> 正态分布的条件分布和独立性</a></li>
<li class="chapter" data-level="7.2.4" data-path="ms_2.html"><a href="ms_2.html#ms_2_4"><i class="fa fa-check"></i><b>7.2.4</b> 偏相关系数与全相关系数</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ms_3.html"><a href="ms_3.html"><i class="fa fa-check"></i><b>7.3</b> 主成分分析</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="ms_3.html"><a href="ms_3.html#ms_3_1"><i class="fa fa-check"></i><b>7.3.1</b> 总体主成分</a></li>
<li class="chapter" data-level="7.3.2" data-path="ms_3.html"><a href="ms_3.html#ms_3_2"><i class="fa fa-check"></i><b>7.3.2</b> 样本主成分</a></li>
<li class="chapter" data-level="7.3.3" data-path="ms_3.html"><a href="ms_3.html#ms_3_3"><i class="fa fa-check"></i><b>7.3.3</b> 关于主成分</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ms_4.html"><a href="ms_4.html"><i class="fa fa-check"></i><b>7.4</b> 因子分析</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="ms_4.html"><a href="ms_4.html#ms_4_1"><i class="fa fa-check"></i><b>7.4.1</b> 正交因子模型</a></li>
<li class="chapter" data-level="7.4.2" data-path="ms_4.html"><a href="ms_4.html#ms_4_3"><i class="fa fa-check"></i><b>7.4.2</b> 参数估计</a></li>
<li class="chapter" data-level="7.4.3" data-path="ms_4.html"><a href="ms_4.html#ms_4_4"><i class="fa fa-check"></i><b>7.4.3</b> 因子旋转</a></li>
<li class="chapter" data-level="7.4.4" data-path="ms_4.html"><a href="ms_4.html#ms_4_5"><i class="fa fa-check"></i><b>7.4.4</b> 因子得分</a></li>
<li class="chapter" data-level="7.4.5" data-path="ms_4.html"><a href="ms_4.html#ms_4_6"><i class="fa fa-check"></i><b>7.4.5</b> 因子分析和主成分分析的区别与联系</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ms_5.html"><a href="ms_5.html"><i class="fa fa-check"></i><b>7.5</b> 判别分析</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="ms_5.html"><a href="ms_5.html#ms_5_1"><i class="fa fa-check"></i><b>7.5.1</b> 距离判别</a></li>
<li class="chapter" data-level="7.5.2" data-path="ms_5.html"><a href="ms_5.html#ms_5_2"><i class="fa fa-check"></i><b>7.5.2</b> 贝叶斯判别</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ms_6.html"><a href="ms_6.html"><i class="fa fa-check"></i><b>7.6</b> 聚类分析</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="ms_6.html"><a href="ms_6.html#ms_6_1"><i class="fa fa-check"></i><b>7.6.1</b> 距离与相似性的度量</a></li>
<li class="chapter" data-level="7.6.2" data-path="ms_6.html"><a href="ms_6.html#ms_6_2"><i class="fa fa-check"></i><b>7.6.2</b> 聚类效果的评价指标</a></li>
<li class="chapter" data-level="7.6.3" data-path="ms_6.html"><a href="ms_6.html#ms_6_3"><i class="fa fa-check"></i><b>7.6.3</b> 系统聚类</a></li>
<li class="chapter" data-level="7.6.4" data-path="ms_6.html"><a href="ms_6.html#ms_6_4"><i class="fa fa-check"></i><b>7.6.4</b> Kmeans</a></li>
<li class="chapter" data-level="7.6.5" data-path="ms_6.html"><a href="ms_6.html#ms_6_5"><i class="fa fa-check"></i><b>7.6.5</b> 其他聚类方法</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ms_7.html"><a href="ms_7.html"><i class="fa fa-check"></i><b>7.7</b> 典型相关分析</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i><b>8</b> 机器学习</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ml_1.html"><a href="ml_1.html"><i class="fa fa-check"></i><b>8.1</b> 基础知识</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ml_1.html"><a href="ml_1.html#ml_1_1"><i class="fa fa-check"></i><b>8.1.1</b> 偏差-方差权衡</a></li>
<li class="chapter" data-level="8.1.2" data-path="ml_1.html"><a href="ml_1.html#ml_1_2"><i class="fa fa-check"></i><b>8.1.2</b> 评价指标</a></li>
<li class="chapter" data-level="8.1.3" data-path="ml_1.html"><a href="ml_1.html#ml_1_3"><i class="fa fa-check"></i><b>8.1.3</b> 特征工程</a></li>
<li class="chapter" data-level="8.1.4" data-path="ml_1.html"><a href="ml_1.html#ml_1_4"><i class="fa fa-check"></i><b>8.1.4</b> pandas与sklearn</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ml_2.html"><a href="ml_2.html"><i class="fa fa-check"></i><b>8.2</b> 决策树</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ml_2.html"><a href="ml_2.html#ml_2_1"><i class="fa fa-check"></i><b>8.2.1</b> 分类树</a></li>
<li class="chapter" data-level="8.2.2" data-path="ml_2.html"><a href="ml_2.html#ml_2_2"><i class="fa fa-check"></i><b>8.2.2</b> 回归树</a></li>
<li class="chapter" data-level="8.2.3" data-path="ml_2.html"><a href="ml_2.html#ml_2_3"><i class="fa fa-check"></i><b>8.2.3</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ml_3.html"><a href="ml_3.html"><i class="fa fa-check"></i><b>8.3</b> 随机森林</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ml_3.html"><a href="ml_3.html#ml_3_1"><i class="fa fa-check"></i><b>8.3.1</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ml_4.html"><a href="ml_4.html"><i class="fa fa-check"></i><b>8.4</b> XGBoost</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ml_4.html"><a href="ml_4.html#ml_4_1"><i class="fa fa-check"></i><b>8.4.1</b> 原理</a></li>
<li class="chapter" data-level="8.4.2" data-path="ml_4.html"><a href="ml_4.html#ml_4_2"><i class="fa fa-check"></i><b>8.4.2</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ml_5.html"><a href="ml_5.html"><i class="fa fa-check"></i><b>8.5</b> LightGBM</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="ml_5.html"><a href="ml_5.html#ml_5_1"><i class="fa fa-check"></i><b>8.5.1</b> 原理</a></li>
<li class="chapter" data-level="8.5.2" data-path="ml_5.html"><a href="ml_5.html#ml_5_2"><i class="fa fa-check"></i><b>8.5.2</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ml_6.html"><a href="ml_6.html"><i class="fa fa-check"></i><b>8.6</b> 因果森林</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="ml_6.html"><a href="ml_6.html#ml_6_1"><i class="fa fa-check"></i><b>8.6.1</b> 原理</a></li>
<li class="chapter" data-level="8.6.2" data-path="ml_6.html"><a href="ml_6.html#ml_6_2"><i class="fa fa-check"></i><b>8.6.2</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ml_7.html"><a href="ml_7.html"><i class="fa fa-check"></i><b>8.7</b> SVM</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="survival.html"><a href="survival.html"><i class="fa fa-check"></i><b>9</b> 生存分析</a>
<ul>
<li class="chapter" data-level="9.1" data-path="survival_1.html"><a href="survival_1.html"><i class="fa fa-check"></i><b>9.1</b> 基本概念</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="survival_1.html"><a href="survival_1.html#survival_1_1"><i class="fa fa-check"></i><b>9.1.1</b> 删失数据</a></li>
<li class="chapter" data-level="9.1.2" data-path="survival_1.html"><a href="survival_1.html#survival_1_2"><i class="fa fa-check"></i><b>9.1.2</b> 截断数据</a></li>
<li class="chapter" data-level="9.1.3" data-path="survival_1.html"><a href="survival_1.html#survival_1_3"><i class="fa fa-check"></i><b>9.1.3</b> 函数</a></li>
<li class="chapter" data-level="9.1.4" data-path="survival_1.html"><a href="survival_1.html#survival_1_4"><i class="fa fa-check"></i><b>9.1.4</b> 似然函数</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="survival_2.html"><a href="survival_2.html"><i class="fa fa-check"></i><b>9.2</b> 参数估计</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="survival_2.html"><a href="survival_2.html#survival_2_1"><i class="fa fa-check"></i><b>9.2.1</b> KM估计</a></li>
<li class="chapter" data-level="9.2.2" data-path="survival_2.html"><a href="survival_2.html#survival_2_2"><i class="fa fa-check"></i><b>9.2.2</b> NA估计</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="survival_3.html"><a href="survival_3.html"><i class="fa fa-check"></i><b>9.3</b> 置信区间与置信带</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="survival_3.html"><a href="survival_3.html#survival_3_1"><i class="fa fa-check"></i><b>9.3.1</b> 置信区间</a></li>
<li class="chapter" data-level="9.3.2" data-path="survival_3.html"><a href="survival_3.html#survival_3_2"><i class="fa fa-check"></i><b>9.3.2</b> 置信带</a></li>
<li class="chapter" data-level="9.3.3" data-path="survival_3.html"><a href="survival_3.html#survival_3_3"><i class="fa fa-check"></i><b>9.3.3</b> 平均生存时间的置信区间</a></li>
<li class="chapter" data-level="9.3.4" data-path="survival_3.html"><a href="survival_3.html#survival_3_4"><i class="fa fa-check"></i><b>9.3.4</b> 分位数的置信区间</a></li>
<li class="chapter" data-level="9.3.5" data-path="survival_3.html"><a href="survival_3.html#survival_3_5"><i class="fa fa-check"></i><b>9.3.5</b> 左截断数据的置信区间</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="survival_4.html"><a href="survival_4.html"><i class="fa fa-check"></i><b>9.4</b> 假设检验</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="survival_4.html"><a href="survival_4.html#survival_4_1"><i class="fa fa-check"></i><b>9.4.1</b> 单样本检验</a></li>
<li class="chapter" data-level="9.4.2" data-path="survival_4.html"><a href="survival_4.html#survival_4_2"><i class="fa fa-check"></i><b>9.4.2</b> 多样本检验</a></li>
<li class="chapter" data-level="9.4.3" data-path="survival_4.html"><a href="survival_4.html#survival_4_3"><i class="fa fa-check"></i><b>9.4.3</b> 趋势性检验</a></li>
<li class="chapter" data-level="9.4.4" data-path="survival_4.html"><a href="survival_4.html#survival_4_4"><i class="fa fa-check"></i><b>9.4.4</b> 分层检验</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="survival_5.html"><a href="survival_5.html"><i class="fa fa-check"></i><b>9.5</b> Cox比例风险模型</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="survival_5.html"><a href="survival_5.html#survival_5_1"><i class="fa fa-check"></i><b>9.5.1</b> 偏对数似然函数</a></li>
<li class="chapter" data-level="9.5.2" data-path="survival_5.html"><a href="survival_5.html#survival_5_x"><i class="fa fa-check"></i><b>9.5.2</b> Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="abtest.html"><a href="abtest.html"><i class="fa fa-check"></i><b>10</b> ABtest</a></li>
<li class="chapter" data-level="11" data-path="dl.html"><a href="dl.html"><i class="fa fa-check"></i><b>11</b> 深度学习</a>
<ul>
<li class="chapter" data-level="11.1" data-path="dl_1.html"><a href="dl_1.html"><i class="fa fa-check"></i><b>11.1</b> 预备知识</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="dl_1.html"><a href="dl_1.html#dl_1_1"><i class="fa fa-check"></i><b>11.1.1</b> 数据操作</a></li>
<li class="chapter" data-level="11.1.2" data-path="dl_1.html"><a href="dl_1.html#dl_1_2"><i class="fa fa-check"></i><b>11.1.2</b> 自动微分</a></li>
<li class="chapter" data-level="11.1.3" data-path="dl_1.html"><a href="dl_1.html#dl_1_3"><i class="fa fa-check"></i><b>11.1.3</b> 加载数据集</a></li>
<li class="chapter" data-level="11.1.4" data-path="dl_1.html"><a href="dl_1.html#dl_1_4"><i class="fa fa-check"></i><b>11.1.4</b> 调参技巧</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="dl_2.html"><a href="dl_2.html"><i class="fa fa-check"></i><b>11.2</b> 线性神经网络</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="dl_2.html"><a href="dl_2.html#dl_2_1"><i class="fa fa-check"></i><b>11.2.1</b> 线性回归</a></li>
<li class="chapter" data-level="11.2.2" data-path="dl_2.html"><a href="dl_2.html#dl_2_2"><i class="fa fa-check"></i><b>11.2.2</b> 二分类问题</a></li>
<li class="chapter" data-level="11.2.3" data-path="dl_2.html"><a href="dl_2.html#dl_2_3"><i class="fa fa-check"></i><b>11.2.3</b> 多分类问题</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="dl_3.html"><a href="dl_3.html"><i class="fa fa-check"></i><b>11.3</b> LSTM</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="dl_3.html"><a href="dl_3.html#dl_3_1"><i class="fa fa-check"></i><b>11.3.1</b> 原理</a></li>
<li class="chapter" data-level="11.3.2" data-path="dl_3.html"><a href="dl_3.html#dl_3_2"><i class="fa fa-check"></i><b>11.3.2</b> 示例</a></li>
<li class="chapter" data-level="11.3.3" data-path="dl_3.html"><a href="dl_3.html#dl_3_3"><i class="fa fa-check"></i><b>11.3.3</b> 拓展</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="dl_4.html"><a href="dl_4.html"><i class="fa fa-check"></i><b>11.4</b> GRU</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="dl_4.html"><a href="dl_4.html#dl_4_1"><i class="fa fa-check"></i><b>11.4.1</b> 原理</a></li>
<li class="chapter" data-level="11.4.2" data-path="dl_4.html"><a href="dl_4.html#dl_4_2"><i class="fa fa-check"></i><b>11.4.2</b> 示例</a></li>
<li class="chapter" data-level="11.4.3" data-path="dl_4.html"><a href="dl_4.html#dl_4_3"><i class="fa fa-check"></i><b>11.4.3</b> 拓展</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="dl_5.html"><a href="dl_5.html"><i class="fa fa-check"></i><b>11.5</b> BNN</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="dl_5.html"><a href="dl_5.html#dl_5_1"><i class="fa fa-check"></i><b>11.5.1</b> 原理</a></li>
<li class="chapter" data-level="11.5.2" data-path="dl_5.html"><a href="dl_5.html#dl_5_2"><i class="fa fa-check"></i><b>11.5.2</b> 示例</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="dl_6.html"><a href="dl_6.html"><i class="fa fa-check"></i><b>11.6</b> GNN</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="dl_6.html"><a href="dl_6.html#dl_6_1"><i class="fa fa-check"></i><b>11.6.1</b> 原理</a></li>
<li class="chapter" data-level="11.6.2" data-path="dl_6.html"><a href="dl_6.html#dl_6_2"><i class="fa fa-check"></i><b>11.6.2</b> 图神经网络的类型</a></li>
<li class="chapter" data-level="11.6.3" data-path="dl_6.html"><a href="dl_6.html#dl_6_3"><i class="fa fa-check"></i><b>11.6.3</b> 示例</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="dl_7.html"><a href="dl_7.html"><i class="fa fa-check"></i><b>11.7</b> Diffusion Model</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="dl_7.html"><a href="dl_7.html#dl_7_1"><i class="fa fa-check"></i><b>11.7.1</b> 原理</a></li>
<li class="chapter" data-level="11.7.2" data-path="dl_7.html"><a href="dl_7.html#dl_7_2"><i class="fa fa-check"></i><b>11.7.2</b> 示例</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 多源数据分析</b></span></li>
<li class="chapter" data-level="12" data-path="network.html"><a href="network.html"><i class="fa fa-check"></i><b>12</b> 网络型数据</a>
<ul>
<li class="chapter" data-level="12.1" data-path="network_1.html"><a href="network_1.html"><i class="fa fa-check"></i><b>12.1</b> 构造联系</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="network_1.html"><a href="network_1.html#network_1_1"><i class="fa fa-check"></i><b>12.1.1</b> 引力模型</a></li>
<li class="chapter" data-level="12.1.2" data-path="network_1.html"><a href="network_1.html#network_1_2"><i class="fa fa-check"></i><b>12.1.2</b> 社会网络量表</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="network_2.html"><a href="network_2.html"><i class="fa fa-check"></i><b>12.2</b> 网络结构特征</a></li>
<li class="chapter" data-level="12.3" data-path="network_3.html"><a href="network_3.html"><i class="fa fa-check"></i><b>12.3</b> 拓展分析</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="network_3.html"><a href="network_3.html#network_3_1"><i class="fa fa-check"></i><b>12.3.1</b> 凝聚子群</a></li>
<li class="chapter" data-level="12.3.2" data-path="network_3.html"><a href="network_3.html#network_3_2"><i class="fa fa-check"></i><b>12.3.2</b> 社区发现</a></li>
<li class="chapter" data-level="12.3.3" data-path="network_3.html"><a href="network_3.html#network_3_3"><i class="fa fa-check"></i><b>12.3.3</b> 核心-边缘分析</a></li>
<li class="chapter" data-level="12.3.4" data-path="network_3.html"><a href="network_3.html#network_3_4"><i class="fa fa-check"></i><b>12.3.4</b> QAP分析</a></li>
<li class="chapter" data-level="12.3.5" data-path="network_3.html"><a href="network_3.html#network_3_5"><i class="fa fa-check"></i><b>12.3.5</b> 计量模型</a></li>
<li class="chapter" data-level="12.3.6" data-path="network_3.html"><a href="network_3.html#network_3_6"><i class="fa fa-check"></i><b>12.3.6</b> 综合评价</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="network_4.html"><a href="network_4.html"><i class="fa fa-check"></i><b>12.4</b> 其他启示</a></li>
</ul></li>
<li class="part"><span><b>IV 可视化</b></span></li>
<li class="chapter" data-level="13" data-path="animation.html"><a href="animation.html"><i class="fa fa-check"></i><b>13</b> Manim动画</a>
<ul>
<li class="chapter" data-level="13.1" data-path="animation_1.html"><a href="animation_1.html"><i class="fa fa-check"></i><b>13.1</b> 最小二乘与投影矩阵</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="people.html"><a href="people.html"><i class="fa fa-check"></i><b>14</b> 七普数据可视化</a>
<ul>
<li class="chapter" data-level="14.1" data-path="people_1.html"><a href="people_1.html"><i class="fa fa-check"></i><b>14.1</b> 数据来源及说明</a></li>
<li class="chapter" data-level="14.2" data-path="people_2.html"><a href="people_2.html"><i class="fa fa-check"></i><b>14.2</b> 全国人口状况</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="people_2.html"><a href="people_2.html#people_2_1"><i class="fa fa-check"></i><b>14.2.1</b> 人口自然增长率</a></li>
<li class="chapter" data-level="14.2.2" data-path="people_2.html"><a href="people_2.html#people_2_2"><i class="fa fa-check"></i><b>14.2.2</b> 年龄结构</a></li>
<li class="chapter" data-level="14.2.3" data-path="people_2.html"><a href="people_2.html#people_2_3"><i class="fa fa-check"></i><b>14.2.3</b> 人口流动</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 组会论文</b></span></li>
<li class="chapter" data-level="15" data-path="penalty.html"><a href="penalty.html"><i class="fa fa-check"></i><b>15</b> 变量选择与惩罚函数</a>
<ul>
<li class="chapter" data-level="15.1" data-path="penalty_1.html"><a href="penalty_1.html"><i class="fa fa-check"></i><b>15.1</b> 准备</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="penalty_1.html"><a href="penalty_1.html#penalty_1_1"><i class="fa fa-check"></i><b>15.1.1</b> 范数</a></li>
<li class="chapter" data-level="15.1.2" data-path="penalty_1.html"><a href="penalty_1.html#penalty_1_2"><i class="fa fa-check"></i><b>15.1.2</b> 目标函数</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="penalty_2.html"><a href="penalty_2.html"><i class="fa fa-check"></i><b>15.2</b> 单变量选择</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_1"><i class="fa fa-check"></i><b>15.2.1</b> Lasso</a></li>
<li class="chapter" data-level="15.2.2" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_2"><i class="fa fa-check"></i><b>15.2.2</b> Hard &amp; Soft Threshold</a></li>
<li class="chapter" data-level="15.2.3" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_3"><i class="fa fa-check"></i><b>15.2.3</b> SCAD</a></li>
<li class="chapter" data-level="15.2.4" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_4"><i class="fa fa-check"></i><b>15.2.4</b> Adaptive Lasso</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="penalty_3.html"><a href="penalty_3.html"><i class="fa fa-check"></i><b>15.3</b> 群组变量选择</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_1"><i class="fa fa-check"></i><b>15.3.1</b> 思维导图</a></li>
<li class="chapter" data-level="15.3.2" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_2"><i class="fa fa-check"></i><b>15.3.2</b> 处理高度相关数据的组变量选择方法</a></li>
<li class="chapter" data-level="15.3.3" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_3"><i class="fa fa-check"></i><b>15.3.3</b> 仅能选择组变量的方法</a></li>
<li class="chapter" data-level="15.3.4" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_4"><i class="fa fa-check"></i><b>15.3.4</b> 双层变量选择方法</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="penalty_4.html"><a href="penalty_4.html"><i class="fa fa-check"></i><b>15.4</b> 算法</a></li>
<li class="chapter" data-level="15.5" data-path="penalty_5.html"><a href="penalty_5.html"><i class="fa fa-check"></i><b>15.5</b> 总结</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="integrative.html"><a href="integrative.html"><i class="fa fa-check"></i><b>16</b> 整合分析</a>
<ul>
<li class="chapter" data-level="16.1" data-path="integrative_1.html"><a href="integrative_1.html"><i class="fa fa-check"></i><b>16.1</b> 引言</a></li>
<li class="chapter" data-level="16.2" data-path="integrative_2.html"><a href="integrative_2.html"><i class="fa fa-check"></i><b>16.2</b> 模型基本形式</a></li>
<li class="chapter" data-level="16.3" data-path="integrative_3.html"><a href="integrative_3.html"><i class="fa fa-check"></i><b>16.3</b> 同构数据的整合分析</a></li>
<li class="chapter" data-level="16.4" data-path="integrative_4.html"><a href="integrative_4.html"><i class="fa fa-check"></i><b>16.4</b> 异构数据的整合分析</a></li>
<li class="chapter" data-level="16.5" data-path="integrative_5.html"><a href="integrative_5.html"><i class="fa fa-check"></i><b>16.5</b> 具有网络结构关系的整合分析</a></li>
</ul></li>
<li class="part"><span><b>VI 算法复现</b></span></li>
<li class="chapter" data-level="17" data-path="code.html"><a href="code.html"><i class="fa fa-check"></i><b>17</b> 算法复现</a>
<ul>
<li class="chapter" data-level="17.1" data-path="code_1.html"><a href="code_1.html"><i class="fa fa-check"></i><b>17.1</b> 惩罚Cox比例风险模型</a></li>
<li class="chapter" data-level="17.2" data-path="code_2.html"><a href="code_2.html"><i class="fa fa-check"></i><b>17.2</b> 异质截距项的线性模型</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="code_2.html"><a href="code_2.html#code_2_1"><i class="fa fa-check"></i><b>17.2.1</b> 自定义算法</a></li>
<li class="chapter" data-level="17.2.2" data-path="code_2.html"><a href="code_2.html#code_2_2"><i class="fa fa-check"></i><b>17.2.2</b> 数据模拟</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="code_3.html"><a href="code_3.html"><i class="fa fa-check"></i><b>17.3</b> （异质）线性+非线性的Cox比例风险模型</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="code_3.html"><a href="code_3.html#code_3_1"><i class="fa fa-check"></i><b>17.3.1</b> 自定义算法</a></li>
<li class="chapter" data-level="17.3.2" data-path="code_3.html"><a href="code_3.html#code_3_2"><i class="fa fa-check"></i><b>17.3.2</b> 数据模拟</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VII 生活</b></span></li>
<li class="chapter" data-level="18" data-path="ball.html"><a href="ball.html"><i class="fa fa-check"></i><b>18</b> 羽毛球修炼手册</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ball_1.html"><a href="ball_1.html"><i class="fa fa-check"></i><b>18.1</b> 发球</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="ball_1.html"><a href="ball_1.html#ball_1_1"><i class="fa fa-check"></i><b>18.1.1</b> 正手发球</a></li>
<li class="chapter" data-level="18.1.2" data-path="ball_1.html"><a href="ball_1.html#ball_1_2"><i class="fa fa-check"></i><b>18.1.2</b> 反手发球</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ball_2.html"><a href="ball_2.html"><i class="fa fa-check"></i><b>18.2</b> 网前技术</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="ball_2.html"><a href="ball_2.html#ball_2_1"><i class="fa fa-check"></i><b>18.2.1</b> 勾对角</a></li>
<li class="chapter" data-level="18.2.2" data-path="ball_2.html"><a href="ball_2.html#ball_2_2"><i class="fa fa-check"></i><b>18.2.2</b> 扑球</a></li>
<li class="chapter" data-level="18.2.3" data-path="ball_2.html"><a href="ball_2.html#ball_2_3"><i class="fa fa-check"></i><b>18.2.3</b> 封网</a></li>
<li class="chapter" data-level="18.2.4" data-path="ball_2.html"><a href="ball_2.html#ball_2_4"><i class="fa fa-check"></i><b>18.2.4</b> 平抽</a></li>
<li class="chapter" data-level="18.2.5" data-path="ball_2.html"><a href="ball_2.html#ball_2_5"><i class="fa fa-check"></i><b>18.2.5</b> 抹球</a></li>
<li class="chapter" data-level="18.2.6" data-path="ball_2.html"><a href="ball_2.html#ball_2_6"><i class="fa fa-check"></i><b>18.2.6</b> 搓球</a></li>
<li class="chapter" data-level="18.2.7" data-path="ball_2.html"><a href="ball_2.html#ball_2_7"><i class="fa fa-check"></i><b>18.2.7</b> 挡网</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="ball_3.html"><a href="ball_3.html"><i class="fa fa-check"></i><b>18.3</b> 后场技术</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="ball_3.html"><a href="ball_3.html#ball_3_1"><i class="fa fa-check"></i><b>18.3.1</b> 杀球</a></li>
<li class="chapter" data-level="18.3.2" data-path="ball_3.html"><a href="ball_3.html#ball_3_2"><i class="fa fa-check"></i><b>18.3.2</b> 吊球</a></li>
<li class="chapter" data-level="18.3.3" data-path="ball_3.html"><a href="ball_3.html#ball_3_3"><i class="fa fa-check"></i><b>18.3.3</b> 反手</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="ball_4.html"><a href="ball_4.html"><i class="fa fa-check"></i><b>18.4</b> 假动作</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="ball_4.html"><a href="ball_4.html#ball_4_1"><i class="fa fa-check"></i><b>18.4.1</b> 发接发</a></li>
<li class="chapter" data-level="18.4.2" data-path="ball_4.html"><a href="ball_4.html#ball_4_2"><i class="fa fa-check"></i><b>18.4.2</b> 网前</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="ball_5.html"><a href="ball_5.html"><i class="fa fa-check"></i><b>18.5</b> 双打</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="ball_5.html"><a href="ball_5.html#ball_5_1"><i class="fa fa-check"></i><b>18.5.1</b> 发接发</a></li>
<li class="chapter" data-level="18.5.2" data-path="ball_5.html"><a href="ball_5.html#ball_5_2"><i class="fa fa-check"></i><b>18.5.2</b> 站位</a></li>
<li class="chapter" data-level="18.5.3" data-path="ball_5.html"><a href="ball_5.html#ball_5_3"><i class="fa fa-check"></i><b>18.5.3</b> 分球</a></li>
<li class="chapter" data-level="18.5.4" data-path="ball_5.html"><a href="ball_5.html#ball_5_4"><i class="fa fa-check"></i><b>18.5.4</b> 球路</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="ball_6.html"><a href="ball_6.html"><i class="fa fa-check"></i><b>18.6</b> 球路</a></li>
<li class="chapter" data-level="18.7" data-path="ball_7.html"><a href="ball_7.html"><i class="fa fa-check"></i><b>18.7</b> 步伐</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="jap.html"><a href="jap.html"><i class="fa fa-check"></i><b>19</b> 日语</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><i class="fa fa-check"></i>参考文献</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">kj的学习笔记</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dl_2" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> 线性神经网络<a href="dl_2.html#dl_2" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h2>
<div id="dl_2_1" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> 线性回归<a href="dl_2.html#dl_2_1" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h3>
<p><code>nn.Linear</code>是线性层，对输入数据进行仿射变换<span class="math inline">\(y=XW^T+b\)</span>，其中<span class="math inline">\(W\)</span>是权重矩阵，<span class="math inline">\(b\)</span>是偏置。</p>
<p>对于简单的线性回归模型，故只需一层线性层即可。</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb324-1"><a href="dl_2.html#cb324-1" tabindex="-1"></a>import torch</span>
<span id="cb324-2"><a href="dl_2.html#cb324-2" tabindex="-1"></a>import torch.nn as nn</span>
<span id="cb324-3"><a href="dl_2.html#cb324-3" tabindex="-1"></a>import torch.optim as optim</span>
<span id="cb324-4"><a href="dl_2.html#cb324-4" tabindex="-1"></a>from torch.utils.data import TensorDataset, DataLoader</span>
<span id="cb324-5"><a href="dl_2.html#cb324-5" tabindex="-1"></a></span>
<span id="cb324-6"><a href="dl_2.html#cb324-6" tabindex="-1"></a>torch.manual_seed(123)   # 设置全局随机数种子</span>
<span id="cb324-7"><a href="dl_2.html#cb324-7" tabindex="-1"></a></span>
<span id="cb324-8"><a href="dl_2.html#cb324-8" tabindex="-1"></a>X = torch.randn(100,2)   # 标准正态抽样</span>
<span id="cb324-9"><a href="dl_2.html#cb324-9" tabindex="-1"></a>beta = torch.rand(2)     # 均匀分布[0,1)抽样</span>
<span id="cb324-10"><a href="dl_2.html#cb324-10" tabindex="-1"></a>intercept = torch.rand(1)</span>
<span id="cb324-11"><a href="dl_2.html#cb324-11" tabindex="-1"></a>y = intercept + torch.matmul(X, beta) + torch.randn(100)*0.1</span>
<span id="cb324-12"><a href="dl_2.html#cb324-12" tabindex="-1"></a>y = y.reshape(-1,1)</span>
<span id="cb324-13"><a href="dl_2.html#cb324-13" tabindex="-1"></a></span>
<span id="cb324-14"><a href="dl_2.html#cb324-14" tabindex="-1"></a>dataset = TensorDataset(X,y)</span>
<span id="cb324-15"><a href="dl_2.html#cb324-15" tabindex="-1"></a>dataloader = DataLoader(dataset, batch_size=10, shuffle=True)</span>
<span id="cb324-16"><a href="dl_2.html#cb324-16" tabindex="-1"></a></span>
<span id="cb324-17"><a href="dl_2.html#cb324-17" tabindex="-1"></a># 搭建网络结构</span>
<span id="cb324-18"><a href="dl_2.html#cb324-18" tabindex="-1"></a>linear_model = nn.Sequential(</span>
<span id="cb324-19"><a href="dl_2.html#cb324-19" tabindex="-1"></a>    nn.Linear(2,1)</span>
<span id="cb324-20"><a href="dl_2.html#cb324-20" tabindex="-1"></a>)</span>
<span id="cb324-21"><a href="dl_2.html#cb324-21" tabindex="-1"></a></span>
<span id="cb324-22"><a href="dl_2.html#cb324-22" tabindex="-1"></a>criterion = nn.MSELoss()</span>
<span id="cb324-23"><a href="dl_2.html#cb324-23" tabindex="-1"></a>optimizer = optim.SGD(linear_model.parameters(), lr=0.05)   # lr为学习率</span>
<span id="cb324-24"><a href="dl_2.html#cb324-24" tabindex="-1"></a></span>
<span id="cb324-25"><a href="dl_2.html#cb324-25" tabindex="-1"></a>for epoch in range(100):       # 迭代50次</span>
<span id="cb324-26"><a href="dl_2.html#cb324-26" tabindex="-1"></a>    linear_model.train()       # 训练模式</span>
<span id="cb324-27"><a href="dl_2.html#cb324-27" tabindex="-1"></a>    for batch_X, batch_y in dataloader:</span>
<span id="cb324-28"><a href="dl_2.html#cb324-28" tabindex="-1"></a>        y_pred = linear_model(batch_X)     # 前向传播，计算预测值</span>
<span id="cb324-29"><a href="dl_2.html#cb324-29" tabindex="-1"></a>        loss = criterion(y_pred, batch_y)  # 计算损失</span>
<span id="cb324-30"><a href="dl_2.html#cb324-30" tabindex="-1"></a>        optimizer.zero_grad()  # 清零梯度</span>
<span id="cb324-31"><a href="dl_2.html#cb324-31" tabindex="-1"></a>        loss.backward()        # 反向传播，计算梯度</span>
<span id="cb324-32"><a href="dl_2.html#cb324-32" tabindex="-1"></a>        optimizer.step()       # 更新模型参数</span>
<span id="cb324-33"><a href="dl_2.html#cb324-33" tabindex="-1"></a>    linear_model.eval()        # 评估模式</span>
<span id="cb324-34"><a href="dl_2.html#cb324-34" tabindex="-1"></a>    with torch.no_grad():</span>
<span id="cb324-35"><a href="dl_2.html#cb324-35" tabindex="-1"></a>        epoch_loss = criterion(linear_model(X),y)</span>
<span id="cb324-36"><a href="dl_2.html#cb324-36" tabindex="-1"></a>        if (epoch + 1) % 10 == 0:</span>
<span id="cb324-37"><a href="dl_2.html#cb324-37" tabindex="-1"></a>            print(f&#39;Epoch_{epoch + 1}: {epoch_loss.item():.6f}&#39;)</span>
<span id="cb324-38"><a href="dl_2.html#cb324-38" tabindex="-1"></a></span>
<span id="cb324-39"><a href="dl_2.html#cb324-39" tabindex="-1"></a>print(linear_model)                  # 查看网络结构</span>
<span id="cb324-40"><a href="dl_2.html#cb324-40" tabindex="-1"></a>print(linear_model[0].weight.data)   # 查看第0层的权重</span>
<span id="cb324-41"><a href="dl_2.html#cb324-41" tabindex="-1"></a>print(linear_model[0].bias.data)     # 查看第0层的偏置</span></code></pre></div>
<p>说明：</p>
<ol style="list-style-type: decimal">
<li><p><code>DataLoader()</code>将数据分批次，变为可迭代的对象，每次返回一个批次的数据。也可结合<code>enumerate()</code>适用。</p></li>
<li><p><code>nn.Sequential()</code><strong>按顺序</strong>组织多个神经网络层，相较自定义类无需定义<code>forward</code>方法，适用于简单场合的模型构建。</p></li>
</ol>
<blockquote>
<p>除了<code>nn.Sequential()</code>，还可以通过继承<code>nn.Module</code>来自定义模型架构，从而创建更复杂的模型</p>
</blockquote>
<ol start="3" style="list-style-type: decimal">
<li><p><code>nn.Linear()</code>是线性全连接层，用来实现仿射变换<span class="math inline">\(y=XW^T+b\)</span>。</p></li>
<li><p><code>nn.MSELoss()</code>定义了损失函数的类型，计算两个形状相同的张量之间的MSE</p></li>
<li><p><code>optim.SGD()</code>定义了优化算法为随机梯度下降法，<code>linear_model.parameters()</code>用于传递需要优化的参数。</p></li>
<li><p><code>.train()</code>、<code>.eval()</code>分别代表模型的训练模式和评估模式，不同模式下会影响部分层(如Dropout层)的行为，一般在训练时开始<code>.train()</code>，在计算相关指标时<code>.eval()</code>。特别的，在评估时还可配合<code>torch.no_grad()</code>来禁用梯度计算，节省内存和计算资源，从而提高计算速度。</p></li>
</ol>
</div>
<div id="dl_2_2" class="section level3 hasAnchor" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> 二分类问题<a href="dl_2.html#dl_2_2" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h3>
<p>对于二分类问题，输出层的维度应该为1，并且输出层的激活函数为Sigmoid函数，损失函数为<code>nn.BCELoss()</code>等适用于二分类场合的函数。</p>
<blockquote>
<p><code>nn.BCELoss()</code>即<span class="math inline">\(-y_i \log \hat y_i - (1-y_i)\log (1-\hat y_i)\)</span></p>
</blockquote>
<div class="sourceCode" id="cb325"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb325-1"><a href="dl_2.html#cb325-1" tabindex="-1"></a>import torch</span>
<span id="cb325-2"><a href="dl_2.html#cb325-2" tabindex="-1"></a>import torch.nn as nn</span>
<span id="cb325-3"><a href="dl_2.html#cb325-3" tabindex="-1"></a>import torch.optim as optim</span>
<span id="cb325-4"><a href="dl_2.html#cb325-4" tabindex="-1"></a>from sklearn.datasets import make_classification</span>
<span id="cb325-5"><a href="dl_2.html#cb325-5" tabindex="-1"></a>from sklearn.model_selection import train_test_split</span>
<span id="cb325-6"><a href="dl_2.html#cb325-6" tabindex="-1"></a>from sklearn.preprocessing import StandardScaler</span>
<span id="cb325-7"><a href="dl_2.html#cb325-7" tabindex="-1"></a>import numpy as np</span>
<span id="cb325-8"><a href="dl_2.html#cb325-8" tabindex="-1"></a>from torch.utils.data import TensorDataset, DataLoader</span>
<span id="cb325-9"><a href="dl_2.html#cb325-9" tabindex="-1"></a></span>
<span id="cb325-10"><a href="dl_2.html#cb325-10" tabindex="-1"></a># 设置随机数种子</span>
<span id="cb325-11"><a href="dl_2.html#cb325-11" tabindex="-1"></a>torch.manual_seed(123)</span>
<span id="cb325-12"><a href="dl_2.html#cb325-12" tabindex="-1"></a>np.random.seed(321)</span>
<span id="cb325-13"><a href="dl_2.html#cb325-13" tabindex="-1"></a></span>
<span id="cb325-14"><a href="dl_2.html#cb325-14" tabindex="-1"></a>def gen_data(n_samples=2000, n_features=10, n_classes=2):</span>
<span id="cb325-15"><a href="dl_2.html#cb325-15" tabindex="-1"></a></span>
<span id="cb325-16"><a href="dl_2.html#cb325-16" tabindex="-1"></a>    # 生成复杂的分类型数据（有重叠）</span>
<span id="cb325-17"><a href="dl_2.html#cb325-17" tabindex="-1"></a>    X, y = make_classification(</span>
<span id="cb325-18"><a href="dl_2.html#cb325-18" tabindex="-1"></a>        n_samples=n_samples,    # 样本数</span>
<span id="cb325-19"><a href="dl_2.html#cb325-19" tabindex="-1"></a>        n_features=n_features,  # 特征数</span>
<span id="cb325-20"><a href="dl_2.html#cb325-20" tabindex="-1"></a>        n_informative=8,        # 有信息量的特征数量</span>
<span id="cb325-21"><a href="dl_2.html#cb325-21" tabindex="-1"></a>        n_redundant=2,          # 冗余特征数量</span>
<span id="cb325-22"><a href="dl_2.html#cb325-22" tabindex="-1"></a>        n_repeated=0,           # 重复特征数量</span>
<span id="cb325-23"><a href="dl_2.html#cb325-23" tabindex="-1"></a>        n_classes=n_classes,    # 类别数</span>
<span id="cb325-24"><a href="dl_2.html#cb325-24" tabindex="-1"></a>        flip_y=0.15,            # 15%的噪声</span>
<span id="cb325-25"><a href="dl_2.html#cb325-25" tabindex="-1"></a>        class_sep=0.8           # 类间分离程度</span>
<span id="cb325-26"><a href="dl_2.html#cb325-26" tabindex="-1"></a>    )</span>
<span id="cb325-27"><a href="dl_2.html#cb325-27" tabindex="-1"></a>    </span>
<span id="cb325-28"><a href="dl_2.html#cb325-28" tabindex="-1"></a>    # 划分训练集和测试集</span>
<span id="cb325-29"><a href="dl_2.html#cb325-29" tabindex="-1"></a>    X_train, X_test, y_train, y_test = train_test_split(</span>
<span id="cb325-30"><a href="dl_2.html#cb325-30" tabindex="-1"></a>        X, y, test_size=0.2, random_state=42</span>
<span id="cb325-31"><a href="dl_2.html#cb325-31" tabindex="-1"></a>    )</span>
<span id="cb325-32"><a href="dl_2.html#cb325-32" tabindex="-1"></a>    </span>
<span id="cb325-33"><a href="dl_2.html#cb325-33" tabindex="-1"></a>    # 数据标准化</span>
<span id="cb325-34"><a href="dl_2.html#cb325-34" tabindex="-1"></a>    scaler = StandardScaler()</span>
<span id="cb325-35"><a href="dl_2.html#cb325-35" tabindex="-1"></a>    X_train = scaler.fit_transform(X_train)</span>
<span id="cb325-36"><a href="dl_2.html#cb325-36" tabindex="-1"></a>    X_test = scaler.transform(X_test)</span>
<span id="cb325-37"><a href="dl_2.html#cb325-37" tabindex="-1"></a></span>
<span id="cb325-38"><a href="dl_2.html#cb325-38" tabindex="-1"></a>    # 转换为PyTorch张量</span>
<span id="cb325-39"><a href="dl_2.html#cb325-39" tabindex="-1"></a>    X_train = torch.tensor(X_train, dtype=torch.float32)</span>
<span id="cb325-40"><a href="dl_2.html#cb325-40" tabindex="-1"></a>    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # 二分类需要二维标签</span>
<span id="cb325-41"><a href="dl_2.html#cb325-41" tabindex="-1"></a>    X_test = torch.tensor(X_test, dtype=torch.float32)</span>
<span id="cb325-42"><a href="dl_2.html#cb325-42" tabindex="-1"></a>    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)</span>
<span id="cb325-43"><a href="dl_2.html#cb325-43" tabindex="-1"></a>    </span>
<span id="cb325-44"><a href="dl_2.html#cb325-44" tabindex="-1"></a>    return X_train, X_test, y_train, y_test</span>
<span id="cb325-45"><a href="dl_2.html#cb325-45" tabindex="-1"></a></span>
<span id="cb325-46"><a href="dl_2.html#cb325-46" tabindex="-1"></a># 生成数据</span>
<span id="cb325-47"><a href="dl_2.html#cb325-47" tabindex="-1"></a>X_train, X_test, y_train, y_test = gen_data()</span>
<span id="cb325-48"><a href="dl_2.html#cb325-48" tabindex="-1"></a></span>
<span id="cb325-49"><a href="dl_2.html#cb325-49" tabindex="-1"></a># 创建数据加载器</span>
<span id="cb325-50"><a href="dl_2.html#cb325-50" tabindex="-1"></a>train_dataset = TensorDataset(X_train, y_train)</span>
<span id="cb325-51"><a href="dl_2.html#cb325-51" tabindex="-1"></a>test_dataset = TensorDataset(X_test, y_test)</span>
<span id="cb325-52"><a href="dl_2.html#cb325-52" tabindex="-1"></a></span>
<span id="cb325-53"><a href="dl_2.html#cb325-53" tabindex="-1"></a>train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)</span>
<span id="cb325-54"><a href="dl_2.html#cb325-54" tabindex="-1"></a>test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)</span>
<span id="cb325-55"><a href="dl_2.html#cb325-55" tabindex="-1"></a></span>
<span id="cb325-56"><a href="dl_2.html#cb325-56" tabindex="-1"></a>model = nn.Sequential(</span>
<span id="cb325-57"><a href="dl_2.html#cb325-57" tabindex="-1"></a>    nn.Linear(10,64),</span>
<span id="cb325-58"><a href="dl_2.html#cb325-58" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb325-59"><a href="dl_2.html#cb325-59" tabindex="-1"></a>    nn.BatchNorm1d(64),  # 对该批次数据进行标准化操作，并进行缩放和平移，可在一定程度上缓解“内部协变量偏移”情况</span>
<span id="cb325-60"><a href="dl_2.html#cb325-60" tabindex="-1"></a>    nn.Dropout(0.2),     # 以一定概率丢弃某些神经元，从而缓解过拟合现象</span>
<span id="cb325-61"><a href="dl_2.html#cb325-61" tabindex="-1"></a>    </span>
<span id="cb325-62"><a href="dl_2.html#cb325-62" tabindex="-1"></a>    nn.Linear(64,32),</span>
<span id="cb325-63"><a href="dl_2.html#cb325-63" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb325-64"><a href="dl_2.html#cb325-64" tabindex="-1"></a>    nn.BatchNorm1d(32),</span>
<span id="cb325-65"><a href="dl_2.html#cb325-65" tabindex="-1"></a>    nn.Dropout(0.2),</span>
<span id="cb325-66"><a href="dl_2.html#cb325-66" tabindex="-1"></a>    </span>
<span id="cb325-67"><a href="dl_2.html#cb325-67" tabindex="-1"></a>    nn.Linear(32,1),</span>
<span id="cb325-68"><a href="dl_2.html#cb325-68" tabindex="-1"></a>    nn.Sigmoid()</span>
<span id="cb325-69"><a href="dl_2.html#cb325-69" tabindex="-1"></a>)</span>
<span id="cb325-70"><a href="dl_2.html#cb325-70" tabindex="-1"></a></span>
<span id="cb325-71"><a href="dl_2.html#cb325-71" tabindex="-1"></a>criterion = nn.BCELoss()</span>
<span id="cb325-72"><a href="dl_2.html#cb325-72" tabindex="-1"></a>optimizer = optim.SGD(model.parameters(), lr=0.05)</span>
<span id="cb325-73"><a href="dl_2.html#cb325-73" tabindex="-1"></a></span>
<span id="cb325-74"><a href="dl_2.html#cb325-74" tabindex="-1"></a># 将模型移到GPU上</span>
<span id="cb325-75"><a href="dl_2.html#cb325-75" tabindex="-1"></a>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
<span id="cb325-76"><a href="dl_2.html#cb325-76" tabindex="-1"></a>model.to(device)</span>
<span id="cb325-77"><a href="dl_2.html#cb325-77" tabindex="-1"></a></span>
<span id="cb325-78"><a href="dl_2.html#cb325-78" tabindex="-1"></a># 存储训练指标</span>
<span id="cb325-79"><a href="dl_2.html#cb325-79" tabindex="-1"></a>train_losses = []</span>
<span id="cb325-80"><a href="dl_2.html#cb325-80" tabindex="-1"></a>train_accuracies = []</span>
<span id="cb325-81"><a href="dl_2.html#cb325-81" tabindex="-1"></a>val_losses = []</span>
<span id="cb325-82"><a href="dl_2.html#cb325-82" tabindex="-1"></a>val_accuracies = []</span>
<span id="cb325-83"><a href="dl_2.html#cb325-83" tabindex="-1"></a></span>
<span id="cb325-84"><a href="dl_2.html#cb325-84" tabindex="-1"></a>for epoch in range(100):</span>
<span id="cb325-85"><a href="dl_2.html#cb325-85" tabindex="-1"></a>    # 训练模式</span>
<span id="cb325-86"><a href="dl_2.html#cb325-86" tabindex="-1"></a>    model.train()</span>
<span id="cb325-87"><a href="dl_2.html#cb325-87" tabindex="-1"></a>    running_loss = 0.0</span>
<span id="cb325-88"><a href="dl_2.html#cb325-88" tabindex="-1"></a>    correct_train = 0</span>
<span id="cb325-89"><a href="dl_2.html#cb325-89" tabindex="-1"></a>    total_train = 0</span>
<span id="cb325-90"><a href="dl_2.html#cb325-90" tabindex="-1"></a>    </span>
<span id="cb325-91"><a href="dl_2.html#cb325-91" tabindex="-1"></a>    for batch_x, batch_y in train_loader:</span>
<span id="cb325-92"><a href="dl_2.html#cb325-92" tabindex="-1"></a>        # 移动数据到设备</span>
<span id="cb325-93"><a href="dl_2.html#cb325-93" tabindex="-1"></a>        batch_x, batch_y = batch_x.to(device), batch_y.to(device)</span>
<span id="cb325-94"><a href="dl_2.html#cb325-94" tabindex="-1"></a>        </span>
<span id="cb325-95"><a href="dl_2.html#cb325-95" tabindex="-1"></a>        # 前向传播</span>
<span id="cb325-96"><a href="dl_2.html#cb325-96" tabindex="-1"></a>        outputs = model(batch_x)</span>
<span id="cb325-97"><a href="dl_2.html#cb325-97" tabindex="-1"></a>        </span>
<span id="cb325-98"><a href="dl_2.html#cb325-98" tabindex="-1"></a>        # 计算损失</span>
<span id="cb325-99"><a href="dl_2.html#cb325-99" tabindex="-1"></a>        loss = criterion(outputs, batch_y)</span>
<span id="cb325-100"><a href="dl_2.html#cb325-100" tabindex="-1"></a>        </span>
<span id="cb325-101"><a href="dl_2.html#cb325-101" tabindex="-1"></a>        # 反向传播和优化</span>
<span id="cb325-102"><a href="dl_2.html#cb325-102" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb325-103"><a href="dl_2.html#cb325-103" tabindex="-1"></a>        loss.backward()</span>
<span id="cb325-104"><a href="dl_2.html#cb325-104" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb325-105"><a href="dl_2.html#cb325-105" tabindex="-1"></a>        </span>
<span id="cb325-106"><a href="dl_2.html#cb325-106" tabindex="-1"></a>        # 统计训练情况</span>
<span id="cb325-107"><a href="dl_2.html#cb325-107" tabindex="-1"></a>        running_loss += loss.item()</span>
<span id="cb325-108"><a href="dl_2.html#cb325-108" tabindex="-1"></a>        </span>
<span id="cb325-109"><a href="dl_2.html#cb325-109" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb325-110"><a href="dl_2.html#cb325-110" tabindex="-1"></a>        predictions = (outputs &gt; 0.5).float()</span>
<span id="cb325-111"><a href="dl_2.html#cb325-111" tabindex="-1"></a>        correct_train += (predictions == batch_y).sum().item()</span>
<span id="cb325-112"><a href="dl_2.html#cb325-112" tabindex="-1"></a>        total_train += batch_y.size(0)</span>
<span id="cb325-113"><a href="dl_2.html#cb325-113" tabindex="-1"></a>    </span>
<span id="cb325-114"><a href="dl_2.html#cb325-114" tabindex="-1"></a>    # 计算本轮训练的平均损失和准确率</span>
<span id="cb325-115"><a href="dl_2.html#cb325-115" tabindex="-1"></a>    epoch_loss = running_loss / len(train_loader)</span>
<span id="cb325-116"><a href="dl_2.html#cb325-116" tabindex="-1"></a>    epoch_acc = correct_train / total_train if total_train &gt; 0 else 0</span>
<span id="cb325-117"><a href="dl_2.html#cb325-117" tabindex="-1"></a>    train_losses.append(epoch_loss)</span>
<span id="cb325-118"><a href="dl_2.html#cb325-118" tabindex="-1"></a>    train_accuracies.append(epoch_acc)</span>
<span id="cb325-119"><a href="dl_2.html#cb325-119" tabindex="-1"></a>    </span>
<span id="cb325-120"><a href="dl_2.html#cb325-120" tabindex="-1"></a>    # 验证评估</span>
<span id="cb325-121"><a href="dl_2.html#cb325-121" tabindex="-1"></a>    model.eval()</span>
<span id="cb325-122"><a href="dl_2.html#cb325-122" tabindex="-1"></a>    with torch.no_grad():</span>
<span id="cb325-123"><a href="dl_2.html#cb325-123" tabindex="-1"></a>        # 移动测试数据到设备</span>
<span id="cb325-124"><a href="dl_2.html#cb325-124" tabindex="-1"></a>        test_x, test_y = X_test.to(device), y_test.to(device)</span>
<span id="cb325-125"><a href="dl_2.html#cb325-125" tabindex="-1"></a>        # 前向传播</span>
<span id="cb325-126"><a href="dl_2.html#cb325-126" tabindex="-1"></a>        outputs = model(test_x)</span>
<span id="cb325-127"><a href="dl_2.html#cb325-127" tabindex="-1"></a>        # 计算损失</span>
<span id="cb325-128"><a href="dl_2.html#cb325-128" tabindex="-1"></a>        val_loss = criterion(outputs, test_y).item()</span>
<span id="cb325-129"><a href="dl_2.html#cb325-129" tabindex="-1"></a>        # 计算预测结果</span>
<span id="cb325-130"><a href="dl_2.html#cb325-130" tabindex="-1"></a>        predictions = (outputs &gt; 0.5).float()</span>
<span id="cb325-131"><a href="dl_2.html#cb325-131" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb325-132"><a href="dl_2.html#cb325-132" tabindex="-1"></a>        correct_val = (predictions == test_y).sum().item()</span>
<span id="cb325-133"><a href="dl_2.html#cb325-133" tabindex="-1"></a>        total_val = test_y.size(0)</span>
<span id="cb325-134"><a href="dl_2.html#cb325-134" tabindex="-1"></a>        val_acc = correct_val / total_val</span>
<span id="cb325-135"><a href="dl_2.html#cb325-135" tabindex="-1"></a>        # 存储验证结果</span>
<span id="cb325-136"><a href="dl_2.html#cb325-136" tabindex="-1"></a>        val_losses.append(val_loss)</span>
<span id="cb325-137"><a href="dl_2.html#cb325-137" tabindex="-1"></a>        val_accuracies.append(val_acc)</span>
<span id="cb325-138"><a href="dl_2.html#cb325-138" tabindex="-1"></a>    </span>
<span id="cb325-139"><a href="dl_2.html#cb325-139" tabindex="-1"></a>    # 每10个epoch打印一次进度</span>
<span id="cb325-140"><a href="dl_2.html#cb325-140" tabindex="-1"></a>    if (epoch + 1) % 10 == 0:</span>
<span id="cb325-141"><a href="dl_2.html#cb325-141" tabindex="-1"></a>        print(&quot;=&quot;*10,</span>
<span id="cb325-142"><a href="dl_2.html#cb325-142" tabindex="-1"></a>              f&quot;Epoch_{epoch+1}&quot;,</span>
<span id="cb325-143"><a href="dl_2.html#cb325-143" tabindex="-1"></a>              &quot;=&quot;*10,</span>
<span id="cb325-144"><a href="dl_2.html#cb325-144" tabindex="-1"></a>              f&quot;\nTrain Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\n&quot;,</span>
<span id="cb325-145"><a href="dl_2.html#cb325-145" tabindex="-1"></a>              f&quot;Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}&quot;)</span></code></pre></div>
<p>说明：</p>
<ol style="list-style-type: decimal">
<li><p>在将数据存储为张量时就要统一特征和标签的数据类型为浮点数，否则后续特征为浮点数，标签为整数会报错。同时，标签的形状也应变为二维的。</p></li>
<li><p><code>nn.BatchNorm1d()</code>对该批次数据进行标准化操作，并进行缩放和平移，可在一定程度上缓解“内部协变量偏移”情况</p></li>
<li><p><code>nn.Dropout()</code>在训练<code>model.train()</code>时会以一定概率丢弃某些神经元，从而缓解过拟合现象，是一种正则化技术。</p></li>
<li><p>无论如何，模型和数据都要在同一设备上。张量数据必须重新赋值<code>batch_x = batch_x.to(device)</code>，而模型则可以直接<code>model.to(device)</code></p></li>
</ol>
</div>
<div id="dl_2_3" class="section level3 hasAnchor" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> 多分类问题<a href="dl_2.html#dl_2_3" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h3>
<p>对于多分类问题，输出层维度为类别数，无需添加softmax函数，因为在交叉熵损失函数<code>nn.CrossEntropyLoss()</code>中自带了softmax运算。</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb326-1"><a href="dl_2.html#cb326-1" tabindex="-1"></a>import torch</span>
<span id="cb326-2"><a href="dl_2.html#cb326-2" tabindex="-1"></a>import torch.nn as nn</span>
<span id="cb326-3"><a href="dl_2.html#cb326-3" tabindex="-1"></a>import torch.optim as optim</span>
<span id="cb326-4"><a href="dl_2.html#cb326-4" tabindex="-1"></a>from sklearn.datasets import make_classification</span>
<span id="cb326-5"><a href="dl_2.html#cb326-5" tabindex="-1"></a>from sklearn.model_selection import train_test_split</span>
<span id="cb326-6"><a href="dl_2.html#cb326-6" tabindex="-1"></a>from sklearn.preprocessing import StandardScaler</span>
<span id="cb326-7"><a href="dl_2.html#cb326-7" tabindex="-1"></a>import numpy as np</span>
<span id="cb326-8"><a href="dl_2.html#cb326-8" tabindex="-1"></a>from torch.utils.data import TensorDataset, DataLoader</span>
<span id="cb326-9"><a href="dl_2.html#cb326-9" tabindex="-1"></a></span>
<span id="cb326-10"><a href="dl_2.html#cb326-10" tabindex="-1"></a># 设置随机数种子</span>
<span id="cb326-11"><a href="dl_2.html#cb326-11" tabindex="-1"></a>torch.manual_seed(123)</span>
<span id="cb326-12"><a href="dl_2.html#cb326-12" tabindex="-1"></a>np.random.seed(321)</span>
<span id="cb326-13"><a href="dl_2.html#cb326-13" tabindex="-1"></a></span>
<span id="cb326-14"><a href="dl_2.html#cb326-14" tabindex="-1"></a>def gen_data(n_samples=2000, n_features=10, n_classes=5):</span>
<span id="cb326-15"><a href="dl_2.html#cb326-15" tabindex="-1"></a></span>
<span id="cb326-16"><a href="dl_2.html#cb326-16" tabindex="-1"></a>    # 生成复杂的分类型数据（有重叠）</span>
<span id="cb326-17"><a href="dl_2.html#cb326-17" tabindex="-1"></a>    X, y = make_classification(</span>
<span id="cb326-18"><a href="dl_2.html#cb326-18" tabindex="-1"></a>        n_samples=n_samples,    # 样本数</span>
<span id="cb326-19"><a href="dl_2.html#cb326-19" tabindex="-1"></a>        n_features=n_features,  # 特征数</span>
<span id="cb326-20"><a href="dl_2.html#cb326-20" tabindex="-1"></a>        n_informative=8,        # 有信息量的特征数量</span>
<span id="cb326-21"><a href="dl_2.html#cb326-21" tabindex="-1"></a>        n_redundant=2,          # 冗余特征数量</span>
<span id="cb326-22"><a href="dl_2.html#cb326-22" tabindex="-1"></a>        n_repeated=0,           # 重复特征数量</span>
<span id="cb326-23"><a href="dl_2.html#cb326-23" tabindex="-1"></a>        n_classes=n_classes,    # 类别数</span>
<span id="cb326-24"><a href="dl_2.html#cb326-24" tabindex="-1"></a>        flip_y=0.15,            # 15%的噪声</span>
<span id="cb326-25"><a href="dl_2.html#cb326-25" tabindex="-1"></a>        class_sep=0.8           # 类间分离程度</span>
<span id="cb326-26"><a href="dl_2.html#cb326-26" tabindex="-1"></a>    )</span>
<span id="cb326-27"><a href="dl_2.html#cb326-27" tabindex="-1"></a>    </span>
<span id="cb326-28"><a href="dl_2.html#cb326-28" tabindex="-1"></a>    # 划分训练集和测试集</span>
<span id="cb326-29"><a href="dl_2.html#cb326-29" tabindex="-1"></a>    X_train, X_test, y_train, y_test = train_test_split(</span>
<span id="cb326-30"><a href="dl_2.html#cb326-30" tabindex="-1"></a>        X, y, test_size=0.2, random_state=42</span>
<span id="cb326-31"><a href="dl_2.html#cb326-31" tabindex="-1"></a>    )</span>
<span id="cb326-32"><a href="dl_2.html#cb326-32" tabindex="-1"></a>    </span>
<span id="cb326-33"><a href="dl_2.html#cb326-33" tabindex="-1"></a>    # 数据标准化</span>
<span id="cb326-34"><a href="dl_2.html#cb326-34" tabindex="-1"></a>    scaler = StandardScaler()</span>
<span id="cb326-35"><a href="dl_2.html#cb326-35" tabindex="-1"></a>    X_train = scaler.fit_transform(X_train)</span>
<span id="cb326-36"><a href="dl_2.html#cb326-36" tabindex="-1"></a>    X_test = scaler.transform(X_test)</span>
<span id="cb326-37"><a href="dl_2.html#cb326-37" tabindex="-1"></a></span>
<span id="cb326-38"><a href="dl_2.html#cb326-38" tabindex="-1"></a>    # 转换为PyTorch张量</span>
<span id="cb326-39"><a href="dl_2.html#cb326-39" tabindex="-1"></a>    X_train = torch.tensor(X_train, dtype=torch.float32)</span>
<span id="cb326-40"><a href="dl_2.html#cb326-40" tabindex="-1"></a>    y_train = torch.tensor(y_train, dtype=torch.long)     # 交叉熵损失函数要求标签为整数型</span>
<span id="cb326-41"><a href="dl_2.html#cb326-41" tabindex="-1"></a>    X_test = torch.tensor(X_test, dtype=torch.float32)</span>
<span id="cb326-42"><a href="dl_2.html#cb326-42" tabindex="-1"></a>    y_test = torch.tensor(y_test, dtype=torch.long)</span>
<span id="cb326-43"><a href="dl_2.html#cb326-43" tabindex="-1"></a>    </span>
<span id="cb326-44"><a href="dl_2.html#cb326-44" tabindex="-1"></a>    return X_train, X_test, y_train, y_test</span>
<span id="cb326-45"><a href="dl_2.html#cb326-45" tabindex="-1"></a></span>
<span id="cb326-46"><a href="dl_2.html#cb326-46" tabindex="-1"></a># 生成数据，多分类任务</span>
<span id="cb326-47"><a href="dl_2.html#cb326-47" tabindex="-1"></a>X_train, X_test, y_train, y_test = gen_data()</span>
<span id="cb326-48"><a href="dl_2.html#cb326-48" tabindex="-1"></a></span>
<span id="cb326-49"><a href="dl_2.html#cb326-49" tabindex="-1"></a># 创建数据加载器</span>
<span id="cb326-50"><a href="dl_2.html#cb326-50" tabindex="-1"></a>train_dataset = TensorDataset(X_train, y_train)</span>
<span id="cb326-51"><a href="dl_2.html#cb326-51" tabindex="-1"></a>test_dataset = TensorDataset(X_test, y_test)</span>
<span id="cb326-52"><a href="dl_2.html#cb326-52" tabindex="-1"></a></span>
<span id="cb326-53"><a href="dl_2.html#cb326-53" tabindex="-1"></a>train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)</span>
<span id="cb326-54"><a href="dl_2.html#cb326-54" tabindex="-1"></a>test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)</span>
<span id="cb326-55"><a href="dl_2.html#cb326-55" tabindex="-1"></a></span>
<span id="cb326-56"><a href="dl_2.html#cb326-56" tabindex="-1"></a>model = nn.Sequential(</span>
<span id="cb326-57"><a href="dl_2.html#cb326-57" tabindex="-1"></a>    nn.Linear(10,128),</span>
<span id="cb326-58"><a href="dl_2.html#cb326-58" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb326-59"><a href="dl_2.html#cb326-59" tabindex="-1"></a>    nn.BatchNorm1d(128),  # 对该批次数据进行标准化操作，并进行缩放和平移，可在一定程度上缓解“内部协变量偏移”情况</span>
<span id="cb326-60"><a href="dl_2.html#cb326-60" tabindex="-1"></a>    nn.Dropout(0.2),     # 以一定概率丢弃某些神经元，从而缓解过拟合现象</span>
<span id="cb326-61"><a href="dl_2.html#cb326-61" tabindex="-1"></a>    </span>
<span id="cb326-62"><a href="dl_2.html#cb326-62" tabindex="-1"></a>    nn.Linear(128,64),</span>
<span id="cb326-63"><a href="dl_2.html#cb326-63" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb326-64"><a href="dl_2.html#cb326-64" tabindex="-1"></a>    nn.BatchNorm1d(64),</span>
<span id="cb326-65"><a href="dl_2.html#cb326-65" tabindex="-1"></a>    nn.Dropout(0.2),</span>
<span id="cb326-66"><a href="dl_2.html#cb326-66" tabindex="-1"></a></span>
<span id="cb326-67"><a href="dl_2.html#cb326-67" tabindex="-1"></a>    nn.Linear(64,32),</span>
<span id="cb326-68"><a href="dl_2.html#cb326-68" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb326-69"><a href="dl_2.html#cb326-69" tabindex="-1"></a>    nn.BatchNorm1d(32),</span>
<span id="cb326-70"><a href="dl_2.html#cb326-70" tabindex="-1"></a>    nn.Dropout(0.2),</span>
<span id="cb326-71"><a href="dl_2.html#cb326-71" tabindex="-1"></a>    </span>
<span id="cb326-72"><a href="dl_2.html#cb326-72" tabindex="-1"></a>    nn.Linear(32,5)      # 输出维度为类别数</span>
<span id="cb326-73"><a href="dl_2.html#cb326-73" tabindex="-1"></a>)</span>
<span id="cb326-74"><a href="dl_2.html#cb326-74" tabindex="-1"></a></span>
<span id="cb326-75"><a href="dl_2.html#cb326-75" tabindex="-1"></a>criterion = nn.CrossEntropyLoss()</span>
<span id="cb326-76"><a href="dl_2.html#cb326-76" tabindex="-1"></a>optimizer = optim.Adam(model.parameters(), lr=0.05)</span>
<span id="cb326-77"><a href="dl_2.html#cb326-77" tabindex="-1"></a></span>
<span id="cb326-78"><a href="dl_2.html#cb326-78" tabindex="-1"></a>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
<span id="cb326-79"><a href="dl_2.html#cb326-79" tabindex="-1"></a>model.to(device)</span>
<span id="cb326-80"><a href="dl_2.html#cb326-80" tabindex="-1"></a></span>
<span id="cb326-81"><a href="dl_2.html#cb326-81" tabindex="-1"></a># 存储训练指标</span>
<span id="cb326-82"><a href="dl_2.html#cb326-82" tabindex="-1"></a>train_losses = []</span>
<span id="cb326-83"><a href="dl_2.html#cb326-83" tabindex="-1"></a>train_accuracies = []</span>
<span id="cb326-84"><a href="dl_2.html#cb326-84" tabindex="-1"></a>val_losses = []</span>
<span id="cb326-85"><a href="dl_2.html#cb326-85" tabindex="-1"></a>val_accuracies = []</span>
<span id="cb326-86"><a href="dl_2.html#cb326-86" tabindex="-1"></a></span>
<span id="cb326-87"><a href="dl_2.html#cb326-87" tabindex="-1"></a>for epoch in range(100):</span>
<span id="cb326-88"><a href="dl_2.html#cb326-88" tabindex="-1"></a>    # 训练模式</span>
<span id="cb326-89"><a href="dl_2.html#cb326-89" tabindex="-1"></a>    model.train()</span>
<span id="cb326-90"><a href="dl_2.html#cb326-90" tabindex="-1"></a>    running_loss = 0.0</span>
<span id="cb326-91"><a href="dl_2.html#cb326-91" tabindex="-1"></a>    correct_train = 0</span>
<span id="cb326-92"><a href="dl_2.html#cb326-92" tabindex="-1"></a>    total_train = 0</span>
<span id="cb326-93"><a href="dl_2.html#cb326-93" tabindex="-1"></a>    </span>
<span id="cb326-94"><a href="dl_2.html#cb326-94" tabindex="-1"></a>    for batch_x, batch_y in train_loader:</span>
<span id="cb326-95"><a href="dl_2.html#cb326-95" tabindex="-1"></a>        # 移动数据到设备</span>
<span id="cb326-96"><a href="dl_2.html#cb326-96" tabindex="-1"></a>        batch_x, batch_y = batch_x.to(device), batch_y.to(device)</span>
<span id="cb326-97"><a href="dl_2.html#cb326-97" tabindex="-1"></a>        </span>
<span id="cb326-98"><a href="dl_2.html#cb326-98" tabindex="-1"></a>        # 前向传播</span>
<span id="cb326-99"><a href="dl_2.html#cb326-99" tabindex="-1"></a>        outputs = model(batch_x)</span>
<span id="cb326-100"><a href="dl_2.html#cb326-100" tabindex="-1"></a>        </span>
<span id="cb326-101"><a href="dl_2.html#cb326-101" tabindex="-1"></a>        # 计算损失</span>
<span id="cb326-102"><a href="dl_2.html#cb326-102" tabindex="-1"></a>        loss = criterion(outputs, batch_y)</span>
<span id="cb326-103"><a href="dl_2.html#cb326-103" tabindex="-1"></a>        </span>
<span id="cb326-104"><a href="dl_2.html#cb326-104" tabindex="-1"></a>        # 反向传播和优化</span>
<span id="cb326-105"><a href="dl_2.html#cb326-105" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb326-106"><a href="dl_2.html#cb326-106" tabindex="-1"></a>        loss.backward()</span>
<span id="cb326-107"><a href="dl_2.html#cb326-107" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb326-108"><a href="dl_2.html#cb326-108" tabindex="-1"></a>        </span>
<span id="cb326-109"><a href="dl_2.html#cb326-109" tabindex="-1"></a>        # 统计训练情况</span>
<span id="cb326-110"><a href="dl_2.html#cb326-110" tabindex="-1"></a>        running_loss += loss.item()</span>
<span id="cb326-111"><a href="dl_2.html#cb326-111" tabindex="-1"></a>        </span>
<span id="cb326-112"><a href="dl_2.html#cb326-112" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb326-113"><a href="dl_2.html#cb326-113" tabindex="-1"></a>        predictions = torch.argmax(outputs, dim = 1)   # logits值最大的为预测类别</span>
<span id="cb326-114"><a href="dl_2.html#cb326-114" tabindex="-1"></a>        correct_train += (predictions == batch_y).sum().item()</span>
<span id="cb326-115"><a href="dl_2.html#cb326-115" tabindex="-1"></a>        total_train += batch_y.size(0)</span>
<span id="cb326-116"><a href="dl_2.html#cb326-116" tabindex="-1"></a>    </span>
<span id="cb326-117"><a href="dl_2.html#cb326-117" tabindex="-1"></a>    # 计算本轮训练的平均损失和准确率</span>
<span id="cb326-118"><a href="dl_2.html#cb326-118" tabindex="-1"></a>    epoch_loss = running_loss / len(train_loader)</span>
<span id="cb326-119"><a href="dl_2.html#cb326-119" tabindex="-1"></a>    epoch_acc = correct_train / total_train if total_train &gt; 0 else 0</span>
<span id="cb326-120"><a href="dl_2.html#cb326-120" tabindex="-1"></a>    train_losses.append(epoch_loss)</span>
<span id="cb326-121"><a href="dl_2.html#cb326-121" tabindex="-1"></a>    train_accuracies.append(epoch_acc)</span>
<span id="cb326-122"><a href="dl_2.html#cb326-122" tabindex="-1"></a>    </span>
<span id="cb326-123"><a href="dl_2.html#cb326-123" tabindex="-1"></a>    # 验证评估</span>
<span id="cb326-124"><a href="dl_2.html#cb326-124" tabindex="-1"></a>    model.eval()</span>
<span id="cb326-125"><a href="dl_2.html#cb326-125" tabindex="-1"></a>    with torch.no_grad():</span>
<span id="cb326-126"><a href="dl_2.html#cb326-126" tabindex="-1"></a>        # 移动测试数据到设备</span>
<span id="cb326-127"><a href="dl_2.html#cb326-127" tabindex="-1"></a>        test_x, test_y = X_test.to(device), y_test.to(device)</span>
<span id="cb326-128"><a href="dl_2.html#cb326-128" tabindex="-1"></a>        # 前向传播</span>
<span id="cb326-129"><a href="dl_2.html#cb326-129" tabindex="-1"></a>        outputs = model(test_x)</span>
<span id="cb326-130"><a href="dl_2.html#cb326-130" tabindex="-1"></a>        # 计算损失</span>
<span id="cb326-131"><a href="dl_2.html#cb326-131" tabindex="-1"></a>        val_loss = criterion(outputs, test_y).item()</span>
<span id="cb326-132"><a href="dl_2.html#cb326-132" tabindex="-1"></a>        # 计算预测结果</span>
<span id="cb326-133"><a href="dl_2.html#cb326-133" tabindex="-1"></a>        predictions = torch.argmax(outputs, dim = 1)</span>
<span id="cb326-134"><a href="dl_2.html#cb326-134" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb326-135"><a href="dl_2.html#cb326-135" tabindex="-1"></a>        correct_val = (predictions == test_y).sum().item()</span>
<span id="cb326-136"><a href="dl_2.html#cb326-136" tabindex="-1"></a>        total_val = test_y.size(0)</span>
<span id="cb326-137"><a href="dl_2.html#cb326-137" tabindex="-1"></a>        val_acc = correct_val / total_val</span>
<span id="cb326-138"><a href="dl_2.html#cb326-138" tabindex="-1"></a>        # 存储验证结果</span>
<span id="cb326-139"><a href="dl_2.html#cb326-139" tabindex="-1"></a>        val_losses.append(val_loss)</span>
<span id="cb326-140"><a href="dl_2.html#cb326-140" tabindex="-1"></a>        val_accuracies.append(val_acc)</span>
<span id="cb326-141"><a href="dl_2.html#cb326-141" tabindex="-1"></a>    </span>
<span id="cb326-142"><a href="dl_2.html#cb326-142" tabindex="-1"></a>    # 每10个epoch打印一次进度</span>
<span id="cb326-143"><a href="dl_2.html#cb326-143" tabindex="-1"></a>    if (epoch + 1) % 10 == 0:</span>
<span id="cb326-144"><a href="dl_2.html#cb326-144" tabindex="-1"></a>        print(&quot;=&quot;*10,</span>
<span id="cb326-145"><a href="dl_2.html#cb326-145" tabindex="-1"></a>              f&quot;Epoch_{epoch+1}&quot;,</span>
<span id="cb326-146"><a href="dl_2.html#cb326-146" tabindex="-1"></a>              &quot;=&quot;*10,</span>
<span id="cb326-147"><a href="dl_2.html#cb326-147" tabindex="-1"></a>              f&quot;\nTrain Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\n&quot;,</span>
<span id="cb326-148"><a href="dl_2.html#cb326-148" tabindex="-1"></a>              f&quot;Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}&quot;)</span></code></pre></div>
<p>说明：</p>
<ol style="list-style-type: decimal">
<li><p><code>nn.CrossEntropyLoss()</code>接收预测值logits（原值）与标签。其中logits为神经网络的原始输出，无需在输出时添加Softmax激活函数，<code>nn.CrossEntropyLoss()</code>的内部会自动进行Softmax计算，避免重复计算。同时，标签要求为整数型且维度为1，不需要独热编码。</p></li>
<li><p>如果需要输出概率，可以在输出logits后手动计算<code>torch.softmax(outputs, dim=1)</code>。</p></li>
<li><p>如果要输出预测类别，可以<code>torch.argmax(outputs, dim=1)</code>。</p></li>
</ol>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="dl_1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dl_3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "toc_depth": 3
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
