<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.2 线性神经网络 | kj的学习笔记</title>
  <meta name="description" content="个人学习笔记" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="10.2 线性神经网络 | kj的学习笔记" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/‪D:.png" />
  <meta property="og:description" content="个人学习笔记" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.2 线性神经网络 | kj的学习笔记" />
  
  <meta name="twitter:description" content="个人学习笔记" />
  <meta name="twitter:image" content="/‪D:.png" />

<meta name="author" content="刘柯榉" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="dl_1.html"/>
<link rel="next" href="dl_9.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.11/grViz.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-1.0.11/DiagrammeR.js"></script>
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<pre>  kj的学习笔记  </pre>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="content.html"><a href="content.html"><i class="fa fa-check"></i>内容组成</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>个人简介</a></li>
<li class="part"><span><b>I 专项</b></span></li>
<li class="chapter" data-level="1" data-path="rmd.html"><a href="rmd.html"><i class="fa fa-check"></i><b>1</b> R Markdown</a>
<ul>
<li class="chapter" data-level="1.1" data-path="rmd_1.html"><a href="rmd_1.html"><i class="fa fa-check"></i><b>1.1</b> 安装与创建</a></li>
<li class="chapter" data-level="1.2" data-path="rmd_2.html"><a href="rmd_2.html"><i class="fa fa-check"></i><b>1.2</b> 初识RMD</a></li>
<li class="chapter" data-level="1.3" data-path="rmd_3.html"><a href="rmd_3.html"><i class="fa fa-check"></i><b>1.3</b> 语法介绍</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_1"><i class="fa fa-check"></i><b>1.3.1</b> 标题</a></li>
<li class="chapter" data-level="1.3.2" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_2"><i class="fa fa-check"></i><b>1.3.2</b> 字体样式</a></li>
<li class="chapter" data-level="1.3.3" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_3"><i class="fa fa-check"></i><b>1.3.3</b> 换行</a></li>
<li class="chapter" data-level="1.3.4" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_4"><i class="fa fa-check"></i><b>1.3.4</b> 链接</a></li>
<li class="chapter" data-level="1.3.5" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_5"><i class="fa fa-check"></i><b>1.3.5</b> 引用</a></li>
<li class="chapter" data-level="1.3.6" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_6"><i class="fa fa-check"></i><b>1.3.6</b> 列表</a></li>
<li class="chapter" data-level="1.3.7" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_7"><i class="fa fa-check"></i><b>1.3.7</b> 代码</a></li>
<li class="chapter" data-level="1.3.8" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_8"><i class="fa fa-check"></i><b>1.3.8</b> 表格</a></li>
<li class="chapter" data-level="1.3.9" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_9"><i class="fa fa-check"></i><b>1.3.9</b> 图片</a></li>
<li class="chapter" data-level="1.3.10" data-path="rmd_3.html"><a href="rmd_3.html#rmd_3_10"><i class="fa fa-check"></i><b>1.3.10</b> 数学公式</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="rmd_4.html"><a href="rmd_4.html"><i class="fa fa-check"></i><b>1.4</b> 文档元素</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_1"><i class="fa fa-check"></i><b>1.4.1</b> 分割线</a></li>
<li class="chapter" data-level="1.4.2" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_2"><i class="fa fa-check"></i><b>1.4.2</b> 转义符</a></li>
<li class="chapter" data-level="1.4.3" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_3"><i class="fa fa-check"></i><b>1.4.3</b> 分页符</a></li>
<li class="chapter" data-level="1.4.4" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_4"><i class="fa fa-check"></i><b>1.4.4</b> 设置动态标题</a></li>
<li class="chapter" data-level="1.4.5" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_5"><i class="fa fa-check"></i><b>1.4.5</b> 自动更新时间</a></li>
<li class="chapter" data-level="1.4.6" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_6"><i class="fa fa-check"></i><b>1.4.6</b> 获取元数据信息</a></li>
<li class="chapter" data-level="1.4.7" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_7"><i class="fa fa-check"></i><b>1.4.7</b> 参考文献</a></li>
<li class="chapter" data-level="1.4.8" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_8"><i class="fa fa-check"></i><b>1.4.8</b> 交叉引用</a></li>
<li class="chapter" data-level="1.4.9" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_9"><i class="fa fa-check"></i><b>1.4.9</b> 多位作者</a></li>
<li class="chapter" data-level="1.4.10" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_10"><i class="fa fa-check"></i><b>1.4.10</b> 将模型输出为公式</a></li>
<li class="chapter" data-level="1.4.11" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_11"><i class="fa fa-check"></i><b>1.4.11</b> 流程图</a></li>
<li class="chapter" data-level="1.4.12" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_12"><i class="fa fa-check"></i><b>1.4.12</b> 注释</a></li>
<li class="chapter" data-level="1.4.13" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_13"><i class="fa fa-check"></i><b>1.4.13</b> 缩进</a></li>
<li class="chapter" data-level="1.4.14" data-path="rmd_4.html"><a href="rmd_4.html#rmd_4_14"><i class="fa fa-check"></i><b>1.4.14</b> 字体颜色</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="rmd_5.html"><a href="rmd_5.html"><i class="fa fa-check"></i><b>1.5</b> HTML文档</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_1"><i class="fa fa-check"></i><b>1.5.1</b> 标签</a></li>
<li class="chapter" data-level="1.5.2" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_2"><i class="fa fa-check"></i><b>1.5.2</b> 目录</a></li>
<li class="chapter" data-level="1.5.3" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_3"><i class="fa fa-check"></i><b>1.5.3</b> 外观</a></li>
<li class="chapter" data-level="1.5.4" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_4"><i class="fa fa-check"></i><b>1.5.4</b> 选项卡</a></li>
<li class="chapter" data-level="1.5.5" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_5"><i class="fa fa-check"></i><b>1.5.5</b> 表格</a></li>
<li class="chapter" data-level="1.5.6" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_6"><i class="fa fa-check"></i><b>1.5.6</b> 代码块及其输出</a></li>
<li class="chapter" data-level="1.5.7" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_7"><i class="fa fa-check"></i><b>1.5.7</b> 添加HTML文件</a></li>
<li class="chapter" data-level="1.5.8" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_8"><i class="fa fa-check"></i><b>1.5.8</b> Pandoc参数</a></li>
<li class="chapter" data-level="1.5.9" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_9"><i class="fa fa-check"></i><b>1.5.9</b> 共享选项</a></li>
<li class="chapter" data-level="1.5.10" data-path="rmd_5.html"><a href="rmd_5.html#rmd_5_10"><i class="fa fa-check"></i><b>1.5.10</b> 下载文件</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="rmd_6.html"><a href="rmd_6.html"><i class="fa fa-check"></i><b>1.6</b> PDF文档</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_1"><i class="fa fa-check"></i><b>1.6.1</b> 中文文档</a></li>
<li class="chapter" data-level="1.6.2" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_2"><i class="fa fa-check"></i><b>1.6.2</b> 目录</a></li>
<li class="chapter" data-level="1.6.3" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_3"><i class="fa fa-check"></i><b>1.6.3</b> 图与表</a></li>
<li class="chapter" data-level="1.6.4" data-path="rmd_6.html"><a href="rmd_6.html#rmd_6_4"><i class="fa fa-check"></i><b>1.6.4</b> 语法高亮</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="manim.html"><a href="manim.html"><i class="fa fa-check"></i><b>2</b> Manim</a>
<ul>
<li class="chapter" data-level="2.1" data-path="manim_1.html"><a href="manim_1.html"><i class="fa fa-check"></i><b>2.1</b> 安装与创建</a></li>
<li class="chapter" data-level="2.2" data-path="manim_2.html"><a href="manim_2.html"><i class="fa fa-check"></i><b>2.2</b> 初识Manim</a></li>
<li class="chapter" data-level="2.3" data-path="manim_3.html"><a href="manim_3.html"><i class="fa fa-check"></i><b>2.3</b> 输出设置</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="manim_3.html"><a href="manim_3.html#manim_3_1"><i class="fa fa-check"></i><b>2.3.1</b> 输出文件夹</a></li>
<li class="chapter" data-level="2.3.2" data-path="manim_3.html"><a href="manim_3.html#manim_3_2"><i class="fa fa-check"></i><b>2.3.2</b> 片段</a></li>
<li class="chapter" data-level="2.3.3" data-path="manim_3.html"><a href="manim_3.html#manim_3_3"><i class="fa fa-check"></i><b>2.3.3</b> 命令行标志</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="manim_4.html"><a href="manim_4.html"><i class="fa fa-check"></i><b>2.4</b> 配置</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="manim_4.html"><a href="manim_4.html#manim_4_1"><i class="fa fa-check"></i><b>2.4.1</b> 命令行参数</a></li>
<li class="chapter" data-level="2.4.2" data-path="manim_4.html"><a href="manim_4.html#manim_4_2"><i class="fa fa-check"></i><b>2.4.2</b> ManimConfig类</a></li>
<li class="chapter" data-level="2.4.3" data-path="manim_4.html"><a href="manim_4.html#manim_4_3"><i class="fa fa-check"></i><b>2.4.3</b> 配置文件</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="manim_5.html"><a href="manim_5.html"><i class="fa fa-check"></i><b>2.5</b> 文本</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="manim_5.html"><a href="manim_5.html#manim_5_1"><i class="fa fa-check"></i><b>2.5.1</b> Text</a></li>
<li class="chapter" data-level="2.5.2" data-path="manim_5.html"><a href="manim_5.html#manim_5_2"><i class="fa fa-check"></i><b>2.5.2</b> MarkupText</a></li>
<li class="chapter" data-level="2.5.3" data-path="manim_5.html"><a href="manim_5.html#manim_5_3"><i class="fa fa-check"></i><b>2.5.3</b> Paragraph</a></li>
<li class="chapter" data-level="2.5.4" data-path="manim_5.html"><a href="manim_5.html#manim_5_4"><i class="fa fa-check"></i><b>2.5.4</b> Tex</a></li>
<li class="chapter" data-level="2.5.5" data-path="manim_5.html"><a href="manim_5.html#manim_5_5"><i class="fa fa-check"></i><b>2.5.5</b> MathTex</a></li>
<li class="chapter" data-level="2.5.6" data-path="manim_5.html"><a href="manim_5.html#manim_5_6"><i class="fa fa-check"></i><b>2.5.6</b> Title</a></li>
<li class="chapter" data-level="2.5.7" data-path="manim_5.html"><a href="manim_5.html#manim_5_7"><i class="fa fa-check"></i><b>2.5.7</b> BulletedList</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="manim_6.html"><a href="manim_6.html"><i class="fa fa-check"></i><b>2.6</b> 内置颜色</a></li>
<li class="chapter" data-level="2.7" data-path="manim_7.html"><a href="manim_7.html"><i class="fa fa-check"></i><b>2.7</b> 物体的位置与移动</a></li>
<li class="chapter" data-level="2.8" data-path="manim_8.html"><a href="manim_8.html"><i class="fa fa-check"></i><b>2.8</b> 动画</a></li>
<li class="chapter" data-level="2.9" data-path="manim_9.html"><a href="manim_9.html"><i class="fa fa-check"></i><b>2.9</b> 镜头视角</a></li>
<li class="chapter" data-level="2.10" data-path="manim_10.html"><a href="manim_10.html"><i class="fa fa-check"></i><b>2.10</b> 存储对象</a></li>
<li class="chapter" data-level="2.11" data-path="manim_11.html"><a href="manim_11.html"><i class="fa fa-check"></i><b>2.11</b> 成品</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sql.html"><a href="sql.html"><i class="fa fa-check"></i><b>3</b> SQL</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sql_1.html"><a href="sql_1.html"><i class="fa fa-check"></i><b>3.1</b> 连接MySQL</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="sql_1.html"><a href="sql_1.html#sql_1_1"><i class="fa fa-check"></i><b>3.1.1</b> R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sql_2.html"><a href="sql_2.html"><i class="fa fa-check"></i><b>3.2</b> MySQL必知必会</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="sql_2.html"><a href="sql_2.html#sql_2_1"><i class="fa fa-check"></i><b>3.2.1</b> 提要</a></li>
<li class="chapter" data-level="3.2.2" data-path="sql_2.html"><a href="sql_2.html#sql_2_2"><i class="fa fa-check"></i><b>3.2.2</b> 选择数据库与表</a></li>
<li class="chapter" data-level="3.2.3" data-path="sql_2.html"><a href="sql_2.html#sql_2_3"><i class="fa fa-check"></i><b>3.2.3</b> 检索数据</a></li>
<li class="chapter" data-level="3.2.4" data-path="sql_2.html"><a href="sql_2.html#sql_2_4"><i class="fa fa-check"></i><b>3.2.4</b> 排序检索数据</a></li>
<li class="chapter" data-level="3.2.5" data-path="sql_2.html"><a href="sql_2.html#sql_2_5"><i class="fa fa-check"></i><b>3.2.5</b> 过滤数据</a></li>
<li class="chapter" data-level="3.2.6" data-path="sql_2.html"><a href="sql_2.html#sql_2_6"><i class="fa fa-check"></i><b>3.2.6</b> 计算字段</a></li>
<li class="chapter" data-level="3.2.7" data-path="sql_2.html"><a href="sql_2.html#sql_2_7"><i class="fa fa-check"></i><b>3.2.7</b> 函数</a></li>
<li class="chapter" data-level="3.2.8" data-path="sql_2.html"><a href="sql_2.html#sql_2_8"><i class="fa fa-check"></i><b>3.2.8</b> 汇总数据</a></li>
<li class="chapter" data-level="3.2.9" data-path="sql_2.html"><a href="sql_2.html#sql_2_9"><i class="fa fa-check"></i><b>3.2.9</b> 数据分组</a></li>
<li class="chapter" data-level="3.2.10" data-path="sql_2.html"><a href="sql_2.html#sql_2_10"><i class="fa fa-check"></i><b>3.2.10</b> 子查询</a></li>
<li class="chapter" data-level="3.2.11" data-path="sql_2.html"><a href="sql_2.html#sql_2_11"><i class="fa fa-check"></i><b>3.2.11</b> 表联结</a></li>
<li class="chapter" data-level="3.2.12" data-path="sql_2.html"><a href="sql_2.html#sql_2_12"><i class="fa fa-check"></i><b>3.2.12</b> 组合查询</a></li>
<li class="chapter" data-level="3.2.13" data-path="sql_2.html"><a href="sql_2.html#sql_2_13"><i class="fa fa-check"></i><b>3.2.13</b> 全文本搜索</a></li>
<li class="chapter" data-level="3.2.14" data-path="sql_2.html"><a href="sql_2.html#sql_2_14"><i class="fa fa-check"></i><b>3.2.14</b> 插入数据</a></li>
<li class="chapter" data-level="3.2.15" data-path="sql_2.html"><a href="sql_2.html#sql_2_15"><i class="fa fa-check"></i><b>3.2.15</b> 更新数据</a></li>
<li class="chapter" data-level="3.2.16" data-path="sql_2.html"><a href="sql_2.html#sql_2_16"><i class="fa fa-check"></i><b>3.2.16</b> 表的操作</a></li>
<li class="chapter" data-level="3.2.17" data-path="sql_2.html"><a href="sql_2.html#sql_2_17"><i class="fa fa-check"></i><b>3.2.17</b> 使用视图</a></li>
<li class="chapter" data-level="3.2.18" data-path="sql_2.html"><a href="sql_2.html#sql_2_18"><i class="fa fa-check"></i><b>3.2.18</b> 使用存储过程</a></li>
<li class="chapter" data-level="3.2.19" data-path="sql_2.html"><a href="sql_2.html#sql_2_19"><i class="fa fa-check"></i><b>3.2.19</b> 触发器</a></li>
<li class="chapter" data-level="3.2.20" data-path="sql_2.html"><a href="sql_2.html#sql_2_20"><i class="fa fa-check"></i><b>3.2.20</b> 事务处理</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="spider.html"><a href="spider.html"><i class="fa fa-check"></i><b>4</b> 爬虫</a>
<ul>
<li class="chapter" data-level="4.1" data-path="spider_1.html"><a href="spider_1.html"><i class="fa fa-check"></i><b>4.1</b> 提要</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>5</b> Shiny</a>
<ul>
<li class="chapter" data-level="5.1" data-path="shiny_1.html"><a href="shiny_1.html"><i class="fa fa-check"></i><b>5.1</b> 初始Shiny</a></li>
<li class="chapter" data-level="5.2" data-path="shiny_2.html"><a href="shiny_2.html"><i class="fa fa-check"></i><b>5.2</b> UI设计</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="shiny_2.html"><a href="shiny_2.html#shiny_2_1"><i class="fa fa-check"></i><b>5.2.1</b> 输入</a></li>
<li class="chapter" data-level="5.2.2" data-path="shiny_2.html"><a href="shiny_2.html#shiny_2_2"><i class="fa fa-check"></i><b>5.2.2</b> 输出</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="shiny_3.html"><a href="shiny_3.html"><i class="fa fa-check"></i><b>5.3</b> 反应式编程</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_1"><i class="fa fa-check"></i><b>5.3.1</b> 服务端</a></li>
<li class="chapter" data-level="5.3.2" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_2"><i class="fa fa-check"></i><b>5.3.2</b> 反应表达式</a></li>
<li class="chapter" data-level="5.3.3" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_3"><i class="fa fa-check"></i><b>5.3.3</b> 控制更新</a></li>
<li class="chapter" data-level="5.3.4" data-path="shiny_3.html"><a href="shiny_3.html#shiny_3_4"><i class="fa fa-check"></i><b>5.3.4</b> 信息反馈</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="shiny_4.html"><a href="shiny_4.html"><i class="fa fa-check"></i><b>5.4</b> 页面布局</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="shiny_4.html"><a href="shiny_4.html#shiny_4_1"><i class="fa fa-check"></i><b>5.4.1</b> 页面函数</a></li>
<li class="chapter" data-level="5.4.2" data-path="shiny_4.html"><a href="shiny_4.html#shiny_4_2"><i class="fa fa-check"></i><b>5.4.2</b> 布局函数</a></li>
<li class="chapter" data-level="5.4.3" data-path="shiny_4.html"><a href="shiny_4.html#shiny_4_2_3"><i class="fa fa-check"></i><b>5.4.3</b> bslib风格布局</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="shiny_5.html"><a href="shiny_5.html"><i class="fa fa-check"></i><b>5.5</b> 主题</a></li>
<li class="chapter" data-level="5.6" data-path="shiny_6.html"><a href="shiny_6.html"><i class="fa fa-check"></i><b>5.6</b> 交互式图像与插入图像</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="shiny_6.html"><a href="shiny_6.html#shiny_6_1"><i class="fa fa-check"></i><b>5.6.1</b> 交互式图像</a></li>
<li class="chapter" data-level="5.6.2" data-path="shiny_6.html"><a href="shiny_6.html#shiny_6_2"><i class="fa fa-check"></i><b>5.6.2</b> 插入图像</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="shiny_7.html"><a href="shiny_7.html"><i class="fa fa-check"></i><b>5.7</b> 用户反馈</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_1"><i class="fa fa-check"></i><b>5.7.1</b> 验证</a></li>
<li class="chapter" data-level="5.7.2" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_2"><i class="fa fa-check"></i><b>5.7.2</b> 通知</a></li>
<li class="chapter" data-level="5.7.3" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_3"><i class="fa fa-check"></i><b>5.7.3</b> 进度条</a></li>
<li class="chapter" data-level="5.7.4" data-path="shiny_7.html"><a href="shiny_7.html#shiny_7_4"><i class="fa fa-check"></i><b>5.7.4</b> 确认</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="shiny_8.html"><a href="shiny_8.html"><i class="fa fa-check"></i><b>5.8</b> shiny中的整洁式编程</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="shiny_8.html"><a href="shiny_8.html#shiny_8_1"><i class="fa fa-check"></i><b>5.8.1</b> Data-masking</a></li>
<li class="chapter" data-level="5.8.2" data-path="shiny_8.html"><a href="shiny_8.html#shiny_8_2"><i class="fa fa-check"></i><b>5.8.2</b> Tidy-selection</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="shiny_9.html"><a href="shiny_9.html"><i class="fa fa-check"></i><b>5.9</b> 交互式Rmarkdown</a></li>
<li class="chapter" data-level="5.10" data-path="shiny_10.html"><a href="shiny_10.html"><i class="fa fa-check"></i><b>5.10</b> 数据仪表盘</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="shiny_10.html"><a href="shiny_10.html#shiny_10_1"><i class="fa fa-check"></i><b>5.10.1</b> 整体框架</a></li>
<li class="chapter" data-level="5.10.2" data-path="shiny_10.html"><a href="shiny_10.html#shiny_10_2"><i class="fa fa-check"></i><b>5.10.2</b> 外观</a></li>
<li class="chapter" data-level="5.10.3" data-path="shiny_10.html"><a href="shiny_10.html#shiny_10_3"><i class="fa fa-check"></i><b>5.10.3</b> 案例</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="shiny_11.html"><a href="shiny_11.html"><i class="fa fa-check"></i><b>5.11</b> 分享shiny</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="langchain.html"><a href="langchain.html"><i class="fa fa-check"></i><b>6</b> Langchain</a>
<ul>
<li class="chapter" data-level="6.1" data-path="langchain_x.html"><a href="langchain_x.html"><i class="fa fa-check"></i><b>6.1</b> 案例</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="langchain_x.html"><a href="langchain_x.html#langchain_x_1"><i class="fa fa-check"></i><b>6.1.1</b> NL2SQL</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 模型与方法</b></span></li>
<li class="chapter" data-level="7" data-path="reg.html"><a href="reg.html"><i class="fa fa-check"></i><b>7</b> 应用回归分析</a>
<ul>
<li class="chapter" data-level="7.1" data-path="reg_1.html"><a href="reg_1.html"><i class="fa fa-check"></i><b>7.1</b> 引言</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="reg_1.html"><a href="reg_1.html#reg_1_1"><i class="fa fa-check"></i><b>7.1.1</b> 变量间的相关关系</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg_1.html"><a href="reg_1.html#reg_1_2"><i class="fa fa-check"></i><b>7.1.2</b> 回归模型的一般形式</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="reg_2.html"><a href="reg_2.html"><i class="fa fa-check"></i><b>7.2</b> 假定</a></li>
<li class="chapter" data-level="7.3" data-path="reg_3.html"><a href="reg_3.html"><i class="fa fa-check"></i><b>7.3</b> 线性回归模型</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="reg_3.html"><a href="reg_3.html#reg_3_1"><i class="fa fa-check"></i><b>7.3.1</b> 一元线性回归模型</a></li>
<li class="chapter" data-level="7.3.2" data-path="reg_3.html"><a href="reg_3.html#reg_3_2"><i class="fa fa-check"></i><b>7.3.2</b> 多元线性回归模型</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="reg_4.html"><a href="reg_4.html"><i class="fa fa-check"></i><b>7.4</b> 参数估计</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="reg_4.html"><a href="reg_4.html#reg_4_1"><i class="fa fa-check"></i><b>7.4.1</b> 最小二乘估计</a></li>
<li class="chapter" data-level="7.4.2" data-path="reg_4.html"><a href="reg_4.html#reg_4_2"><i class="fa fa-check"></i><b>7.4.2</b> 极大似然估计</a></li>
<li class="chapter" data-level="7.4.3" data-path="reg_4.html"><a href="reg_4.html#reg_4_3"><i class="fa fa-check"></i><b>7.4.3</b> 矩估计</a></li>
<li class="chapter" data-level="7.4.4" data-path="reg_4.html"><a href="reg_4.html#reg_4_4"><i class="fa fa-check"></i><b>7.4.4</b> 几何视角</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="reg_5.html"><a href="reg_5.html"><i class="fa fa-check"></i><b>7.5</b> 最小二乘估计的性质</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="reg_5.html"><a href="reg_5.html#reg_5_1"><i class="fa fa-check"></i><b>7.5.1</b> 线性</a></li>
<li class="chapter" data-level="7.5.2" data-path="reg_5.html"><a href="reg_5.html#reg_5_2"><i class="fa fa-check"></i><b>7.5.2</b> 无偏性</a></li>
<li class="chapter" data-level="7.5.3" data-path="reg_5.html"><a href="reg_5.html#reg_5_3"><i class="fa fa-check"></i><b>7.5.3</b> 有效性</a></li>
<li class="chapter" data-level="7.5.4" data-path="reg_5.html"><a href="reg_5.html#reg_5_4"><i class="fa fa-check"></i><b>7.5.4</b> 方差</a></li>
<li class="chapter" data-level="7.5.5" data-path="reg_5.html"><a href="reg_5.html#reg_5_5"><i class="fa fa-check"></i><b>7.5.5</b> 正态性</a></li>
<li class="chapter" data-level="7.5.6" data-path="reg_5.html"><a href="reg_5.html#reg_5_6"><i class="fa fa-check"></i><b>7.5.6</b> 残差</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="reg_6.html"><a href="reg_6.html"><i class="fa fa-check"></i><b>7.6</b> 显著性检验</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="reg_6.html"><a href="reg_6.html#reg_6_1"><i class="fa fa-check"></i><b>7.6.1</b> 区间估计</a></li>
<li class="chapter" data-level="7.6.2" data-path="reg_6.html"><a href="reg_6.html#reg_6_2"><i class="fa fa-check"></i><b>7.6.2</b> t检验</a></li>
<li class="chapter" data-level="7.6.3" data-path="reg_6.html"><a href="reg_6.html#reg_6_3"><i class="fa fa-check"></i><b>7.6.3</b> F检验</a></li>
<li class="chapter" data-level="7.6.4" data-path="reg_6.html"><a href="reg_6.html#reg_6_4"><i class="fa fa-check"></i><b>7.6.4</b> 偏F检验</a></li>
<li class="chapter" data-level="7.6.5" data-path="reg_6.html"><a href="reg_6.html#reg_6_5"><i class="fa fa-check"></i><b>7.6.5</b> 样本决定系数</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="reg_7.html"><a href="reg_7.html"><i class="fa fa-check"></i><b>7.7</b> 预测</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="reg_7.html"><a href="reg_7.html#reg_7_1"><i class="fa fa-check"></i><b>7.7.1</b> 预测因变量新值的均值</a></li>
<li class="chapter" data-level="7.7.2" data-path="reg_7.html"><a href="reg_7.html#reg_7_2"><i class="fa fa-check"></i><b>7.7.2</b> 预测因变量的新值</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="reg_8.html"><a href="reg_8.html"><i class="fa fa-check"></i><b>7.8</b> 回归系数的解释</a></li>
<li class="chapter" data-level="7.9" data-path="reg_9.html"><a href="reg_9.html"><i class="fa fa-check"></i><b>7.9</b> 中心化与标准化</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="reg_9.html"><a href="reg_9.html#reg_9_1"><i class="fa fa-check"></i><b>7.9.1</b> 中心化</a></li>
<li class="chapter" data-level="7.9.2" data-path="reg_9.html"><a href="reg_9.html#reg_9_2"><i class="fa fa-check"></i><b>7.9.2</b> 标准化</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="reg_10.html"><a href="reg_10.html"><i class="fa fa-check"></i><b>7.10</b> 相关系数与偏相关系数</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="reg_10.html"><a href="reg_10.html#reg_10_1"><i class="fa fa-check"></i><b>7.10.1</b> 样本相关系数</a></li>
<li class="chapter" data-level="7.10.2" data-path="reg_10.html"><a href="reg_10.html#reg_10_2"><i class="fa fa-check"></i><b>7.10.2</b> 样本偏相关系数</a></li>
</ul></li>
<li class="chapter" data-level="7.11" data-path="reg_11.html"><a href="reg_11.html"><i class="fa fa-check"></i><b>7.11</b> 重要的定义和等式</a></li>
<li class="chapter" data-level="7.12" data-path="reg_12.html"><a href="reg_12.html"><i class="fa fa-check"></i><b>7.12</b> 回归诊断</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="reg_12.html"><a href="reg_12.html#reg_12_1"><i class="fa fa-check"></i><b>7.12.1</b> 残差分析</a></li>
<li class="chapter" data-level="7.12.2" data-path="reg_12.html"><a href="reg_12.html#reg_12_2"><i class="fa fa-check"></i><b>7.12.2</b> 异常点和强影响点</a></li>
<li class="chapter" data-level="7.12.3" data-path="reg_12.html"><a href="reg_12.html#reg_12_3"><i class="fa fa-check"></i><b>7.12.3</b> 异方差</a></li>
<li class="chapter" data-level="7.12.4" data-path="reg_12.html"><a href="reg_12.html#reg_12_4"><i class="fa fa-check"></i><b>7.12.4</b> 自相关</a></li>
<li class="chapter" data-level="7.12.5" data-path="reg_12.html"><a href="reg_12.html#reg_12_5"><i class="fa fa-check"></i><b>7.12.5</b> 多重共线性</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="reg_13.html"><a href="reg_13.html"><i class="fa fa-check"></i><b>7.13</b> 变量选择与正则化</a>
<ul>
<li class="chapter" data-level="7.13.1" data-path="reg_13.html"><a href="reg_13.html#reg_13_1"><i class="fa fa-check"></i><b>7.13.1</b> 冗余与遗漏</a></li>
<li class="chapter" data-level="7.13.2" data-path="reg_13.html"><a href="reg_13.html#reg_13_2"><i class="fa fa-check"></i><b>7.13.2</b> 变量选择的传统方法</a></li>
<li class="chapter" data-level="7.13.3" data-path="reg_13.html"><a href="reg_13.html#reg_13_3"><i class="fa fa-check"></i><b>7.13.3</b> 变量选择的正则化方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ms.html"><a href="ms.html"><i class="fa fa-check"></i><b>8</b> 应用多元统计</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ms_1.html"><a href="ms_1.html"><i class="fa fa-check"></i><b>8.1</b> 矩阵运算</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ms_1.html"><a href="ms_1.html#ms_1_1"><i class="fa fa-check"></i><b>8.1.1</b> Kronecker积</a></li>
<li class="chapter" data-level="8.1.2" data-path="ms_1.html"><a href="ms_1.html#ms_1_2"><i class="fa fa-check"></i><b>8.1.2</b> 拉直</a></li>
<li class="chapter" data-level="8.1.3" data-path="ms_1.html"><a href="ms_1.html#ms_1_3"><i class="fa fa-check"></i><b>8.1.3</b> 减号逆与加号逆</a></li>
<li class="chapter" data-level="8.1.4" data-path="ms_1.html"><a href="ms_1.html#ms_1_4"><i class="fa fa-check"></i><b>8.1.4</b> 分块矩阵</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ms_2.html"><a href="ms_2.html"><i class="fa fa-check"></i><b>8.2</b> 多元正态分布</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ms_2.html"><a href="ms_2.html#ms_2_1"><i class="fa fa-check"></i><b>8.2.1</b> 多元分布的基本运算性质</a></li>
<li class="chapter" data-level="8.2.2" data-path="ms_2.html"><a href="ms_2.html#ms_2_2"><i class="fa fa-check"></i><b>8.2.2</b> 多元正态分布的定义</a></li>
<li class="chapter" data-level="8.2.3" data-path="ms_2.html"><a href="ms_2.html#ms_2_3"><i class="fa fa-check"></i><b>8.2.3</b> 正态分布的条件分布和独立性</a></li>
<li class="chapter" data-level="8.2.4" data-path="ms_2.html"><a href="ms_2.html#ms_2_4"><i class="fa fa-check"></i><b>8.2.4</b> 偏相关系数与全相关系数</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ms_3.html"><a href="ms_3.html"><i class="fa fa-check"></i><b>8.3</b> 主成分分析</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ms_3.html"><a href="ms_3.html#ms_3_1"><i class="fa fa-check"></i><b>8.3.1</b> 总体主成分</a></li>
<li class="chapter" data-level="8.3.2" data-path="ms_3.html"><a href="ms_3.html#ms_3_2"><i class="fa fa-check"></i><b>8.3.2</b> 样本主成分</a></li>
<li class="chapter" data-level="8.3.3" data-path="ms_3.html"><a href="ms_3.html#ms_3_3"><i class="fa fa-check"></i><b>8.3.3</b> 关于主成分</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ms_4.html"><a href="ms_4.html"><i class="fa fa-check"></i><b>8.4</b> 因子分析</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ms_4.html"><a href="ms_4.html#ms_4_1"><i class="fa fa-check"></i><b>8.4.1</b> 正交因子模型</a></li>
<li class="chapter" data-level="8.4.2" data-path="ms_4.html"><a href="ms_4.html#ms_4_3"><i class="fa fa-check"></i><b>8.4.2</b> 参数估计</a></li>
<li class="chapter" data-level="8.4.3" data-path="ms_4.html"><a href="ms_4.html#ms_4_4"><i class="fa fa-check"></i><b>8.4.3</b> 因子旋转</a></li>
<li class="chapter" data-level="8.4.4" data-path="ms_4.html"><a href="ms_4.html#ms_4_5"><i class="fa fa-check"></i><b>8.4.4</b> 因子得分</a></li>
<li class="chapter" data-level="8.4.5" data-path="ms_4.html"><a href="ms_4.html#ms_4_6"><i class="fa fa-check"></i><b>8.4.5</b> 因子分析和主成分分析的区别与联系</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ms_5.html"><a href="ms_5.html"><i class="fa fa-check"></i><b>8.5</b> 判别分析</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="ms_5.html"><a href="ms_5.html#ms_5_1"><i class="fa fa-check"></i><b>8.5.1</b> 距离判别</a></li>
<li class="chapter" data-level="8.5.2" data-path="ms_5.html"><a href="ms_5.html#ms_5_2"><i class="fa fa-check"></i><b>8.5.2</b> 贝叶斯判别</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ms_6.html"><a href="ms_6.html"><i class="fa fa-check"></i><b>8.6</b> 聚类分析</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="ms_6.html"><a href="ms_6.html#ms_6_1"><i class="fa fa-check"></i><b>8.6.1</b> 距离与相似性的度量</a></li>
<li class="chapter" data-level="8.6.2" data-path="ms_6.html"><a href="ms_6.html#ms_6_2"><i class="fa fa-check"></i><b>8.6.2</b> 聚类效果的评价指标</a></li>
<li class="chapter" data-level="8.6.3" data-path="ms_6.html"><a href="ms_6.html#ms_6_3"><i class="fa fa-check"></i><b>8.6.3</b> 系统聚类</a></li>
<li class="chapter" data-level="8.6.4" data-path="ms_6.html"><a href="ms_6.html#ms_6_4"><i class="fa fa-check"></i><b>8.6.4</b> Kmeans</a></li>
<li class="chapter" data-level="8.6.5" data-path="ms_6.html"><a href="ms_6.html#ms_6_5"><i class="fa fa-check"></i><b>8.6.5</b> 其他聚类方法</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ms_7.html"><a href="ms_7.html"><i class="fa fa-check"></i><b>8.7</b> 典型相关分析</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i><b>9</b> 机器学习</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ml_1.html"><a href="ml_1.html"><i class="fa fa-check"></i><b>9.1</b> 基础知识</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ml_1.html"><a href="ml_1.html#ml_1_1"><i class="fa fa-check"></i><b>9.1.1</b> 偏差-方差权衡</a></li>
<li class="chapter" data-level="9.1.2" data-path="ml_1.html"><a href="ml_1.html#ml_1_2"><i class="fa fa-check"></i><b>9.1.2</b> 评价指标</a></li>
<li class="chapter" data-level="9.1.3" data-path="ml_1.html"><a href="ml_1.html#ml_1_3"><i class="fa fa-check"></i><b>9.1.3</b> 特征工程</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ml_2.html"><a href="ml_2.html"><i class="fa fa-check"></i><b>9.2</b> pandas与sklearn</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ml_2.html"><a href="ml_2.html#ml_2_1"><i class="fa fa-check"></i><b>9.2.1</b> 导入数据集</a></li>
<li class="chapter" data-level="9.2.2" data-path="ml_2.html"><a href="ml_2.html#ml_2_2"><i class="fa fa-check"></i><b>9.2.2</b> 数据预处理</a></li>
<li class="chapter" data-level="9.2.3" data-path="ml_2.html"><a href="ml_2.html#ml_2_3"><i class="fa fa-check"></i><b>9.2.3</b> 分割数据集</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ml_3.html"><a href="ml_3.html"><i class="fa fa-check"></i><b>9.3</b> 决策树</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="ml_3.html"><a href="ml_3.html#ml_3_1"><i class="fa fa-check"></i><b>9.3.1</b> 分类树</a></li>
<li class="chapter" data-level="9.3.2" data-path="ml_3.html"><a href="ml_3.html#ml_3_2"><i class="fa fa-check"></i><b>9.3.2</b> 回归树</a></li>
<li class="chapter" data-level="9.3.3" data-path="ml_3.html"><a href="ml_3.html#ml_3_3"><i class="fa fa-check"></i><b>9.3.3</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ml_4.html"><a href="ml_4.html"><i class="fa fa-check"></i><b>9.4</b> 随机森林</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="ml_4.html"><a href="ml_4.html#ml_4_1"><i class="fa fa-check"></i><b>9.4.1</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ml_5.html"><a href="ml_5.html"><i class="fa fa-check"></i><b>9.5</b> XGBoost</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="ml_5.html"><a href="ml_5.html#ml_5_1"><i class="fa fa-check"></i><b>9.5.1</b> 原理</a></li>
<li class="chapter" data-level="9.5.2" data-path="ml_5.html"><a href="ml_5.html#ml_5_2"><i class="fa fa-check"></i><b>9.5.2</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ml_6.html"><a href="ml_6.html"><i class="fa fa-check"></i><b>9.6</b> LightGBM</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="ml_6.html"><a href="ml_6.html#ml_6_1"><i class="fa fa-check"></i><b>9.6.1</b> 原理</a></li>
<li class="chapter" data-level="9.6.2" data-path="ml_6.html"><a href="ml_6.html#ml_6_2"><i class="fa fa-check"></i><b>9.6.2</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ml_7.html"><a href="ml_7.html"><i class="fa fa-check"></i><b>9.7</b> 因果森林</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="ml_7.html"><a href="ml_7.html#ml_7_1"><i class="fa fa-check"></i><b>9.7.1</b> 原理</a></li>
<li class="chapter" data-level="9.7.2" data-path="ml_7.html"><a href="ml_7.html#ml_7_2"><i class="fa fa-check"></i><b>9.7.2</b> 实现</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="ml_8.html"><a href="ml_8.html"><i class="fa fa-check"></i><b>9.8</b> SVM</a></li>
<li class="chapter" data-level="9.9" data-path="ml_9.html"><a href="ml_9.html"><i class="fa fa-check"></i><b>9.9</b> 聚类分析</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="ml_9.html"><a href="ml_9.html#ml_9_1"><i class="fa fa-check"></i><b>9.9.1</b> 聚类结果评价</a></li>
<li class="chapter" data-level="9.9.2" data-path="ml_9.html"><a href="ml_9.html#ml_9_2"><i class="fa fa-check"></i><b>9.9.2</b> Kmeans</a></li>
<li class="chapter" data-level="9.9.3" data-path="ml_9.html"><a href="ml_9.html#ml_9_3"><i class="fa fa-check"></i><b>9.9.3</b> Kmeans++</a></li>
<li class="chapter" data-level="9.9.4" data-path="ml_9.html"><a href="ml_9.html#ml_9_4"><i class="fa fa-check"></i><b>9.9.4</b> DBSCAN</a></li>
<li class="chapter" data-level="9.9.5" data-path="ml_9.html"><a href="ml_9.html#ml_9_5"><i class="fa fa-check"></i><b>9.9.5</b> HDBSCAN</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dl.html"><a href="dl.html"><i class="fa fa-check"></i><b>10</b> 深度学习</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dl_1.html"><a href="dl_1.html"><i class="fa fa-check"></i><b>10.1</b> 预备知识</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="dl_1.html"><a href="dl_1.html#dl_1_1"><i class="fa fa-check"></i><b>10.1.1</b> 数据操作</a></li>
<li class="chapter" data-level="10.1.2" data-path="dl_1.html"><a href="dl_1.html#dl_1_2"><i class="fa fa-check"></i><b>10.1.2</b> 自动微分</a></li>
<li class="chapter" data-level="10.1.3" data-path="dl_1.html"><a href="dl_1.html#dl_1_3"><i class="fa fa-check"></i><b>10.1.3</b> 加载数据集</a></li>
<li class="chapter" data-level="10.1.4" data-path="dl_1.html"><a href="dl_1.html#dl_1_4"><i class="fa fa-check"></i><b>10.1.4</b> 调参技巧</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="dl_2.html"><a href="dl_2.html"><i class="fa fa-check"></i><b>10.2</b> 线性神经网络</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="dl_2.html"><a href="dl_2.html#dl_2_1"><i class="fa fa-check"></i><b>10.2.1</b> 线性回归</a></li>
<li class="chapter" data-level="10.2.2" data-path="dl_2.html"><a href="dl_2.html#dl_2_2"><i class="fa fa-check"></i><b>10.2.2</b> 二分类问题</a></li>
<li class="chapter" data-level="10.2.3" data-path="dl_2.html"><a href="dl_2.html#dl_2_3"><i class="fa fa-check"></i><b>10.2.3</b> 多分类问题</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="dl_9.html"><a href="dl_9.html"><i class="fa fa-check"></i><b>10.3</b> RNN</a></li>
<li class="chapter" data-level="10.4" data-path="dl_3.html"><a href="dl_3.html"><i class="fa fa-check"></i><b>10.4</b> LSTM</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="dl_3.html"><a href="dl_3.html#dl_3_1"><i class="fa fa-check"></i><b>10.4.1</b> 原理</a></li>
<li class="chapter" data-level="10.4.2" data-path="dl_3.html"><a href="dl_3.html#dl_3_2"><i class="fa fa-check"></i><b>10.4.2</b> 示例</a></li>
<li class="chapter" data-level="10.4.3" data-path="dl_3.html"><a href="dl_3.html#dl_3_3"><i class="fa fa-check"></i><b>10.4.3</b> 拓展</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="dl_4.html"><a href="dl_4.html"><i class="fa fa-check"></i><b>10.5</b> GRU</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="dl_4.html"><a href="dl_4.html#dl_4_1"><i class="fa fa-check"></i><b>10.5.1</b> 原理</a></li>
<li class="chapter" data-level="10.5.2" data-path="dl_4.html"><a href="dl_4.html#dl_4_2"><i class="fa fa-check"></i><b>10.5.2</b> 示例</a></li>
<li class="chapter" data-level="10.5.3" data-path="dl_4.html"><a href="dl_4.html#dl_4_3"><i class="fa fa-check"></i><b>10.5.3</b> 拓展</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="dl_5.html"><a href="dl_5.html"><i class="fa fa-check"></i><b>10.6</b> Seq2Seq</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="dl_5.html"><a href="dl_5.html#dl_5_1"><i class="fa fa-check"></i><b>10.6.1</b> 原理</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="dl_6.html"><a href="dl_6.html"><i class="fa fa-check"></i><b>10.7</b> BNN</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="dl_6.html"><a href="dl_6.html#dl_6_1"><i class="fa fa-check"></i><b>10.7.1</b> 原理</a></li>
<li class="chapter" data-level="10.7.2" data-path="dl_6.html"><a href="dl_6.html#dl_6_2"><i class="fa fa-check"></i><b>10.7.2</b> 示例</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="dl_7.html"><a href="dl_7.html"><i class="fa fa-check"></i><b>10.8</b> GNN</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="dl_7.html"><a href="dl_7.html#dl_7_1"><i class="fa fa-check"></i><b>10.8.1</b> 原理</a></li>
<li class="chapter" data-level="10.8.2" data-path="dl_7.html"><a href="dl_7.html#dl_7_2"><i class="fa fa-check"></i><b>10.8.2</b> 图神经网络的类型</a></li>
<li class="chapter" data-level="10.8.3" data-path="dl_7.html"><a href="dl_7.html#dl_7_3"><i class="fa fa-check"></i><b>10.8.3</b> 示例</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="dl_8.html"><a href="dl_8.html"><i class="fa fa-check"></i><b>10.9</b> Diffusion Model</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="dl_8.html"><a href="dl_8.html#dl_8_1"><i class="fa fa-check"></i><b>10.9.1</b> 原理</a></li>
<li class="chapter" data-level="10.9.2" data-path="dl_8.html"><a href="dl_8.html#dl_8_2"><i class="fa fa-check"></i><b>10.9.2</b> 示例</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="dl_10.html"><a href="dl_10.html"><i class="fa fa-check"></i><b>10.10</b> Transformer</a>
<ul>
<li class="chapter" data-level="10.10.1" data-path="dl_10.html"><a href="dl_10.html#dl_10_1"><i class="fa fa-check"></i><b>10.10.1</b> 原理</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="dl_11.html"><a href="dl_11.html"><i class="fa fa-check"></i><b>10.11</b> BERT</a>
<ul>
<li class="chapter" data-level="10.11.1" data-path="dl_11.html"><a href="dl_11.html#dl_11_1"><i class="fa fa-check"></i><b>10.11.1</b> 原理</a></li>
</ul></li>
<li class="chapter" data-level="10.12" data-path="dl_12.html"><a href="dl_12.html"><i class="fa fa-check"></i><b>10.12</b> GPT</a>
<ul>
<li class="chapter" data-level="10.12.1" data-path="dl_12.html"><a href="dl_12.html#dl_12_1"><i class="fa fa-check"></i><b>10.12.1</b> GPT-1</a></li>
<li class="chapter" data-level="10.12.2" data-path="dl_12.html"><a href="dl_12.html#dl_12_2"><i class="fa fa-check"></i><b>10.12.2</b> GPT-2</a></li>
<li class="chapter" data-level="10.12.3" data-path="dl_12.html"><a href="dl_12.html#dl_12_3"><i class="fa fa-check"></i><b>10.12.3</b> GPT-3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="survival.html"><a href="survival.html"><i class="fa fa-check"></i><b>11</b> 生存分析</a>
<ul>
<li class="chapter" data-level="11.1" data-path="survival_1.html"><a href="survival_1.html"><i class="fa fa-check"></i><b>11.1</b> 基本概念</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="survival_1.html"><a href="survival_1.html#survival_1_1"><i class="fa fa-check"></i><b>11.1.1</b> 删失数据</a></li>
<li class="chapter" data-level="11.1.2" data-path="survival_1.html"><a href="survival_1.html#survival_1_2"><i class="fa fa-check"></i><b>11.1.2</b> 截断数据</a></li>
<li class="chapter" data-level="11.1.3" data-path="survival_1.html"><a href="survival_1.html#survival_1_3"><i class="fa fa-check"></i><b>11.1.3</b> 函数</a></li>
<li class="chapter" data-level="11.1.4" data-path="survival_1.html"><a href="survival_1.html#survival_1_4"><i class="fa fa-check"></i><b>11.1.4</b> 似然函数</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="survival_2.html"><a href="survival_2.html"><i class="fa fa-check"></i><b>11.2</b> 参数估计</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="survival_2.html"><a href="survival_2.html#survival_2_1"><i class="fa fa-check"></i><b>11.2.1</b> KM估计</a></li>
<li class="chapter" data-level="11.2.2" data-path="survival_2.html"><a href="survival_2.html#survival_2_2"><i class="fa fa-check"></i><b>11.2.2</b> NA估计</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="survival_3.html"><a href="survival_3.html"><i class="fa fa-check"></i><b>11.3</b> 置信区间与置信带</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="survival_3.html"><a href="survival_3.html#survival_3_1"><i class="fa fa-check"></i><b>11.3.1</b> 置信区间</a></li>
<li class="chapter" data-level="11.3.2" data-path="survival_3.html"><a href="survival_3.html#survival_3_2"><i class="fa fa-check"></i><b>11.3.2</b> 置信带</a></li>
<li class="chapter" data-level="11.3.3" data-path="survival_3.html"><a href="survival_3.html#survival_3_3"><i class="fa fa-check"></i><b>11.3.3</b> 平均生存时间的置信区间</a></li>
<li class="chapter" data-level="11.3.4" data-path="survival_3.html"><a href="survival_3.html#survival_3_4"><i class="fa fa-check"></i><b>11.3.4</b> 分位数的置信区间</a></li>
<li class="chapter" data-level="11.3.5" data-path="survival_3.html"><a href="survival_3.html#survival_3_5"><i class="fa fa-check"></i><b>11.3.5</b> 左截断数据的置信区间</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="survival_4.html"><a href="survival_4.html"><i class="fa fa-check"></i><b>11.4</b> 假设检验</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="survival_4.html"><a href="survival_4.html#survival_4_1"><i class="fa fa-check"></i><b>11.4.1</b> 单样本检验</a></li>
<li class="chapter" data-level="11.4.2" data-path="survival_4.html"><a href="survival_4.html#survival_4_2"><i class="fa fa-check"></i><b>11.4.2</b> 多样本检验</a></li>
<li class="chapter" data-level="11.4.3" data-path="survival_4.html"><a href="survival_4.html#survival_4_3"><i class="fa fa-check"></i><b>11.4.3</b> 趋势性检验</a></li>
<li class="chapter" data-level="11.4.4" data-path="survival_4.html"><a href="survival_4.html#survival_4_4"><i class="fa fa-check"></i><b>11.4.4</b> 分层检验</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="survival_5.html"><a href="survival_5.html"><i class="fa fa-check"></i><b>11.5</b> Cox比例风险模型</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="survival_5.html"><a href="survival_5.html#survival_5_1"><i class="fa fa-check"></i><b>11.5.1</b> 偏对数似然函数</a></li>
<li class="chapter" data-level="11.5.2" data-path="survival_5.html"><a href="survival_5.html#survival_5_x"><i class="fa fa-check"></i><b>11.5.2</b> Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="da.html"><a href="da.html"><i class="fa fa-check"></i><b>12</b> 数据分析</a>
<ul>
<li class="chapter" data-level="12.1" data-path="da_1.html"><a href="da_1.html"><i class="fa fa-check"></i><b>12.1</b> ABtest</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="da_1.html"><a href="da_1.html#da_1_1"><i class="fa fa-check"></i><b>12.1.1</b> 确定目标与指标选取</a></li>
<li class="chapter" data-level="12.1.2" data-path="da_1.html"><a href="da_1.html#da_1_2"><i class="fa fa-check"></i><b>12.1.2</b> 实验设计</a></li>
<li class="chapter" data-level="12.1.3" data-path="da_1.html"><a href="da_1.html#da_1_3"><i class="fa fa-check"></i><b>12.1.3</b> 实验上线</a></li>
<li class="chapter" data-level="12.1.4" data-path="da_1.html"><a href="da_1.html#da_1_4"><i class="fa fa-check"></i><b>12.1.4</b> 实验结束</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="da_2.html"><a href="da_2.html"><i class="fa fa-check"></i><b>12.2</b> 异动归因</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="da_2.html"><a href="da_2.html#da_2_1"><i class="fa fa-check"></i><b>12.2.1</b> 验真</a></li>
<li class="chapter" data-level="12.2.2" data-path="da_2.html"><a href="da_2.html#da_2_2"><i class="fa fa-check"></i><b>12.2.2</b> 维度拆解</a></li>
<li class="chapter" data-level="12.2.3" data-path="da_2.html"><a href="da_2.html#da_2_3"><i class="fa fa-check"></i><b>12.2.3</b> 贡献度分析</a></li>
<li class="chapter" data-level="12.2.4" data-path="da_2.html"><a href="da_2.html#da_2_4"><i class="fa fa-check"></i><b>12.2.4</b> 从数据原因到业务原因</a></li>
<li class="chapter" data-level="12.2.5" data-path="da_2.html"><a href="da_2.html#da_2_5"><i class="fa fa-check"></i><b>12.2.5</b> 案例分析</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="da_3.html"><a href="da_3.html"><i class="fa fa-check"></i><b>12.3</b> 用户分析</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="da_3.html"><a href="da_3.html#da_3_1"><i class="fa fa-check"></i><b>12.3.1</b> 用户画像</a></li>
<li class="chapter" data-level="12.3.2" data-path="da_3.html"><a href="da_3.html#da_3_2"><i class="fa fa-check"></i><b>12.3.2</b> 用户行为路径分析</a></li>
<li class="chapter" data-level="12.3.3" data-path="da_3.html"><a href="da_3.html#da_3_3"><i class="fa fa-check"></i><b>12.3.3</b> 用户分层模型</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 多源数据分析</b></span></li>
<li class="chapter" data-level="13" data-path="network.html"><a href="network.html"><i class="fa fa-check"></i><b>13</b> 网络型数据</a>
<ul>
<li class="chapter" data-level="13.1" data-path="network_1.html"><a href="network_1.html"><i class="fa fa-check"></i><b>13.1</b> 构造联系</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="network_1.html"><a href="network_1.html#network_1_1"><i class="fa fa-check"></i><b>13.1.1</b> 引力模型</a></li>
<li class="chapter" data-level="13.1.2" data-path="network_1.html"><a href="network_1.html#network_1_2"><i class="fa fa-check"></i><b>13.1.2</b> 社会网络量表</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="network_2.html"><a href="network_2.html"><i class="fa fa-check"></i><b>13.2</b> 网络结构特征</a></li>
<li class="chapter" data-level="13.3" data-path="network_3.html"><a href="network_3.html"><i class="fa fa-check"></i><b>13.3</b> 拓展分析</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="network_3.html"><a href="network_3.html#network_3_1"><i class="fa fa-check"></i><b>13.3.1</b> 凝聚子群</a></li>
<li class="chapter" data-level="13.3.2" data-path="network_3.html"><a href="network_3.html#network_3_2"><i class="fa fa-check"></i><b>13.3.2</b> 社区发现</a></li>
<li class="chapter" data-level="13.3.3" data-path="network_3.html"><a href="network_3.html#network_3_3"><i class="fa fa-check"></i><b>13.3.3</b> 核心-边缘分析</a></li>
<li class="chapter" data-level="13.3.4" data-path="network_3.html"><a href="network_3.html#network_3_4"><i class="fa fa-check"></i><b>13.3.4</b> QAP分析</a></li>
<li class="chapter" data-level="13.3.5" data-path="network_3.html"><a href="network_3.html#network_3_5"><i class="fa fa-check"></i><b>13.3.5</b> 计量模型</a></li>
<li class="chapter" data-level="13.3.6" data-path="network_3.html"><a href="network_3.html#network_3_6"><i class="fa fa-check"></i><b>13.3.6</b> 综合评价</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="network_4.html"><a href="network_4.html"><i class="fa fa-check"></i><b>13.4</b> 其他启示</a></li>
</ul></li>
<li class="part"><span><b>IV 可视化</b></span></li>
<li class="chapter" data-level="14" data-path="animation.html"><a href="animation.html"><i class="fa fa-check"></i><b>14</b> Manim动画</a>
<ul>
<li class="chapter" data-level="14.1" data-path="animation_1.html"><a href="animation_1.html"><i class="fa fa-check"></i><b>14.1</b> 最小二乘与投影矩阵</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="people.html"><a href="people.html"><i class="fa fa-check"></i><b>15</b> 七普数据可视化</a>
<ul>
<li class="chapter" data-level="15.1" data-path="people_1.html"><a href="people_1.html"><i class="fa fa-check"></i><b>15.1</b> 数据来源及说明</a></li>
<li class="chapter" data-level="15.2" data-path="people_2.html"><a href="people_2.html"><i class="fa fa-check"></i><b>15.2</b> 全国人口状况</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="people_2.html"><a href="people_2.html#people_2_1"><i class="fa fa-check"></i><b>15.2.1</b> 人口自然增长率</a></li>
<li class="chapter" data-level="15.2.2" data-path="people_2.html"><a href="people_2.html#people_2_2"><i class="fa fa-check"></i><b>15.2.2</b> 年龄结构</a></li>
<li class="chapter" data-level="15.2.3" data-path="people_2.html"><a href="people_2.html#people_2_3"><i class="fa fa-check"></i><b>15.2.3</b> 人口流动</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 组会论文</b></span></li>
<li class="chapter" data-level="16" data-path="penalty.html"><a href="penalty.html"><i class="fa fa-check"></i><b>16</b> 变量选择与惩罚函数</a>
<ul>
<li class="chapter" data-level="16.1" data-path="penalty_1.html"><a href="penalty_1.html"><i class="fa fa-check"></i><b>16.1</b> 准备</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="penalty_1.html"><a href="penalty_1.html#penalty_1_1"><i class="fa fa-check"></i><b>16.1.1</b> 范数</a></li>
<li class="chapter" data-level="16.1.2" data-path="penalty_1.html"><a href="penalty_1.html#penalty_1_2"><i class="fa fa-check"></i><b>16.1.2</b> 目标函数</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="penalty_2.html"><a href="penalty_2.html"><i class="fa fa-check"></i><b>16.2</b> 单变量选择</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_1"><i class="fa fa-check"></i><b>16.2.1</b> Lasso</a></li>
<li class="chapter" data-level="16.2.2" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_2"><i class="fa fa-check"></i><b>16.2.2</b> Hard &amp; Soft Threshold</a></li>
<li class="chapter" data-level="16.2.3" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_3"><i class="fa fa-check"></i><b>16.2.3</b> SCAD</a></li>
<li class="chapter" data-level="16.2.4" data-path="penalty_2.html"><a href="penalty_2.html#penalty_2_4"><i class="fa fa-check"></i><b>16.2.4</b> Adaptive Lasso</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="penalty_3.html"><a href="penalty_3.html"><i class="fa fa-check"></i><b>16.3</b> 群组变量选择</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_1"><i class="fa fa-check"></i><b>16.3.1</b> 思维导图</a></li>
<li class="chapter" data-level="16.3.2" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_2"><i class="fa fa-check"></i><b>16.3.2</b> 处理高度相关数据的组变量选择方法</a></li>
<li class="chapter" data-level="16.3.3" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_3"><i class="fa fa-check"></i><b>16.3.3</b> 仅能选择组变量的方法</a></li>
<li class="chapter" data-level="16.3.4" data-path="penalty_3.html"><a href="penalty_3.html#penalty_3_4"><i class="fa fa-check"></i><b>16.3.4</b> 双层变量选择方法</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="penalty_4.html"><a href="penalty_4.html"><i class="fa fa-check"></i><b>16.4</b> 算法</a></li>
<li class="chapter" data-level="16.5" data-path="penalty_5.html"><a href="penalty_5.html"><i class="fa fa-check"></i><b>16.5</b> 总结</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="integrative.html"><a href="integrative.html"><i class="fa fa-check"></i><b>17</b> 整合分析</a>
<ul>
<li class="chapter" data-level="17.1" data-path="integrative_1.html"><a href="integrative_1.html"><i class="fa fa-check"></i><b>17.1</b> 引言</a></li>
<li class="chapter" data-level="17.2" data-path="integrative_2.html"><a href="integrative_2.html"><i class="fa fa-check"></i><b>17.2</b> 模型基本形式</a></li>
<li class="chapter" data-level="17.3" data-path="integrative_3.html"><a href="integrative_3.html"><i class="fa fa-check"></i><b>17.3</b> 同构数据的整合分析</a></li>
<li class="chapter" data-level="17.4" data-path="integrative_4.html"><a href="integrative_4.html"><i class="fa fa-check"></i><b>17.4</b> 异构数据的整合分析</a></li>
<li class="chapter" data-level="17.5" data-path="integrative_5.html"><a href="integrative_5.html"><i class="fa fa-check"></i><b>17.5</b> 具有网络结构关系的整合分析</a></li>
</ul></li>
<li class="part"><span><b>VI 算法复现</b></span></li>
<li class="chapter" data-level="18" data-path="code.html"><a href="code.html"><i class="fa fa-check"></i><b>18</b> 算法复现</a>
<ul>
<li class="chapter" data-level="18.1" data-path="code_1.html"><a href="code_1.html"><i class="fa fa-check"></i><b>18.1</b> 惩罚Cox比例风险模型</a></li>
<li class="chapter" data-level="18.2" data-path="code_2.html"><a href="code_2.html"><i class="fa fa-check"></i><b>18.2</b> 异质截距项的线性模型</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="code_2.html"><a href="code_2.html#code_2_1"><i class="fa fa-check"></i><b>18.2.1</b> 自定义算法</a></li>
<li class="chapter" data-level="18.2.2" data-path="code_2.html"><a href="code_2.html#code_2_2"><i class="fa fa-check"></i><b>18.2.2</b> 数据模拟</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="code_3.html"><a href="code_3.html"><i class="fa fa-check"></i><b>18.3</b> （异质）线性+非线性的Cox比例风险模型</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="code_3.html"><a href="code_3.html#code_3_1"><i class="fa fa-check"></i><b>18.3.1</b> 自定义算法</a></li>
<li class="chapter" data-level="18.3.2" data-path="code_3.html"><a href="code_3.html#code_3_2"><i class="fa fa-check"></i><b>18.3.2</b> 数据模拟</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VII 生活</b></span></li>
<li class="chapter" data-level="19" data-path="ball.html"><a href="ball.html"><i class="fa fa-check"></i><b>19</b> 羽毛球修炼手册</a>
<ul>
<li class="chapter" data-level="19.1" data-path="ball_1.html"><a href="ball_1.html"><i class="fa fa-check"></i><b>19.1</b> 发球</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="ball_1.html"><a href="ball_1.html#ball_1_1"><i class="fa fa-check"></i><b>19.1.1</b> 正手发球</a></li>
<li class="chapter" data-level="19.1.2" data-path="ball_1.html"><a href="ball_1.html#ball_1_2"><i class="fa fa-check"></i><b>19.1.2</b> 反手发球</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="ball_2.html"><a href="ball_2.html"><i class="fa fa-check"></i><b>19.2</b> 网前技术</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="ball_2.html"><a href="ball_2.html#ball_2_1"><i class="fa fa-check"></i><b>19.2.1</b> 勾对角</a></li>
<li class="chapter" data-level="19.2.2" data-path="ball_2.html"><a href="ball_2.html#ball_2_2"><i class="fa fa-check"></i><b>19.2.2</b> 扑球</a></li>
<li class="chapter" data-level="19.2.3" data-path="ball_2.html"><a href="ball_2.html#ball_2_3"><i class="fa fa-check"></i><b>19.2.3</b> 封网</a></li>
<li class="chapter" data-level="19.2.4" data-path="ball_2.html"><a href="ball_2.html#ball_2_4"><i class="fa fa-check"></i><b>19.2.4</b> 平抽</a></li>
<li class="chapter" data-level="19.2.5" data-path="ball_2.html"><a href="ball_2.html#ball_2_5"><i class="fa fa-check"></i><b>19.2.5</b> 抹球</a></li>
<li class="chapter" data-level="19.2.6" data-path="ball_2.html"><a href="ball_2.html#ball_2_6"><i class="fa fa-check"></i><b>19.2.6</b> 搓球</a></li>
<li class="chapter" data-level="19.2.7" data-path="ball_2.html"><a href="ball_2.html#ball_2_7"><i class="fa fa-check"></i><b>19.2.7</b> 挡网</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="ball_3.html"><a href="ball_3.html"><i class="fa fa-check"></i><b>19.3</b> 后场技术</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="ball_3.html"><a href="ball_3.html#ball_3_1"><i class="fa fa-check"></i><b>19.3.1</b> 杀球</a></li>
<li class="chapter" data-level="19.3.2" data-path="ball_3.html"><a href="ball_3.html#ball_3_2"><i class="fa fa-check"></i><b>19.3.2</b> 吊球</a></li>
<li class="chapter" data-level="19.3.3" data-path="ball_3.html"><a href="ball_3.html#ball_3_3"><i class="fa fa-check"></i><b>19.3.3</b> 反手</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="ball_4.html"><a href="ball_4.html"><i class="fa fa-check"></i><b>19.4</b> 假动作</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="ball_4.html"><a href="ball_4.html#ball_4_1"><i class="fa fa-check"></i><b>19.4.1</b> 发接发</a></li>
<li class="chapter" data-level="19.4.2" data-path="ball_4.html"><a href="ball_4.html#ball_4_2"><i class="fa fa-check"></i><b>19.4.2</b> 网前</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="ball_5.html"><a href="ball_5.html"><i class="fa fa-check"></i><b>19.5</b> 双打</a>
<ul>
<li class="chapter" data-level="19.5.1" data-path="ball_5.html"><a href="ball_5.html#ball_5_1"><i class="fa fa-check"></i><b>19.5.1</b> 发接发</a></li>
<li class="chapter" data-level="19.5.2" data-path="ball_5.html"><a href="ball_5.html#ball_5_2"><i class="fa fa-check"></i><b>19.5.2</b> 站位</a></li>
<li class="chapter" data-level="19.5.3" data-path="ball_5.html"><a href="ball_5.html#ball_5_3"><i class="fa fa-check"></i><b>19.5.3</b> 分球</a></li>
<li class="chapter" data-level="19.5.4" data-path="ball_5.html"><a href="ball_5.html#ball_5_4"><i class="fa fa-check"></i><b>19.5.4</b> 球路</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="ball_6.html"><a href="ball_6.html"><i class="fa fa-check"></i><b>19.6</b> 球路</a></li>
<li class="chapter" data-level="19.7" data-path="ball_7.html"><a href="ball_7.html"><i class="fa fa-check"></i><b>19.7</b> 步伐</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="jap.html"><a href="jap.html"><i class="fa fa-check"></i><b>20</b> 日语</a></li>
<li class="chapter" data-level="" data-path=""><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><i class="fa fa-check"></i>参考文献</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">kj的学习笔记</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dl_2" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> 线性神经网络<a href="dl_2.html#dl_2" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h2>
<div id="dl_2_1" class="section level3 hasAnchor" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> 线性回归<a href="dl_2.html#dl_2_1" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h3>
<p><code>nn.Linear</code>是线性层，对输入数据进行仿射变换<span class="math inline">\(y=XW^T+b\)</span>，其中<span class="math inline">\(W\)</span>是权重矩阵，<span class="math inline">\(b\)</span>是偏置。</p>
<p>对于简单的线性回归模型，故只需一层线性层即可。</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb286-1"><a href="dl_2.html#cb286-1" tabindex="-1"></a>import torch</span>
<span id="cb286-2"><a href="dl_2.html#cb286-2" tabindex="-1"></a>import torch.nn as nn</span>
<span id="cb286-3"><a href="dl_2.html#cb286-3" tabindex="-1"></a>import torch.optim as optim</span>
<span id="cb286-4"><a href="dl_2.html#cb286-4" tabindex="-1"></a>from torch.utils.data import TensorDataset, DataLoader</span>
<span id="cb286-5"><a href="dl_2.html#cb286-5" tabindex="-1"></a></span>
<span id="cb286-6"><a href="dl_2.html#cb286-6" tabindex="-1"></a>torch.manual_seed(123)   # 设置全局随机数种子</span>
<span id="cb286-7"><a href="dl_2.html#cb286-7" tabindex="-1"></a></span>
<span id="cb286-8"><a href="dl_2.html#cb286-8" tabindex="-1"></a>X = torch.randn(100,2)   # 标准正态抽样</span>
<span id="cb286-9"><a href="dl_2.html#cb286-9" tabindex="-1"></a>beta = torch.rand(2)     # 均匀分布[0,1)抽样</span>
<span id="cb286-10"><a href="dl_2.html#cb286-10" tabindex="-1"></a>intercept = torch.rand(1)</span>
<span id="cb286-11"><a href="dl_2.html#cb286-11" tabindex="-1"></a>y = intercept + torch.matmul(X, beta) + torch.randn(100)*0.1</span>
<span id="cb286-12"><a href="dl_2.html#cb286-12" tabindex="-1"></a>y = y.reshape(-1,1)</span>
<span id="cb286-13"><a href="dl_2.html#cb286-13" tabindex="-1"></a></span>
<span id="cb286-14"><a href="dl_2.html#cb286-14" tabindex="-1"></a>dataset = TensorDataset(X,y)</span>
<span id="cb286-15"><a href="dl_2.html#cb286-15" tabindex="-1"></a>dataloader = DataLoader(dataset, batch_size=10, shuffle=True)</span>
<span id="cb286-16"><a href="dl_2.html#cb286-16" tabindex="-1"></a></span>
<span id="cb286-17"><a href="dl_2.html#cb286-17" tabindex="-1"></a># 搭建网络结构</span>
<span id="cb286-18"><a href="dl_2.html#cb286-18" tabindex="-1"></a>linear_model = nn.Sequential(</span>
<span id="cb286-19"><a href="dl_2.html#cb286-19" tabindex="-1"></a>    nn.Linear(2,1)</span>
<span id="cb286-20"><a href="dl_2.html#cb286-20" tabindex="-1"></a>)</span>
<span id="cb286-21"><a href="dl_2.html#cb286-21" tabindex="-1"></a></span>
<span id="cb286-22"><a href="dl_2.html#cb286-22" tabindex="-1"></a>criterion = nn.MSELoss()</span>
<span id="cb286-23"><a href="dl_2.html#cb286-23" tabindex="-1"></a>optimizer = optim.SGD(linear_model.parameters(), lr=0.05)   # lr为学习率</span>
<span id="cb286-24"><a href="dl_2.html#cb286-24" tabindex="-1"></a></span>
<span id="cb286-25"><a href="dl_2.html#cb286-25" tabindex="-1"></a>for epoch in range(100):       # 迭代50次</span>
<span id="cb286-26"><a href="dl_2.html#cb286-26" tabindex="-1"></a>    linear_model.train()       # 训练模式</span>
<span id="cb286-27"><a href="dl_2.html#cb286-27" tabindex="-1"></a>    for batch_X, batch_y in dataloader:</span>
<span id="cb286-28"><a href="dl_2.html#cb286-28" tabindex="-1"></a>        y_pred = linear_model(batch_X)     # 前向传播，计算预测值</span>
<span id="cb286-29"><a href="dl_2.html#cb286-29" tabindex="-1"></a>        loss = criterion(y_pred, batch_y)  # 计算损失</span>
<span id="cb286-30"><a href="dl_2.html#cb286-30" tabindex="-1"></a>        optimizer.zero_grad()  # 清零梯度</span>
<span id="cb286-31"><a href="dl_2.html#cb286-31" tabindex="-1"></a>        loss.backward()        # 反向传播，计算梯度</span>
<span id="cb286-32"><a href="dl_2.html#cb286-32" tabindex="-1"></a>        optimizer.step()       # 更新模型参数</span>
<span id="cb286-33"><a href="dl_2.html#cb286-33" tabindex="-1"></a>    linear_model.eval()        # 评估模式</span>
<span id="cb286-34"><a href="dl_2.html#cb286-34" tabindex="-1"></a>    with torch.no_grad():</span>
<span id="cb286-35"><a href="dl_2.html#cb286-35" tabindex="-1"></a>        epoch_loss = criterion(linear_model(X),y)</span>
<span id="cb286-36"><a href="dl_2.html#cb286-36" tabindex="-1"></a>        if (epoch + 1) % 10 == 0:</span>
<span id="cb286-37"><a href="dl_2.html#cb286-37" tabindex="-1"></a>            print(f&#39;Epoch_{epoch + 1}: {epoch_loss.item():.6f}&#39;)</span>
<span id="cb286-38"><a href="dl_2.html#cb286-38" tabindex="-1"></a></span>
<span id="cb286-39"><a href="dl_2.html#cb286-39" tabindex="-1"></a>print(linear_model)                  # 查看网络结构</span>
<span id="cb286-40"><a href="dl_2.html#cb286-40" tabindex="-1"></a>print(linear_model[0].weight.data)   # 查看第0层的权重</span>
<span id="cb286-41"><a href="dl_2.html#cb286-41" tabindex="-1"></a>print(linear_model[0].bias.data)     # 查看第0层的偏置</span></code></pre></div>
<p>说明：</p>
<ol style="list-style-type: decimal">
<li><p><code>DataLoader()</code>将数据分批次，变为可迭代的对象，每次返回一个批次的数据。也可结合<code>enumerate()</code>适用。</p></li>
<li><p><code>nn.Sequential()</code><strong>按顺序</strong>组织多个神经网络层，相较自定义类无需定义<code>forward</code>方法，适用于简单场合的模型构建。</p></li>
</ol>
<blockquote>
<p>除了<code>nn.Sequential()</code>，还可以通过继承<code>nn.Module</code>来自定义模型架构，从而创建更复杂的模型</p>
</blockquote>
<ol start="3" style="list-style-type: decimal">
<li><p><code>nn.Linear()</code>是线性全连接层，用来实现仿射变换<span class="math inline">\(y=XW^T+b\)</span>。</p></li>
<li><p><code>nn.MSELoss()</code>定义了损失函数的类型，计算两个形状相同的张量之间的MSE</p></li>
<li><p><code>optim.SGD()</code>定义了优化算法为随机梯度下降法，<code>linear_model.parameters()</code>用于传递需要优化的参数。</p></li>
<li><p><code>.train()</code>、<code>.eval()</code>分别代表模型的训练模式和评估模式，不同模式下会影响部分层(如Dropout层)的行为，一般在训练时开始<code>.train()</code>，在计算相关指标时<code>.eval()</code>。特别的，在评估时还可配合<code>torch.no_grad()</code>来禁用梯度计算，节省内存和计算资源，从而提高计算速度。</p></li>
</ol>
</div>
<div id="dl_2_2" class="section level3 hasAnchor" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> 二分类问题<a href="dl_2.html#dl_2_2" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h3>
<p>对于二分类问题，输出层的维度应该为1，并且输出层的激活函数为Sigmoid函数，损失函数为<code>nn.BCELoss()</code>等适用于二分类场合的函数。</p>
<blockquote>
<p><code>nn.BCELoss()</code>即<span class="math inline">\(-y_i \log \hat y_i - (1-y_i)\log (1-\hat y_i)\)</span></p>
</blockquote>
<div class="sourceCode" id="cb287"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb287-1"><a href="dl_2.html#cb287-1" tabindex="-1"></a>import torch</span>
<span id="cb287-2"><a href="dl_2.html#cb287-2" tabindex="-1"></a>import torch.nn as nn</span>
<span id="cb287-3"><a href="dl_2.html#cb287-3" tabindex="-1"></a>import torch.optim as optim</span>
<span id="cb287-4"><a href="dl_2.html#cb287-4" tabindex="-1"></a>from sklearn.datasets import make_classification</span>
<span id="cb287-5"><a href="dl_2.html#cb287-5" tabindex="-1"></a>from sklearn.model_selection import train_test_split</span>
<span id="cb287-6"><a href="dl_2.html#cb287-6" tabindex="-1"></a>from sklearn.preprocessing import StandardScaler</span>
<span id="cb287-7"><a href="dl_2.html#cb287-7" tabindex="-1"></a>import numpy as np</span>
<span id="cb287-8"><a href="dl_2.html#cb287-8" tabindex="-1"></a>from torch.utils.data import TensorDataset, DataLoader</span>
<span id="cb287-9"><a href="dl_2.html#cb287-9" tabindex="-1"></a></span>
<span id="cb287-10"><a href="dl_2.html#cb287-10" tabindex="-1"></a># 设置随机数种子</span>
<span id="cb287-11"><a href="dl_2.html#cb287-11" tabindex="-1"></a>torch.manual_seed(123)</span>
<span id="cb287-12"><a href="dl_2.html#cb287-12" tabindex="-1"></a>np.random.seed(321)</span>
<span id="cb287-13"><a href="dl_2.html#cb287-13" tabindex="-1"></a></span>
<span id="cb287-14"><a href="dl_2.html#cb287-14" tabindex="-1"></a>def gen_data(n_samples=2000, n_features=10, n_classes=2):</span>
<span id="cb287-15"><a href="dl_2.html#cb287-15" tabindex="-1"></a></span>
<span id="cb287-16"><a href="dl_2.html#cb287-16" tabindex="-1"></a>    # 生成复杂的分类型数据（有重叠）</span>
<span id="cb287-17"><a href="dl_2.html#cb287-17" tabindex="-1"></a>    X, y = make_classification(</span>
<span id="cb287-18"><a href="dl_2.html#cb287-18" tabindex="-1"></a>        n_samples=n_samples,    # 样本数</span>
<span id="cb287-19"><a href="dl_2.html#cb287-19" tabindex="-1"></a>        n_features=n_features,  # 特征数</span>
<span id="cb287-20"><a href="dl_2.html#cb287-20" tabindex="-1"></a>        n_informative=8,        # 有信息量的特征数量</span>
<span id="cb287-21"><a href="dl_2.html#cb287-21" tabindex="-1"></a>        n_redundant=2,          # 冗余特征数量</span>
<span id="cb287-22"><a href="dl_2.html#cb287-22" tabindex="-1"></a>        n_repeated=0,           # 重复特征数量</span>
<span id="cb287-23"><a href="dl_2.html#cb287-23" tabindex="-1"></a>        n_classes=n_classes,    # 类别数</span>
<span id="cb287-24"><a href="dl_2.html#cb287-24" tabindex="-1"></a>        flip_y=0.15,            # 15%的噪声</span>
<span id="cb287-25"><a href="dl_2.html#cb287-25" tabindex="-1"></a>        class_sep=0.8           # 类间分离程度</span>
<span id="cb287-26"><a href="dl_2.html#cb287-26" tabindex="-1"></a>    )</span>
<span id="cb287-27"><a href="dl_2.html#cb287-27" tabindex="-1"></a>    </span>
<span id="cb287-28"><a href="dl_2.html#cb287-28" tabindex="-1"></a>    # 划分训练集和测试集</span>
<span id="cb287-29"><a href="dl_2.html#cb287-29" tabindex="-1"></a>    X_train, X_test, y_train, y_test = train_test_split(</span>
<span id="cb287-30"><a href="dl_2.html#cb287-30" tabindex="-1"></a>        X, y, test_size=0.2, random_state=42</span>
<span id="cb287-31"><a href="dl_2.html#cb287-31" tabindex="-1"></a>    )</span>
<span id="cb287-32"><a href="dl_2.html#cb287-32" tabindex="-1"></a>    </span>
<span id="cb287-33"><a href="dl_2.html#cb287-33" tabindex="-1"></a>    # 数据标准化</span>
<span id="cb287-34"><a href="dl_2.html#cb287-34" tabindex="-1"></a>    scaler = StandardScaler()</span>
<span id="cb287-35"><a href="dl_2.html#cb287-35" tabindex="-1"></a>    X_train = scaler.fit_transform(X_train)</span>
<span id="cb287-36"><a href="dl_2.html#cb287-36" tabindex="-1"></a>    X_test = scaler.transform(X_test)</span>
<span id="cb287-37"><a href="dl_2.html#cb287-37" tabindex="-1"></a></span>
<span id="cb287-38"><a href="dl_2.html#cb287-38" tabindex="-1"></a>    # 转换为PyTorch张量</span>
<span id="cb287-39"><a href="dl_2.html#cb287-39" tabindex="-1"></a>    X_train = torch.tensor(X_train, dtype=torch.float32)</span>
<span id="cb287-40"><a href="dl_2.html#cb287-40" tabindex="-1"></a>    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # 二分类需要二维标签</span>
<span id="cb287-41"><a href="dl_2.html#cb287-41" tabindex="-1"></a>    X_test = torch.tensor(X_test, dtype=torch.float32)</span>
<span id="cb287-42"><a href="dl_2.html#cb287-42" tabindex="-1"></a>    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)</span>
<span id="cb287-43"><a href="dl_2.html#cb287-43" tabindex="-1"></a>    </span>
<span id="cb287-44"><a href="dl_2.html#cb287-44" tabindex="-1"></a>    return X_train, X_test, y_train, y_test</span>
<span id="cb287-45"><a href="dl_2.html#cb287-45" tabindex="-1"></a></span>
<span id="cb287-46"><a href="dl_2.html#cb287-46" tabindex="-1"></a># 生成数据</span>
<span id="cb287-47"><a href="dl_2.html#cb287-47" tabindex="-1"></a>X_train, X_test, y_train, y_test = gen_data()</span>
<span id="cb287-48"><a href="dl_2.html#cb287-48" tabindex="-1"></a></span>
<span id="cb287-49"><a href="dl_2.html#cb287-49" tabindex="-1"></a># 创建数据加载器</span>
<span id="cb287-50"><a href="dl_2.html#cb287-50" tabindex="-1"></a>train_dataset = TensorDataset(X_train, y_train)</span>
<span id="cb287-51"><a href="dl_2.html#cb287-51" tabindex="-1"></a>test_dataset = TensorDataset(X_test, y_test)</span>
<span id="cb287-52"><a href="dl_2.html#cb287-52" tabindex="-1"></a></span>
<span id="cb287-53"><a href="dl_2.html#cb287-53" tabindex="-1"></a>train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)</span>
<span id="cb287-54"><a href="dl_2.html#cb287-54" tabindex="-1"></a>test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)</span>
<span id="cb287-55"><a href="dl_2.html#cb287-55" tabindex="-1"></a></span>
<span id="cb287-56"><a href="dl_2.html#cb287-56" tabindex="-1"></a>model = nn.Sequential(</span>
<span id="cb287-57"><a href="dl_2.html#cb287-57" tabindex="-1"></a>    nn.Linear(10,64),</span>
<span id="cb287-58"><a href="dl_2.html#cb287-58" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb287-59"><a href="dl_2.html#cb287-59" tabindex="-1"></a>    nn.BatchNorm1d(64),  # 对该批次数据进行标准化操作，并进行缩放和平移，可在一定程度上缓解“内部协变量偏移”情况</span>
<span id="cb287-60"><a href="dl_2.html#cb287-60" tabindex="-1"></a>    nn.Dropout(0.2),     # 以一定概率丢弃某些神经元，从而缓解过拟合现象</span>
<span id="cb287-61"><a href="dl_2.html#cb287-61" tabindex="-1"></a>    </span>
<span id="cb287-62"><a href="dl_2.html#cb287-62" tabindex="-1"></a>    nn.Linear(64,32),</span>
<span id="cb287-63"><a href="dl_2.html#cb287-63" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb287-64"><a href="dl_2.html#cb287-64" tabindex="-1"></a>    nn.BatchNorm1d(32),</span>
<span id="cb287-65"><a href="dl_2.html#cb287-65" tabindex="-1"></a>    nn.Dropout(0.2),</span>
<span id="cb287-66"><a href="dl_2.html#cb287-66" tabindex="-1"></a>    </span>
<span id="cb287-67"><a href="dl_2.html#cb287-67" tabindex="-1"></a>    nn.Linear(32,1),</span>
<span id="cb287-68"><a href="dl_2.html#cb287-68" tabindex="-1"></a>    nn.Sigmoid()</span>
<span id="cb287-69"><a href="dl_2.html#cb287-69" tabindex="-1"></a>)</span>
<span id="cb287-70"><a href="dl_2.html#cb287-70" tabindex="-1"></a></span>
<span id="cb287-71"><a href="dl_2.html#cb287-71" tabindex="-1"></a>criterion = nn.BCELoss()</span>
<span id="cb287-72"><a href="dl_2.html#cb287-72" tabindex="-1"></a>optimizer = optim.SGD(model.parameters(), lr=0.05)</span>
<span id="cb287-73"><a href="dl_2.html#cb287-73" tabindex="-1"></a></span>
<span id="cb287-74"><a href="dl_2.html#cb287-74" tabindex="-1"></a># 将模型移到GPU上</span>
<span id="cb287-75"><a href="dl_2.html#cb287-75" tabindex="-1"></a>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
<span id="cb287-76"><a href="dl_2.html#cb287-76" tabindex="-1"></a>model.to(device)</span>
<span id="cb287-77"><a href="dl_2.html#cb287-77" tabindex="-1"></a></span>
<span id="cb287-78"><a href="dl_2.html#cb287-78" tabindex="-1"></a># 存储训练指标</span>
<span id="cb287-79"><a href="dl_2.html#cb287-79" tabindex="-1"></a>train_losses = []</span>
<span id="cb287-80"><a href="dl_2.html#cb287-80" tabindex="-1"></a>train_accuracies = []</span>
<span id="cb287-81"><a href="dl_2.html#cb287-81" tabindex="-1"></a>val_losses = []</span>
<span id="cb287-82"><a href="dl_2.html#cb287-82" tabindex="-1"></a>val_accuracies = []</span>
<span id="cb287-83"><a href="dl_2.html#cb287-83" tabindex="-1"></a></span>
<span id="cb287-84"><a href="dl_2.html#cb287-84" tabindex="-1"></a>for epoch in range(100):</span>
<span id="cb287-85"><a href="dl_2.html#cb287-85" tabindex="-1"></a>    # 训练模式</span>
<span id="cb287-86"><a href="dl_2.html#cb287-86" tabindex="-1"></a>    model.train()</span>
<span id="cb287-87"><a href="dl_2.html#cb287-87" tabindex="-1"></a>    running_loss = 0.0</span>
<span id="cb287-88"><a href="dl_2.html#cb287-88" tabindex="-1"></a>    correct_train = 0</span>
<span id="cb287-89"><a href="dl_2.html#cb287-89" tabindex="-1"></a>    total_train = 0</span>
<span id="cb287-90"><a href="dl_2.html#cb287-90" tabindex="-1"></a>    </span>
<span id="cb287-91"><a href="dl_2.html#cb287-91" tabindex="-1"></a>    for batch_x, batch_y in train_loader:</span>
<span id="cb287-92"><a href="dl_2.html#cb287-92" tabindex="-1"></a>        # 移动数据到设备</span>
<span id="cb287-93"><a href="dl_2.html#cb287-93" tabindex="-1"></a>        batch_x, batch_y = batch_x.to(device), batch_y.to(device)</span>
<span id="cb287-94"><a href="dl_2.html#cb287-94" tabindex="-1"></a>        </span>
<span id="cb287-95"><a href="dl_2.html#cb287-95" tabindex="-1"></a>        # 前向传播</span>
<span id="cb287-96"><a href="dl_2.html#cb287-96" tabindex="-1"></a>        outputs = model(batch_x)</span>
<span id="cb287-97"><a href="dl_2.html#cb287-97" tabindex="-1"></a>        </span>
<span id="cb287-98"><a href="dl_2.html#cb287-98" tabindex="-1"></a>        # 计算损失</span>
<span id="cb287-99"><a href="dl_2.html#cb287-99" tabindex="-1"></a>        loss = criterion(outputs, batch_y)</span>
<span id="cb287-100"><a href="dl_2.html#cb287-100" tabindex="-1"></a>        </span>
<span id="cb287-101"><a href="dl_2.html#cb287-101" tabindex="-1"></a>        # 反向传播和优化</span>
<span id="cb287-102"><a href="dl_2.html#cb287-102" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb287-103"><a href="dl_2.html#cb287-103" tabindex="-1"></a>        loss.backward()</span>
<span id="cb287-104"><a href="dl_2.html#cb287-104" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb287-105"><a href="dl_2.html#cb287-105" tabindex="-1"></a>        </span>
<span id="cb287-106"><a href="dl_2.html#cb287-106" tabindex="-1"></a>        # 统计训练情况</span>
<span id="cb287-107"><a href="dl_2.html#cb287-107" tabindex="-1"></a>        running_loss += loss.item()</span>
<span id="cb287-108"><a href="dl_2.html#cb287-108" tabindex="-1"></a>        </span>
<span id="cb287-109"><a href="dl_2.html#cb287-109" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb287-110"><a href="dl_2.html#cb287-110" tabindex="-1"></a>        predictions = (outputs &gt; 0.5).float()</span>
<span id="cb287-111"><a href="dl_2.html#cb287-111" tabindex="-1"></a>        correct_train += (predictions == batch_y).sum().item()</span>
<span id="cb287-112"><a href="dl_2.html#cb287-112" tabindex="-1"></a>        total_train += batch_y.size(0)</span>
<span id="cb287-113"><a href="dl_2.html#cb287-113" tabindex="-1"></a>    </span>
<span id="cb287-114"><a href="dl_2.html#cb287-114" tabindex="-1"></a>    # 计算本轮训练的平均损失和准确率</span>
<span id="cb287-115"><a href="dl_2.html#cb287-115" tabindex="-1"></a>    epoch_loss = running_loss / len(train_loader)</span>
<span id="cb287-116"><a href="dl_2.html#cb287-116" tabindex="-1"></a>    epoch_acc = correct_train / total_train if total_train &gt; 0 else 0</span>
<span id="cb287-117"><a href="dl_2.html#cb287-117" tabindex="-1"></a>    train_losses.append(epoch_loss)</span>
<span id="cb287-118"><a href="dl_2.html#cb287-118" tabindex="-1"></a>    train_accuracies.append(epoch_acc)</span>
<span id="cb287-119"><a href="dl_2.html#cb287-119" tabindex="-1"></a>    </span>
<span id="cb287-120"><a href="dl_2.html#cb287-120" tabindex="-1"></a>    # 验证评估</span>
<span id="cb287-121"><a href="dl_2.html#cb287-121" tabindex="-1"></a>    model.eval()</span>
<span id="cb287-122"><a href="dl_2.html#cb287-122" tabindex="-1"></a>    with torch.no_grad():</span>
<span id="cb287-123"><a href="dl_2.html#cb287-123" tabindex="-1"></a>        # 移动测试数据到设备</span>
<span id="cb287-124"><a href="dl_2.html#cb287-124" tabindex="-1"></a>        test_x, test_y = X_test.to(device), y_test.to(device)</span>
<span id="cb287-125"><a href="dl_2.html#cb287-125" tabindex="-1"></a>        # 前向传播</span>
<span id="cb287-126"><a href="dl_2.html#cb287-126" tabindex="-1"></a>        outputs = model(test_x)</span>
<span id="cb287-127"><a href="dl_2.html#cb287-127" tabindex="-1"></a>        # 计算损失</span>
<span id="cb287-128"><a href="dl_2.html#cb287-128" tabindex="-1"></a>        val_loss = criterion(outputs, test_y).item()</span>
<span id="cb287-129"><a href="dl_2.html#cb287-129" tabindex="-1"></a>        # 计算预测结果</span>
<span id="cb287-130"><a href="dl_2.html#cb287-130" tabindex="-1"></a>        predictions = (outputs &gt; 0.5).float()</span>
<span id="cb287-131"><a href="dl_2.html#cb287-131" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb287-132"><a href="dl_2.html#cb287-132" tabindex="-1"></a>        correct_val = (predictions == test_y).sum().item()</span>
<span id="cb287-133"><a href="dl_2.html#cb287-133" tabindex="-1"></a>        total_val = test_y.size(0)</span>
<span id="cb287-134"><a href="dl_2.html#cb287-134" tabindex="-1"></a>        val_acc = correct_val / total_val</span>
<span id="cb287-135"><a href="dl_2.html#cb287-135" tabindex="-1"></a>        # 存储验证结果</span>
<span id="cb287-136"><a href="dl_2.html#cb287-136" tabindex="-1"></a>        val_losses.append(val_loss)</span>
<span id="cb287-137"><a href="dl_2.html#cb287-137" tabindex="-1"></a>        val_accuracies.append(val_acc)</span>
<span id="cb287-138"><a href="dl_2.html#cb287-138" tabindex="-1"></a>    </span>
<span id="cb287-139"><a href="dl_2.html#cb287-139" tabindex="-1"></a>    # 每10个epoch打印一次进度</span>
<span id="cb287-140"><a href="dl_2.html#cb287-140" tabindex="-1"></a>    if (epoch + 1) % 10 == 0:</span>
<span id="cb287-141"><a href="dl_2.html#cb287-141" tabindex="-1"></a>        print(&quot;=&quot;*10,</span>
<span id="cb287-142"><a href="dl_2.html#cb287-142" tabindex="-1"></a>              f&quot;Epoch_{epoch+1}&quot;,</span>
<span id="cb287-143"><a href="dl_2.html#cb287-143" tabindex="-1"></a>              &quot;=&quot;*10,</span>
<span id="cb287-144"><a href="dl_2.html#cb287-144" tabindex="-1"></a>              f&quot;\nTrain Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\n&quot;,</span>
<span id="cb287-145"><a href="dl_2.html#cb287-145" tabindex="-1"></a>              f&quot;Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}&quot;)</span></code></pre></div>
<p>说明：</p>
<ol style="list-style-type: decimal">
<li><p>在将数据存储为张量时就要统一特征和标签的数据类型为浮点数，否则后续特征为浮点数，标签为整数会报错。同时，标签的形状也应变为二维的。</p></li>
<li><p><code>nn.BatchNorm1d()</code>对该批次数据进行标准化操作，并进行缩放和平移，可在一定程度上缓解“内部协变量偏移”情况</p></li>
<li><p><code>nn.Dropout()</code>在训练<code>model.train()</code>时会以一定概率丢弃某些神经元，从而缓解过拟合现象，是一种正则化技术。</p></li>
<li><p>无论如何，模型和数据都要在同一设备上。张量数据必须重新赋值<code>batch_x = batch_x.to(device)</code>，而模型则可以直接<code>model.to(device)</code></p></li>
</ol>
</div>
<div id="dl_2_3" class="section level3 hasAnchor" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> 多分类问题<a href="dl_2.html#dl_2_3" class="anchor-section" aria-label="Anchor link to header" target="_blank"></a></h3>
<p>对于多分类问题，输出层维度为类别数，无需添加softmax函数，因为在交叉熵损失函数<code>nn.CrossEntropyLoss()</code>中自带了softmax运算。</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb288-1"><a href="dl_2.html#cb288-1" tabindex="-1"></a>import torch</span>
<span id="cb288-2"><a href="dl_2.html#cb288-2" tabindex="-1"></a>import torch.nn as nn</span>
<span id="cb288-3"><a href="dl_2.html#cb288-3" tabindex="-1"></a>import torch.optim as optim</span>
<span id="cb288-4"><a href="dl_2.html#cb288-4" tabindex="-1"></a>from sklearn.datasets import make_classification</span>
<span id="cb288-5"><a href="dl_2.html#cb288-5" tabindex="-1"></a>from sklearn.model_selection import train_test_split</span>
<span id="cb288-6"><a href="dl_2.html#cb288-6" tabindex="-1"></a>from sklearn.preprocessing import StandardScaler</span>
<span id="cb288-7"><a href="dl_2.html#cb288-7" tabindex="-1"></a>import numpy as np</span>
<span id="cb288-8"><a href="dl_2.html#cb288-8" tabindex="-1"></a>from torch.utils.data import TensorDataset, DataLoader</span>
<span id="cb288-9"><a href="dl_2.html#cb288-9" tabindex="-1"></a></span>
<span id="cb288-10"><a href="dl_2.html#cb288-10" tabindex="-1"></a># 设置随机数种子</span>
<span id="cb288-11"><a href="dl_2.html#cb288-11" tabindex="-1"></a>torch.manual_seed(123)</span>
<span id="cb288-12"><a href="dl_2.html#cb288-12" tabindex="-1"></a>np.random.seed(321)</span>
<span id="cb288-13"><a href="dl_2.html#cb288-13" tabindex="-1"></a></span>
<span id="cb288-14"><a href="dl_2.html#cb288-14" tabindex="-1"></a>def gen_data(n_samples=2000, n_features=10, n_classes=5):</span>
<span id="cb288-15"><a href="dl_2.html#cb288-15" tabindex="-1"></a></span>
<span id="cb288-16"><a href="dl_2.html#cb288-16" tabindex="-1"></a>    # 生成复杂的分类型数据（有重叠）</span>
<span id="cb288-17"><a href="dl_2.html#cb288-17" tabindex="-1"></a>    X, y = make_classification(</span>
<span id="cb288-18"><a href="dl_2.html#cb288-18" tabindex="-1"></a>        n_samples=n_samples,    # 样本数</span>
<span id="cb288-19"><a href="dl_2.html#cb288-19" tabindex="-1"></a>        n_features=n_features,  # 特征数</span>
<span id="cb288-20"><a href="dl_2.html#cb288-20" tabindex="-1"></a>        n_informative=8,        # 有信息量的特征数量</span>
<span id="cb288-21"><a href="dl_2.html#cb288-21" tabindex="-1"></a>        n_redundant=2,          # 冗余特征数量</span>
<span id="cb288-22"><a href="dl_2.html#cb288-22" tabindex="-1"></a>        n_repeated=0,           # 重复特征数量</span>
<span id="cb288-23"><a href="dl_2.html#cb288-23" tabindex="-1"></a>        n_classes=n_classes,    # 类别数</span>
<span id="cb288-24"><a href="dl_2.html#cb288-24" tabindex="-1"></a>        flip_y=0.15,            # 15%的噪声</span>
<span id="cb288-25"><a href="dl_2.html#cb288-25" tabindex="-1"></a>        class_sep=0.8           # 类间分离程度</span>
<span id="cb288-26"><a href="dl_2.html#cb288-26" tabindex="-1"></a>    )</span>
<span id="cb288-27"><a href="dl_2.html#cb288-27" tabindex="-1"></a>    </span>
<span id="cb288-28"><a href="dl_2.html#cb288-28" tabindex="-1"></a>    # 划分训练集和测试集</span>
<span id="cb288-29"><a href="dl_2.html#cb288-29" tabindex="-1"></a>    X_train, X_test, y_train, y_test = train_test_split(</span>
<span id="cb288-30"><a href="dl_2.html#cb288-30" tabindex="-1"></a>        X, y, test_size=0.2, random_state=42</span>
<span id="cb288-31"><a href="dl_2.html#cb288-31" tabindex="-1"></a>    )</span>
<span id="cb288-32"><a href="dl_2.html#cb288-32" tabindex="-1"></a>    </span>
<span id="cb288-33"><a href="dl_2.html#cb288-33" tabindex="-1"></a>    # 数据标准化</span>
<span id="cb288-34"><a href="dl_2.html#cb288-34" tabindex="-1"></a>    scaler = StandardScaler()</span>
<span id="cb288-35"><a href="dl_2.html#cb288-35" tabindex="-1"></a>    X_train = scaler.fit_transform(X_train)</span>
<span id="cb288-36"><a href="dl_2.html#cb288-36" tabindex="-1"></a>    X_test = scaler.transform(X_test)</span>
<span id="cb288-37"><a href="dl_2.html#cb288-37" tabindex="-1"></a></span>
<span id="cb288-38"><a href="dl_2.html#cb288-38" tabindex="-1"></a>    # 转换为PyTorch张量</span>
<span id="cb288-39"><a href="dl_2.html#cb288-39" tabindex="-1"></a>    X_train = torch.tensor(X_train, dtype=torch.float32)</span>
<span id="cb288-40"><a href="dl_2.html#cb288-40" tabindex="-1"></a>    y_train = torch.tensor(y_train, dtype=torch.long)     # 交叉熵损失函数要求标签为整数型</span>
<span id="cb288-41"><a href="dl_2.html#cb288-41" tabindex="-1"></a>    X_test = torch.tensor(X_test, dtype=torch.float32)</span>
<span id="cb288-42"><a href="dl_2.html#cb288-42" tabindex="-1"></a>    y_test = torch.tensor(y_test, dtype=torch.long)</span>
<span id="cb288-43"><a href="dl_2.html#cb288-43" tabindex="-1"></a>    </span>
<span id="cb288-44"><a href="dl_2.html#cb288-44" tabindex="-1"></a>    return X_train, X_test, y_train, y_test</span>
<span id="cb288-45"><a href="dl_2.html#cb288-45" tabindex="-1"></a></span>
<span id="cb288-46"><a href="dl_2.html#cb288-46" tabindex="-1"></a># 生成数据，多分类任务</span>
<span id="cb288-47"><a href="dl_2.html#cb288-47" tabindex="-1"></a>X_train, X_test, y_train, y_test = gen_data()</span>
<span id="cb288-48"><a href="dl_2.html#cb288-48" tabindex="-1"></a></span>
<span id="cb288-49"><a href="dl_2.html#cb288-49" tabindex="-1"></a># 创建数据加载器</span>
<span id="cb288-50"><a href="dl_2.html#cb288-50" tabindex="-1"></a>train_dataset = TensorDataset(X_train, y_train)</span>
<span id="cb288-51"><a href="dl_2.html#cb288-51" tabindex="-1"></a>test_dataset = TensorDataset(X_test, y_test)</span>
<span id="cb288-52"><a href="dl_2.html#cb288-52" tabindex="-1"></a></span>
<span id="cb288-53"><a href="dl_2.html#cb288-53" tabindex="-1"></a>train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)</span>
<span id="cb288-54"><a href="dl_2.html#cb288-54" tabindex="-1"></a>test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)</span>
<span id="cb288-55"><a href="dl_2.html#cb288-55" tabindex="-1"></a></span>
<span id="cb288-56"><a href="dl_2.html#cb288-56" tabindex="-1"></a>model = nn.Sequential(</span>
<span id="cb288-57"><a href="dl_2.html#cb288-57" tabindex="-1"></a>    nn.Linear(10,128),</span>
<span id="cb288-58"><a href="dl_2.html#cb288-58" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb288-59"><a href="dl_2.html#cb288-59" tabindex="-1"></a>    nn.BatchNorm1d(128),  # 对该批次数据进行标准化操作，并进行缩放和平移，可在一定程度上缓解“内部协变量偏移”情况</span>
<span id="cb288-60"><a href="dl_2.html#cb288-60" tabindex="-1"></a>    nn.Dropout(0.2),     # 以一定概率丢弃某些神经元，从而缓解过拟合现象</span>
<span id="cb288-61"><a href="dl_2.html#cb288-61" tabindex="-1"></a>    </span>
<span id="cb288-62"><a href="dl_2.html#cb288-62" tabindex="-1"></a>    nn.Linear(128,64),</span>
<span id="cb288-63"><a href="dl_2.html#cb288-63" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb288-64"><a href="dl_2.html#cb288-64" tabindex="-1"></a>    nn.BatchNorm1d(64),</span>
<span id="cb288-65"><a href="dl_2.html#cb288-65" tabindex="-1"></a>    nn.Dropout(0.2),</span>
<span id="cb288-66"><a href="dl_2.html#cb288-66" tabindex="-1"></a></span>
<span id="cb288-67"><a href="dl_2.html#cb288-67" tabindex="-1"></a>    nn.Linear(64,32),</span>
<span id="cb288-68"><a href="dl_2.html#cb288-68" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb288-69"><a href="dl_2.html#cb288-69" tabindex="-1"></a>    nn.BatchNorm1d(32),</span>
<span id="cb288-70"><a href="dl_2.html#cb288-70" tabindex="-1"></a>    nn.Dropout(0.2),</span>
<span id="cb288-71"><a href="dl_2.html#cb288-71" tabindex="-1"></a>    </span>
<span id="cb288-72"><a href="dl_2.html#cb288-72" tabindex="-1"></a>    nn.Linear(32,5)      # 输出维度为类别数</span>
<span id="cb288-73"><a href="dl_2.html#cb288-73" tabindex="-1"></a>)</span>
<span id="cb288-74"><a href="dl_2.html#cb288-74" tabindex="-1"></a></span>
<span id="cb288-75"><a href="dl_2.html#cb288-75" tabindex="-1"></a>criterion = nn.CrossEntropyLoss()</span>
<span id="cb288-76"><a href="dl_2.html#cb288-76" tabindex="-1"></a>optimizer = optim.Adam(model.parameters(), lr=0.05)</span>
<span id="cb288-77"><a href="dl_2.html#cb288-77" tabindex="-1"></a></span>
<span id="cb288-78"><a href="dl_2.html#cb288-78" tabindex="-1"></a>device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
<span id="cb288-79"><a href="dl_2.html#cb288-79" tabindex="-1"></a>model.to(device)</span>
<span id="cb288-80"><a href="dl_2.html#cb288-80" tabindex="-1"></a></span>
<span id="cb288-81"><a href="dl_2.html#cb288-81" tabindex="-1"></a># 存储训练指标</span>
<span id="cb288-82"><a href="dl_2.html#cb288-82" tabindex="-1"></a>train_losses = []</span>
<span id="cb288-83"><a href="dl_2.html#cb288-83" tabindex="-1"></a>train_accuracies = []</span>
<span id="cb288-84"><a href="dl_2.html#cb288-84" tabindex="-1"></a>val_losses = []</span>
<span id="cb288-85"><a href="dl_2.html#cb288-85" tabindex="-1"></a>val_accuracies = []</span>
<span id="cb288-86"><a href="dl_2.html#cb288-86" tabindex="-1"></a></span>
<span id="cb288-87"><a href="dl_2.html#cb288-87" tabindex="-1"></a>for epoch in range(100):</span>
<span id="cb288-88"><a href="dl_2.html#cb288-88" tabindex="-1"></a>    # 训练模式</span>
<span id="cb288-89"><a href="dl_2.html#cb288-89" tabindex="-1"></a>    model.train()</span>
<span id="cb288-90"><a href="dl_2.html#cb288-90" tabindex="-1"></a>    running_loss = 0.0</span>
<span id="cb288-91"><a href="dl_2.html#cb288-91" tabindex="-1"></a>    correct_train = 0</span>
<span id="cb288-92"><a href="dl_2.html#cb288-92" tabindex="-1"></a>    total_train = 0</span>
<span id="cb288-93"><a href="dl_2.html#cb288-93" tabindex="-1"></a>    </span>
<span id="cb288-94"><a href="dl_2.html#cb288-94" tabindex="-1"></a>    for batch_x, batch_y in train_loader:</span>
<span id="cb288-95"><a href="dl_2.html#cb288-95" tabindex="-1"></a>        # 移动数据到设备</span>
<span id="cb288-96"><a href="dl_2.html#cb288-96" tabindex="-1"></a>        batch_x, batch_y = batch_x.to(device), batch_y.to(device)</span>
<span id="cb288-97"><a href="dl_2.html#cb288-97" tabindex="-1"></a>        </span>
<span id="cb288-98"><a href="dl_2.html#cb288-98" tabindex="-1"></a>        # 前向传播</span>
<span id="cb288-99"><a href="dl_2.html#cb288-99" tabindex="-1"></a>        outputs = model(batch_x)</span>
<span id="cb288-100"><a href="dl_2.html#cb288-100" tabindex="-1"></a>        </span>
<span id="cb288-101"><a href="dl_2.html#cb288-101" tabindex="-1"></a>        # 计算损失</span>
<span id="cb288-102"><a href="dl_2.html#cb288-102" tabindex="-1"></a>        loss = criterion(outputs, batch_y)</span>
<span id="cb288-103"><a href="dl_2.html#cb288-103" tabindex="-1"></a>        </span>
<span id="cb288-104"><a href="dl_2.html#cb288-104" tabindex="-1"></a>        # 反向传播和优化</span>
<span id="cb288-105"><a href="dl_2.html#cb288-105" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb288-106"><a href="dl_2.html#cb288-106" tabindex="-1"></a>        loss.backward()</span>
<span id="cb288-107"><a href="dl_2.html#cb288-107" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb288-108"><a href="dl_2.html#cb288-108" tabindex="-1"></a>        </span>
<span id="cb288-109"><a href="dl_2.html#cb288-109" tabindex="-1"></a>        # 统计训练情况</span>
<span id="cb288-110"><a href="dl_2.html#cb288-110" tabindex="-1"></a>        running_loss += loss.item()</span>
<span id="cb288-111"><a href="dl_2.html#cb288-111" tabindex="-1"></a>        </span>
<span id="cb288-112"><a href="dl_2.html#cb288-112" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb288-113"><a href="dl_2.html#cb288-113" tabindex="-1"></a>        predictions = torch.argmax(outputs, dim = 1)   # logits值最大的为预测类别</span>
<span id="cb288-114"><a href="dl_2.html#cb288-114" tabindex="-1"></a>        correct_train += (predictions == batch_y).sum().item()</span>
<span id="cb288-115"><a href="dl_2.html#cb288-115" tabindex="-1"></a>        total_train += batch_y.size(0)</span>
<span id="cb288-116"><a href="dl_2.html#cb288-116" tabindex="-1"></a>    </span>
<span id="cb288-117"><a href="dl_2.html#cb288-117" tabindex="-1"></a>    # 计算本轮训练的平均损失和准确率</span>
<span id="cb288-118"><a href="dl_2.html#cb288-118" tabindex="-1"></a>    epoch_loss = running_loss / len(train_loader)</span>
<span id="cb288-119"><a href="dl_2.html#cb288-119" tabindex="-1"></a>    epoch_acc = correct_train / total_train if total_train &gt; 0 else 0</span>
<span id="cb288-120"><a href="dl_2.html#cb288-120" tabindex="-1"></a>    train_losses.append(epoch_loss)</span>
<span id="cb288-121"><a href="dl_2.html#cb288-121" tabindex="-1"></a>    train_accuracies.append(epoch_acc)</span>
<span id="cb288-122"><a href="dl_2.html#cb288-122" tabindex="-1"></a>    </span>
<span id="cb288-123"><a href="dl_2.html#cb288-123" tabindex="-1"></a>    # 验证评估</span>
<span id="cb288-124"><a href="dl_2.html#cb288-124" tabindex="-1"></a>    model.eval()</span>
<span id="cb288-125"><a href="dl_2.html#cb288-125" tabindex="-1"></a>    with torch.no_grad():</span>
<span id="cb288-126"><a href="dl_2.html#cb288-126" tabindex="-1"></a>        # 移动测试数据到设备</span>
<span id="cb288-127"><a href="dl_2.html#cb288-127" tabindex="-1"></a>        test_x, test_y = X_test.to(device), y_test.to(device)</span>
<span id="cb288-128"><a href="dl_2.html#cb288-128" tabindex="-1"></a>        # 前向传播</span>
<span id="cb288-129"><a href="dl_2.html#cb288-129" tabindex="-1"></a>        outputs = model(test_x)</span>
<span id="cb288-130"><a href="dl_2.html#cb288-130" tabindex="-1"></a>        # 计算损失</span>
<span id="cb288-131"><a href="dl_2.html#cb288-131" tabindex="-1"></a>        val_loss = criterion(outputs, test_y).item()</span>
<span id="cb288-132"><a href="dl_2.html#cb288-132" tabindex="-1"></a>        # 计算预测结果</span>
<span id="cb288-133"><a href="dl_2.html#cb288-133" tabindex="-1"></a>        predictions = torch.argmax(outputs, dim = 1)</span>
<span id="cb288-134"><a href="dl_2.html#cb288-134" tabindex="-1"></a>        # 计算准确率</span>
<span id="cb288-135"><a href="dl_2.html#cb288-135" tabindex="-1"></a>        correct_val = (predictions == test_y).sum().item()</span>
<span id="cb288-136"><a href="dl_2.html#cb288-136" tabindex="-1"></a>        total_val = test_y.size(0)</span>
<span id="cb288-137"><a href="dl_2.html#cb288-137" tabindex="-1"></a>        val_acc = correct_val / total_val</span>
<span id="cb288-138"><a href="dl_2.html#cb288-138" tabindex="-1"></a>        # 存储验证结果</span>
<span id="cb288-139"><a href="dl_2.html#cb288-139" tabindex="-1"></a>        val_losses.append(val_loss)</span>
<span id="cb288-140"><a href="dl_2.html#cb288-140" tabindex="-1"></a>        val_accuracies.append(val_acc)</span>
<span id="cb288-141"><a href="dl_2.html#cb288-141" tabindex="-1"></a>    </span>
<span id="cb288-142"><a href="dl_2.html#cb288-142" tabindex="-1"></a>    # 每10个epoch打印一次进度</span>
<span id="cb288-143"><a href="dl_2.html#cb288-143" tabindex="-1"></a>    if (epoch + 1) % 10 == 0:</span>
<span id="cb288-144"><a href="dl_2.html#cb288-144" tabindex="-1"></a>        print(&quot;=&quot;*10,</span>
<span id="cb288-145"><a href="dl_2.html#cb288-145" tabindex="-1"></a>              f&quot;Epoch_{epoch+1}&quot;,</span>
<span id="cb288-146"><a href="dl_2.html#cb288-146" tabindex="-1"></a>              &quot;=&quot;*10,</span>
<span id="cb288-147"><a href="dl_2.html#cb288-147" tabindex="-1"></a>              f&quot;\nTrain Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\n&quot;,</span>
<span id="cb288-148"><a href="dl_2.html#cb288-148" tabindex="-1"></a>              f&quot;Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}&quot;)</span></code></pre></div>
<p>说明：</p>
<ol style="list-style-type: decimal">
<li><p><code>nn.CrossEntropyLoss()</code>接收预测值logits（原值）与标签。其中logits为神经网络的原始输出，无需在输出时添加Softmax激活函数，<code>nn.CrossEntropyLoss()</code>的内部会自动进行Softmax计算，避免重复计算。同时，标签要求为整数型且维度为1，不需要独热编码。</p></li>
<li><p>如果需要输出概率，可以在输出logits后手动计算<code>torch.softmax(outputs, dim=1)</code>。</p></li>
<li><p>如果要输出预测类别，可以<code>torch.argmax(outputs, dim=1)</code>。</p></li>
</ol>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="dl_1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dl_9.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "toc_depth": 3
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
